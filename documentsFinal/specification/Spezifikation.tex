%% LyX 1.6.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english,ngerman]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{listings}
\usepackage[letterpaper]{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}
\usepackage{babel}

\usepackage{array}
\usepackage{float}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage[unicode=true, pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks=false]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.





\usepackage{babel}

% Package für das Einfärben von Tabellen
\usepackage{colortbl}

% Packages für eigen definierte Header und Footer
\usepackage{lastpage}
\usepackage{fancyhdr}

% doctitel = Titel des Dokuments
% docvers = Versionsnr.
% docautor = Author(en)
% docdate = Datum der letzten Änderung
\def\doctitel{Spezifikation}
\def\docvers{2.6}
\def\docautor{}
\def\docdate{15. Juni 2010}

% docstate = Status des Dokuments aus {neu, bearbeitet}
% qsstate = QS-Prüfungsstatus aus {positiv QS-geprüft, negativ QS-geprüft, verworfen}
% proofstate = Prüfungsstatus (durch Projektleiter) aus {positiv geprüft, negativ geprüft, verworfen}
% reviewstate = Annahmestatus des Reviews {kein Review durchgeführt, akzeptiert ohne Änderungen, akzeptiert mit Änderungen, nicht akzeptiert}
% endstate = Endstatus des Dokuments aus {freigegeben, verworfen}
\def\docstate{bearbeitet}
\def\qsstate{negativ QS-geprüft}
\def\proofstate{negativ geprüft}
\def\reviewstate{akzeptiert mit Änderungen}
\def\endstate{freigegeben}

% Definierter Grauton für die Tabellenfärbung
\definecolor{lightgray}{rgb}{0.7,0.7,0.7}

%Nicht einrücken
%\setlength{\parindent}{0pt}

\makeatother

\begin{document}
\input{Deckblatt.tex}



%Header und Footer Definitionen für alle anderen Seiten
\pagestyle{fancy} \global\long\def\headrulewidth{0mm}
 \lhead{} \chead{} \rhead{} \lfoot{{\small SIMPL © 2009
\$IMPL}} \cfoot{} \rfoot{{\small \thepage\ / \pageref{LastPage}}}

%Ab hier beginnt das Dokument
\tableofcontents{}

\newpage{}


\section*{Änderungsgeschichte}

\begin{center}
\begin{tabular}{|>{\raggedright}p{2cm}|>{\raggedright}p{3cm}|>{\raggedright}p{3cm}|>{\raggedright}p{6cm}|}
\hline 
\textbf{Version} & \textbf{Datum} & \textbf{Autor} & \textbf{Änderungen}\tabularnewline
\hline
\hline 
0.1 & 11.09.2009 & hahnml & Erstellung des Dokuments.\tabularnewline
\hline 
0.2 & 14.09.2009 & zoabfs, hahnml, xitu & Kapitel \ref{sec:Nichtfunktionale-Anforderungen} eingefügt.\tabularnewline
\hline 
0.3 & 17.09.2009 & hahnml, zoabisfs & Kapitel \ref{sec:Konzepte-und-Realisierungen} eingefügt.\tabularnewline
\hline 
0.4 & 21.09.2009 & hahnml, zoabisfs, rehnre & Kapitel \ref{sec:Akteure} und \ref{sec:Anwendungsf=0000E4lle-(Use-Cases)}
eingefügt.\tabularnewline
\hline 
1.0 & 28.09.2009 & hahnml, zoabisfs, schneimi, bruededl, huettiwg, rehnre & Abschließende Überarbeitung des Dokuments.\tabularnewline
\hline 
1.1 & 19.10.2009 & hahnml, schneimi, rehnre & Korrektur der Spezifikation nach dem Review mit den Kunden.\tabularnewline
\hline 
1.2 & 13.11.2009 & hahnml & Korrektur der 1.Iteration der Spezifikation.\tabularnewline
\hline 
1.3 & 13.11.2009 & huettiwg & Abschließende Überarbeitung der 1. Iteration der Spezifikation.\tabularnewline
\hline 
1.4 & 22.01.2010 & hahnml & Korrektur der Spezifikation anhand von weiteren Kommentaren der Kunden.\tabularnewline
\hline 
1.5 & 05.02.2010 & rehnre & Korrektur von Kapitel \ref{sub:Auditing}.\tabularnewline
\hline 
2.0 & 06.02.2010 & hahnml & Erweiterung der Spezifikation auf die 2.Iteration.\tabularnewline
\hline 
2.1 & 01.03.2010 & schneimi & Use-Case-Diagramme und einige Use Cases überarbeitet.\tabularnewline
\hline 
2.2 & 01.03.2010 & schneimi, huettiwg, rehnre, hahnml & Abschließende Bearbeitung der Spezifikation.\tabularnewline
\hline 
2.3 & 02.03.2010 & hahnml, huettiwg & Überarbeitung der Spezifikation.\tabularnewline
\hline 
2.4 & 27.05.2010 & hahnml & Korrektur der Spezifikation anhand der Kundenkommentare zur 2.Iteration.
Einfügen von Kapitel \ref{sub:Benutzeroberfl=0000E4che-erw-BPEL-Des}.\tabularnewline
\hline 
2.5 & 14.06.2010 & huettiwg, rehnre & Überarbeitung der Spezifikation.

Einfügen von Kapitel \ref{sec:Ausblick}\tabularnewline
\hline 
2.6 & 15.06.2010 & huettiwg & Abschließende Überarbeitung\tabularnewline
\hline
\end{tabular}
\par\end{center}

\pagebreak{}


\section{Einleitung}

In diesem Kapitel wird der Zweck dieses Dokuments sowie der Einsatzbereich
und die Ziele der zu entwickelnden Software beschrieben. Weiterhin
werden die in diesem Dokument verwendeten Definitionen erläutert und
ein Überblick über das restliche Dokument gegeben.


\subsection{Zweck des Dokuments}

Diese Spezifikation ist die Grundlage für alle weiteren Dokumente,
die im Rahmen dieses Projekts entstehen. In ihr sind sämtliche Anforderungen
an die zu entwickelnde Software festgelegt. Sie muss stets mit den
anderen Dokumenten, insbesondere mit dem Entwurf und der Implementierung,
konsistent gehalten werden. Die Spezifikation dient den Team-Mitgliedern
als Grundlage und Richtlinie für die Entwicklung der Software und
den Kunden als Zwischenergebnis zur Kontrolle.

Zum Leserkreis dieser Spezifikation gehören: 
\begin{itemize}
\item Die Entwickler der Software, 
\item die Kunden und
\item die Gutachter der Spezifikationsreviews.
\end{itemize}

\subsection{Einsatzbereich und Ziele}

Das Entwicklungsteam soll ein erweiterbares und generisches Rahmenwerk
für die Modellierung und Ausführung von Workflows erstellen, welches
den Zugriff auf nahezu beliebige Datenquellen ermöglichen soll. Bei
den Datenquellen kann es sich beispielsweise um Sensornetze, Datenbanken
und Dateisysteme handeln. Der Schwerpunkt soll klar auf wissenschaftlichen
Workflows liegen, in denen es möglich sein muss, große heterogene
Datenmengen verarbeiten zu können. Als Modellierungs- und Ausführungssprache
für die hier betrachteten Workflows dient die Business Process Execution
Langauge (BPEL, \cite{key-4}). Über das Rahmenwerk sollen beliebige
Datenmanagement-Funktionen in einen BPEL-Prozess eingebunden werden
können. Dafür werden bereits vorhandene Konzepte evaluiert, wie z.B.
die Sprache BPEL, und falls nötig erweitert und angepasst. Für eine
möglichst hohe Flexibilität soll ein dynamischer Ansatz gewählt werden,
so dass auch erst zur Laufzeit des Systems die Datenquellen festgelegt
werden können. Nichtsdestoweniger sollte auch die Möglichkeit bestehen,
die Datenquellen statisch anbinden zu können. Eine Anforderung des
Kunden ist, dass eine vorhandene BPEL-Workflow-Engine sowie ein vorhandenes
Modellierungstool um diese gewünschten Funktionen erweitert bzw. angepasst
werden. Die BPEL-Prozesse sollen mit dem entsprechenden Modellierungstool
spezifiziert und mit der BPEL-Workflow-Engine ausgeführt werden können.


\subsection{Evolution des Dokuments}

Die vorliegende Spezifikation beschreibt die Anforderungen, die im
SIMPL-Rahmenwerk umgesetzt werden, sowie einige mögliche Erweiterungen,
die später noch hinzukommen können. 


\subsubsection{Iteration 1\label{sub:Iteration-1}}

Folgende Funktionen bilden die Funktionalität des SIMPL-Rahmenwerks
nach der 1.Iteration:
\begin{itemize}
\item Umsetzung eines Plug-In System für die Anbindung von verschiedenen
Datenquellen.
\item Die statische Anbindung von Datenquellen, wobei vorerst nur relationale
Datenbanken unterstützt werden sollen.
\item Bereitstellung von generischen BPEL-Aktivitäten im Eclipse BPEL Designer
für den Zugriff auf Datenquellen.
\item Bereitstellung von grafischen Abfragebefehls-Editoren für die verschiedenen
DM-Aktivitäten.
\item Umsetzung einer grundlegenden Admin-Konsole, in der das Auditing aktiviert
werden kann und die Zieldatenquelle und deren Authentifizierungsinformationen
für das Auditing festgelegt werden können.
\end{itemize}

\subsubsection{Iteration 2\label{sub:Iteration-2}}

Die Funktionalität des SIMPL-Rahmenwerks wird in der 2.Iteration um
folgende Funktionen erweitert:
\begin{itemize}
\item Anbindung von Dateisystemen am Beispiel des CSV-Dateiformats.
\item Unterstützung von Referenzen in BPEL (siehe \cite{key-3}), damit
auf Daten auch per Referenz im Workflow zugegriffen werden kann. Dies
wird aus Gründen der Performanz benötigt, da die Datenübergabe zwischen
Workflow und Web Service standardmäßig per Wert erfolgt, was bei großen
Datenmengen (bis zu Gigabytes oder gar Terabytes im wissenschaftlichen
Bereich) zu erheblichen Performanzeinbußen führt.
\item Bereitstellung einer Datenquellen-Registry, mit Hilfe derer Datenquellen
über den Eclipse BPEL Designer (siehe \cite{key-10}) manuell durch
den Benutzer oder dynamisch durch das SIMPL Rahmenwerk ausgewählt
werden können.
\item Unterstützung einer automatischen Auswahl von Datenquellen zur Laufzeit.
Dabei kann der Benutzer Anforderungen an Datenquellen formulieren
und eine Strategie auswählen, mit deren Hilfe eine Datenquelle, die
seine Anforderungen erfüllt, ausgewählt wird.
\end{itemize}

\subsubsection{Mögliche Erweiterungen \label{sub:Ausblick}}

Im Folgenden werden einige mögliche Erweiterungen beschrieben. Auf
einige dieser Erweiterungsmöglichkeiten wird in den entsprechenden
Kapiteln näher eingegangen.
\begin{itemize}
\item Einstellung der Granularität des Auditings.
\item Validierung der DM-Aktivitäten im Eclipse BPEL Designer.
\item Implementierung eines Monitorings, welches das bestehende Auditing
nutzt, um dessen Daten in definierten Abständen auszulesen und dem
Benutzer zur Beobachtung und Überwachung von BPEL-Prozessen anzuzeigen.
\end{itemize}

\subsection{Definitionen}

Die in der Spezifikation verwendeten Begriffe, Definitionen und Abkürzungen
werden in einem separaten Begriffslexikon eindeutig definiert und
erklärt. Dadurch werden Missverständnisse innerhalb des Projektteams
oder zwischen Projektteam und Kunde vermieden.

Auf alle in Abschnitt \ref{sub:Resultierende-BPEL-Aktivit=0000E4ten}
beschriebenen BPEL-Aktivitäten wird in diesem Dokument mit dem Sammelbegriff
Data-Management-Aktivität verwiesen. Wird also von einer Data-Management-Aktivität
gesprochen, ist indirekt eine oder mehrere dieser Aktivitäten gemeint.
Über die Definition und Verwendung dieses Sammelbegriffs soll lediglich
die Allgemeingültigkeit der getroffenen Aussagen für jede der in Abschnitt
\ref{sub:Resultierende-BPEL-Aktivit=0000E4ten} beschriebenen Aktivitäten
erreicht werden. Nachfolgend wird weiterhin für den Begriff Data-Management-Aktivität
die Abkürzung DM-Aktivität verwendet.


\subsection{Überblick}

In diesem Dokument soll die zu entwickelnde Software spezifiziert
werden. Dazu werden in Kapitel \ref{sec:Allgemeine-Beschreibung}
die spätere Systemumgebung, die Kernfunktionen, die Sprache und weitere
Aspekte der Software beschrieben. So erhält der Leser einen Überblick
über die Funktionalität der Software und deren Verwendung. Weiterhin
werden die Ziele und Aufgaben, die für die Realisierung der Software
bestehen, aufgezeigt. Anschließend werden die vom Kunden genannten
Anforderungen durch die Kapitel \ref{sec:Nichtfunktionale-Anforderungen},
\ref{sec:Akteure}, \ref{sec:Anwendungsf=0000E4lle-(Use-Cases)} und
die Benutzeroberfläche in Kapitel \ref{sec:Benutzeroberfl=0000E4che}
aufgezeigt. Dabei werden durch die nichtfunktionalen Anforderungen
qualitative (Robustheit, Portabilität, usw.) und quantitative (Mengengerüst)
Anforderungen an die Software spezifiziert. Die Anwendungsfälle in
Kapitel \ref{sec:Anwendungsf=0000E4lle-(Use-Cases)} beschreiben die
funktionalen Anforderungen. Es werden also konkret die Funktionen,
die die Software enthalten soll und z.T. schon in der Übersicht der
Kernfunktionalität in Abschnitt \ref{sub:Funktionen} aufgeführt sind,
beschrieben. Im Anschluss folgen in Kapitel \ref{sec:Konzepte-und-Realisierungen}
die Beschreibungen und Definitionen einiger Konzepte bzw. Ansätze,
die zur Umsetzung der gewünschten Funktionalität benötigt werden.
Am Ende des Dokuments werden in Kapitel \ref{sec:Technologien und Werkzeuge}
die verwendeten Werkzeuge und Technologien, die für die Erstellung
der Software benötigt werden, vorgestellt.

\pagebreak{}


\section{\label{sec:Allgemeine-Beschreibung}Allgemeine Beschreibung}

Dieses Kapitel liefert allgemeine Informationen über die zu entwickelnde
Software. Dazu gehören beispielsweise die Beschreibung der späteren
Systemumgebung, die wichtigsten Funktionen, die verwendete Sprache
und Informationen über den Benutzerkreis der Software.


\subsection{\label{sub:Einbettung-Systemumgebung}Einbettung in die Systemumgebung}

Das SIMPL Rahmenwerk, bestehend aus dem SIMPL Core, den SIMPL Eclipse
Plug-Ins und den BPEL-DM Extension Activities, soll in die in Abbildung
\ref{fig:Systemumgebung} dargestellte Systemumgebung eingebettet
werden. Die Systemumgebung besteht dabei aus Eclipse mit dem BPEL
Designer Plug-In, einem Web Server, wie dem Apache Tomcat (siehe \cite{key-7}),
und den Datenquellen, auf die zugegriffen wird. Der SIMPL Core und
eine Workflow-Engine (Apache Orchestration Director Engine (ODE),
siehe \cite{key-6}) werden auf dem Web Server ausgeführt. SIMPL unterstützt
relationale Datenbanken (MySQL, IBM DB2, Apache Derby) und Dateisysteme
(CSV-Dateiformat) und kann um weitere Datenquellen, wie XML-Datenbanken
(IBM DB2 mit pureXML-Technologie) oder Sensornetz-Datenbanken (TinyDB)
ergänzt werden. Eine Sensornetz-Datenbank (TinyDB) speichert die Daten
von meist kabellos vernetzten Sensoren und liefert so eine zentrale
und einheitliche Zugriffsmöglichkeit auf Sensordaten. Der SIMPL Core
läuft als Web Service auf dem Web Server und liefert u.a. die Funktionalität,
die während der Laufzeit von Prozessen mit DM-Aktivitäten benötigt
wird. Durch den SIMPL Core werden generell weitgehend alle Funktionalitäten,
die von einem beliebigen Ansatz für den Zugriff auf Datenquellen von
wissenschaftlichen Workflows benötigt werden, geliefert. Dadurch ergibt
sich die Möglichkeit, in der Workflow-Engine so wenig wie nötig implementieren
zu müssen. Diese Aufteilung ermöglicht es, entsprechende zukünftige
Ansätze für den Datenzugriff relativ leicht umzusetzen bzw. bereits
entwickelte Ansätze auch relativ leicht in andere Workflow-Laufzeit-
und Modellierungsumgebungen zu integrieren. Dieser Umstand erhöht
die Portabilität und die Erweiterbarkeit des Rahmenwerks beträchtlich.
Die SIMPL Eclipse Plug-Ins bestehen aus drei separaten Plug-Ins, dem
SIMPL Core Plug-In, dem BPEL-DM Plug-In und dem SIMPL Core Communication
Plug-In. Das SIMPL Core Plug-In erweitert die grafische Oberfläche
von Eclipse, um Einstellungen für das SIMPL Rahmenwerk vornehmen zu
können. Das BPEL-DM Plug-In erweitert das Eclipse BPEL Designer Plug-In,
um Prozesse mit DM-Aktivitäten modellieren zu können. Durch diese
Trennung ist es möglich, auch nur eines der beiden Plug-Ins in Eclipse
einzubinden und z.B. für das jeweils andere Plug-In eigene Implementierungen
zu nutzen. Das SIMPL Core Communication Plug-In realisiert die Verbindung
mit dem SIMPL Core und wird sowohl für das SIMPL Core Plug-In (Laden
und Speichern von Rahmenwerkseinstellungen), als auch für das BPEL-DM
Plug-In (Laden aller vom SIMPL Core unterstützten Datenquellen) benötigt.
Die Ausführungslogiken der jeweiligen DM-Aktivitäten werden in der
Workflow-Engine implementiert und in diese als Plug-In (BPEL-DM Extension
Activities) eingebunden. Dabei läuft die benötigte Software auf dem
lokalen Rechner des Benutzers, die Datenquellen können auf verschiedene
Server verteilt sein. Das RRS Plug-In bindet ein Reference Resolution
System (RRS) für die Verwendung von Referenzen auf Daten in BPEL in
Eclipse ein (siehe \ref{sub:Reference-Resolution-System}). Das UDDI
( Universal Description, Discovery and Integration ) Plug-In bindet
eine Datenquellen-Registry in Eclipse ein (siehe \ref{fig:Datenquellen-Registry-View}).
Die dort hinterlegten Datenquellen können dann bei der Modellierung
von Prozessen in den DM-Aktivitäten ausgewählt werden.

%
\begin{figure}[H]
\noindent \begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/Systemumgebung}
\par\end{centering}

\caption{\label{fig:Systemumgebung}Übersicht über die Systemumgebung von SIMPL}

\end{figure}



\subsection{\label{sub:Funktionen}Funktionen}

In diesem Abschnitt folgen die wichtigsten Funktionen des Rahmenwerks,
die später dessen Kernfunktionalität bilden sollen.

Das Rahmenwerk soll als Eclipse Plug-In verwendet werden und mit der
Laufzeitumgebung integriert sein. Es soll die Verarbeitung von großen,
heterogenen Datenmengen im Rahmen von wissenschaftlichen Workflows
ermöglichen.

Die vorhandenen BPEL-Aktivitäten des Eclipse BPEL Designers werden
dazu um neue Aktivitäten für die Verwaltung von Daten erweitert (DM-Aktivitäten).
Mit deren Hilfe wird die Anbindung von Datenquellen in BPEL-Prozessen
vereinfacht. Dabei können die Datenquellen sowohl statisch als auch
dynamisch angebunden werden. Für die dynamische Anbindung von Datenquellen
wird eine Datenquellen-Registry bereitgestellt, die es ermöglicht,
dass Datenquellen im Modellierungswerkzeug einfach ausgewählt werden
können oder automatisch zur Laufzeit angebunden werden. Eine nähere
Beschreibung der DM-Aktivitäten wird in Abschnitt \ref{sub:Data-Management-Aktivit=0000E4ten-GUI}
gegeben.

Alle Ereignisse, die während der Laufzeit eines Prozesses auftreten
(z.B. Ausführung einer DM-Aktivität), werden durch ein Auditing in
einer vom Nutzer definierten Datenbank gespeichert.

Für die Verwaltung des SIMPL-Rahmenwerks und zur Änderung von Einstellungen
auch während der Laufzeit von Prozessen wird eine Admin-Konsole implementiert.
Über diese kann das Auditing an- und ausgeschaltet sowie eine Datenbank
zur Speicherung der Auditinginformationen angegeben werden.


\subsection{Sprache}

Generell gilt, dass alle Dokumente auf Deutsch und jeder Quellcode
einschließlich Kommentaren auf Englisch verfasst und ausgeliefert
werden sollen. Eine Ausnahme bilden das Handbuch und die verschiedenen
Dokumentationen der von uns durchgeführten Erweiterungen, wie z.B.
die Erweiterungen von Apache ODE oder dem Eclipse BPEL Designer. Diese
Dokumente werden auf Deutsch und auf Englisch verfasst, um sie einem
breiteren Leserkreis zur Verfügung stellen zu können.


\subsection{Distributionsform und Installation}

Das Rahmenwerk wird als Teil eines großen Installationpakets ausgeliefert.
Dieses Installationspaket besteht aus allen Programmen, die für die
Verwendung des Rahmenwerks benötigt werden. Dazu gehöhrt ein Modellierungstool
(Eclipse BPEL Designer), ein Web Server (Apache Tomcat), der eine
Workflow-Engine ausführen kann, eine Workflow-Engine (Apache ODE)
und natürlich das Rahmenwerk selbst. Mithilfe des Installationspakets
ist es möglich, viele Einstellungen bereits vorzudefinieren und dem
Benutzer die Installation zu erleichern. Das Installationspaket wird
dabei als RAR-Archiv zusammen mit allen wichtigen Dokumenten auf einer
CD/DVD ausgeliefert. So können nachträgliche Erweiterungen/Korrekturen
des Rahmenwerks mithilfe der Dokumentationen leichter realisiert werden.
Die Installation der einzelnen Komponenten wird dann anhand der mitgelieferten
Installationsanleitung durchgeführt. Nähere Informationen liefert
\cite{key-1}.


\subsection{Benutzerprofile}

Die Benutzer sind im Normalfall Wissenschaftler und Ingenieure. Sie
haben meist keine bis wenig Vorkenntnisse in den Bereichen Workflow
und Informatik und stellen so entsprechende Anforderungen an die Benutzbarkeit
des Rahmenwerks (siehe Kapitel \ref{sec:Nichtfunktionale-Anforderungen}).


\subsection{Einschränkungen}

Für die Erstellung und Verwendung des SIMPL Rahmenwerks gelten die
folgenden Einschränkungen:
\begin{itemize}
\item Als Workflow-Modellierungssprache dient die Business Process Execution
Language (BPEL).
\item Die Modellierung von BPEL-Prozessen ist an das Modellierungswerkzeug
Eclipse BPEL Designer gebunden. 
\item Die Ausführung von BPEL-Prozessen ist an die Workflow-Engine Apache
ODE gebunden. Das Auditing einer Prozessausführung wird nur für Apache
ODE bereitgestellt.
\item Die SIMPL Eclipse Plug-Ins sind nur voll funktionsfähig, falls der
SIMPL Core erreichbar ist, d.h. dass ein Apache Tomcat Server mit
angebundenem SIMPL Core gestartet wurde.
\item Als Programmiersprache für das SIMPL Rahmenwerk kommt Java zum Einsatz.
\end{itemize}
\pagebreak{}


\section{\label{sec:Nichtfunktionale-Anforderungen}Nichtfunktionale Anforderungen}

In diesem Kapitel werden die nichtfunktionalen Anforderungen an die
zu entwickelnde Software beschrieben. Dafür werden die entsprechenden
Software-Qualitäten aufgeführt und ihre Bedeutung für die zu entwickelnde
Software erläutert.


\subsection{Mengengerüst}

Das Mengengerüst beinhaltet alle quantifizierbaren Anforderungen an
das Rahmenwerk:
\begin{itemize}
\item Für die Speicherung der Auditing-Daten kann nur eine Datenbank gleichzeitig
ausgewählt sein.
\item Alle laufenden Prozesse einer Workflow-Engine können zu einem Zeitpunkt
gemeinsam nur Daten in Höhe des Speichers, der durch das Betriebssystem
zur Verfügung gestellt wird, halten.
\end{itemize}

\subsection{Benutzbarkeit}

Die Benutzbarkeit soll sich vor allem an Nutzer mit wenig Kenntnissen
im Umgang mit Workflows und BPEL richten und die dafür größtmögliche
Transparenz liefern. Das bedeutet, dass die interne Prozesslogik der
Software bestmöglichst vom Benutzer abgeschirmt wird. Dadurch erhält
der Benutzer eine einfache und schnell verständliche Schnittstelle
zur Software.


\subsection{Verfügbarkeit}

Die Verfügbarkeit des Rahmenwerks soll mindestens so hoch sein, dass
sie der Verfügbarkeit der späteren Systemumgebung entspricht oder
diese übersteigt, damit durch die Verwendung des Rahmenwerks keine
zusätzlichen Ausfallzeiten entstehen.


\subsection{Robustheit}

Unter Robustheit ist hier zu verstehen, dass selbst wenn es zu ungünstigen
Bedingungen kommt, SIMPL weiterhin weitgehend fehlerfrei verwendet
werden kann. Ungünstige Bedingungen sind dabei z.B. der Ausfall des
Servers oder Probleme bei der Verbindung mit Datenquellen. Dazu sollen
Prozesse fehlerfrei ausgeführt werden und entsprechend korrekte Ergebnisse
liefern oder das Rahmenwerk sicher beendet werden können. Nach dem
Neustart des Rahmenwerks müssen evtl. auch die Prozessinstanzen, die
zum Zeitpunkt des Fehlers ausgeführt wurden, neu gestartet werden,
falls kein Recovery möglich ist.

Benutzereingaben werden nicht vom Rahmenwerk überprüft. Fehlerhafte
Eingaben resultieren während dem Deployment bzw. dem Prozessablauf
jedoch immer in stabilen Zuständen, die über entsprechende Fehlermeldungen
dem Benutzer mitgeteilt werden. Anhand der Fehlermeldungen kann der
Benutzer seine Eingaben korrigieren und den Prozess neu deployen bzw.
ausführen.


\subsection{Sicherheit}

Da das Rahmenwerk nur lokal ausgeführt wird und alle lokalen Benutzer
momentan die gleichen Rechte besitzen, wird vorerst auf Authentifizierungs-
und Autorisierungsmaßnahmen für den Zugriff auf das Rahmenwerk verzichtet.
Um eine spätere Realisierung zu vereinfachen, werden bereits jetzt
die Rollen Prozess-Modellierer und Workflow-Administrator (siehe Kapitel
\ref{sec:Akteure}) definiert. Die Authentifizierung und Autorisierung
bei Datenquellen wird in Abschnitt \ref{sub:Authentifizierung-und-Autorisierung}
beschrieben.


\subsection{Portabilität}

Die Portabilität des SIMPL Eclipse Plug-Ins ist durch die Integration
in Eclipse gewährleistet. Der SIMPL Core wird dahingehend implementiert,
dass er in allen Java unterstützenden Web Containern lauffähig ist.


\subsection{Erweiterbarkeit}

Die Erweiterbarkeit des Systems ist eine zentrale Anforderung, da
es über einen langen Zeitraum genutzt und in Zukunft um die Anbindung
weiterer Datenquellen, Konzepte für den Datenzugriff und den Umgang
mit weiteren Datenformaten ergänzt werden soll. Um die Erweiterbarkeit
des Systems zu gewährleisten, werden ein modularer Aufbau zugrunde
gelegt und entsprechende Schnittstellen geschaffen. Beispiele für
den modularen Aufbau des Rahmenwerks sind:
\begin{itemize}
\item Die Aufteilung des Rahmenwerks in SIMPL Core, erweiterter Workflow-Engine
und erweitertes Eclipse Plug-In (siehe Abschnitt \ref{sub:Einbettung-Systemumgebung}).
\item Das Plug-In System des SIMPL Cores, über das Plug-Ins zur Unterstützung
von weiteren Datenquellentypen einfach angebunden werden können.
\item Die Verwendung des Eclipse Plug-In Mechanismus für die Admin-Konsole.
\end{itemize}

\subsection{Wartbarkeit}

Durch eine qualitativ hochwertige Dokumentation und ein strukturiertes,
geplantes und sauberes Entwicklungsvorgehen soll eine hohe Wartbarkeit
erreicht werden. Dazu werden alle Dokumente entsprechend gepflegt
und laufend aktualisiert. Weiterhin werden nach jedem Entwicklungsintervall
Tests durchgeführt und deren Ergebnisse protokolliert.


\subsection{Skalierbarkeit}

Die Skalierbarkeit des Systems muss eine sehr flexible Infrastruktur
erlauben, da die Computersysteme, auf denen SIMPL später ausgeführt
wird, in ihrer Leistung sehr weit auseinander gehen können, d.h. vom
normalen Desktop-Computer bis zum Supercomputer kann und soll alles
möglich sein. Weiterhin soll die Skalierbarkeit des Rahmenwerks garantieren,
dass für die Verarbeitung von größer werdenden Datenmengen die benötigten
Ressourcen höchstens in der gleichen Größenordnung steigen.

\pagebreak{}


\section{\label{sec:Benutzeroberfl=0000E4che}Benutzeroberflächen von SIMPL}

In diesem Kapitel werden alle Benutzeroberflächen, die durch SIMPL
bereitgestellt oder erweitert werden, beschrieben.


\subsection{\label{sub:Benutzeroberfl=0000E4che-erw-BPEL-Des}Benutzeroberfläche
des erweiterten Eclipse BPEL Designers}

Dieses Kapitel beschreibt alle Erweiterungen des Eclipse BPEL Designers
und dessen Benutzeroberfläche.


\subsubsection{\label{sub:Erweiterungen-zur-Integration-Ref}Erweiterungen zur Integration
von Referenzvariablen in den Eclipse BPEL Designer}

In diesem Kapitel werden alle Erweiterungen des Eclipse BPEL Designers
beschrieben, die für die Modellierung und Verwendung von Referenzvariablen
in BPEL-Prozessen benötigt werden. Abbildung \ref{fig:SIMPL-Referenzvariablen}
zeigt den erweiterten BPEL Editor des Eclipse BPEL Designers. Auf
die neuen Elemente wird dabei im folgenden näher eingegangen. 

%
\begin{figure}
\begin{centering}
\includegraphics[width=1\textwidth]{img/screenshots/SIMPL_BPEL_Designer.JPG}
\par\end{centering}

\caption{\label{fig:SIMPL-Referenzvariablen}Um Referenzvariablen erweiterter
Eclipse BPEL Designer}

\end{figure}


Das rot umrandete Symbol in der Toolbar stößt die Transformation eines
Prozesses mit Referenzvariablen an. Was genau während der Transformation
geschieht und wie diese durchgeführt wird, wird in Kapitel \ref{sub:Transformation-des-Modells}
beschrieben. Damit Referenzvariablen überhaupt modelliert werden können,
muss ein neuer Variablentyp in BPEL eingeführt werden. Da Referenzvariablen
eine ähnliche Struktur wie Standard-BPEL-Variablen haben, werden Referenzvariablen
analog realisiert. Listing \ref{lst:ReferenzVariable} zeigt die Struktur
einer Referenzvariablen sowie deren Container (\emph{bpel:referenceVariables}).
Eine Referenzvariable hat dabei immer einen Namen (\emph{name}), einen
Referenztyp (\emph{referenceType}) und einen Werttyp (\emph{valueType}).
Die anderen Attribute wurden nicht in die Benutzeroberfläche integriert,
sind aber im Modell vorhanden, sodass durch eine Erweiterung der Benutzeroberfläche
diese Attribute verwendet werden können. Die Bedeutung der einzelnen
Attribute liefert Kapitel \ref{sub:Realisierung-von-Referenzen}.

Die Zuordnung zwischen Referenzvariablen und Referenzen wird über
den Namen realisiert, d.h. eine Referenzvariable mit dem Namen {}``myData''
wird bei der Transformation auf die gleichnamige Referenz (logischer
Namen) abgebildet. Der Hintergrund dafür ist, dass die Zuweisung automatisch
abläuft und keine weiteren Attribute in den Referenzvariablen zur
Angabe einer Referenz benötigt werden.

Analog zu den Standard-BPEL-Variablen können durch die Erweiterung
nun Referenzvariablen erzeugt, ausgewählt und gelöscht werden (siehe
rot umrandeter Bereich in Abbildung \ref{fig:SIMPL-Referenzvariablen}).
Nachdem eine Referenzvariable erstellt oder ausgewählt ist, können
deren Attribute in der Properties-View gesetzt werden (siehe Abbildung
\ref{fig:SIMPL-Referenzvariablen} unten). Dabei kann als Referenztyp
\emph{onInstantiation} oder \emph{fresh} ausgewählt werden und der
Werttyp über den Browse-Button analog wie bei Standard-BPEL-Variablen
gesetzt werden. Damit man auch Referenzvariablen in Kommunikationsaktivitäten
(Invoke, Reply und Receive) verwenden kann, wurde der Eclipse BPEL
Designer entsprechend erweitert, sodass auch Referenzvariablen bei
der Modellierung zur Auswahl stehen. Generell sind die durchgeführten
Erweiterungen nur eine Übergangslösung, da das zugrundeliegende BPEL-Modell
nicht für mehrere verschiedene Variablenarten ausgelegt ist und sich
dies auch in der Implementierung des Eclipse BPEL Designer niederschlägt.
Eine mögliche Lösung dieses Problems würde die Umstrukturierung des
zugrundeliegenden BPEL-Modells liefern. D.h. man sollte alle gemeinsamen
Eigenschaften von Referenzvariablen und Standard-BPEL-Variablen in
einer Oberklasse abstrahieren, sodass generell zwischen verschiedenen
Variablenarten unterschieden werden kann und so auch die Implementierung
übersichtlicher, konsistenter und in Zukunft einfacher erweiterbar
wird.

\begin{center}

\begin{lstlisting}[caption={Schema der ReferenceVariables- und ReferenceVariable-Elemente},label={lst:ReferenzVariable},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=2cm,xrightmargin=2cm]
<bpel:referenceVariables>
    <bpel:referenceVariable 
        name = "xsd:string"
        referenceType = "bpel:ReferenceType"
        valueType = "xsd:schema"
        period = "duration"
        external = "partnerLink">
    </bpel:referenceVariable>
</bpel:referenceVariables>

\end{lstlisting}

\par\end{center}


\subsubsection{\label{sub:ODE-Deployment-Deskriptor}ODE Deployment-Deskriptor}

Über den ODE Deployment-Deskriptor sollen in Zukunft Daten für DM-Aktivitäten
eines BPEL-Prozesses, wie z.B. Datenquellen-Informationen, Auditing-Parameter
und die Zuordnung von Late-Binding Strategien und Policies, spezifiziert
werden. Abbildung \ref{fig:SIMPL-DD} zeigt die Benutzeroberfläche
des erweiterten DD (Deployment-Deskriptors). Das erweiterte Schema
des DDs zeigt Listing \ref{lst:DD-Schema}. Das Attribut \emph{attachedUddiAddress}
wird im Hintergrund auf den in den Einstellungen hinterlegten Wert
der UDDI-Adresse gesetzt. Dies ist notwendig, damit in ODE zur Laufzeit
die Adresse der angebundenen UDDI bekannt ist und das Late-Binding
sowie statisch angebundene UDDI-Datenquellen verwendet werden können. 

Im erweiterten DD können nun Datenquellen-Informationen wie die physikalische
Adresse, der Typ, der Subtyp, die Abfragesprache, das Datenformat
und Authentifizierungsinformationen (Benutzername, Passwort) einer
Datenquelle (siehe Listing \ref{lst:DD-Datenquelle}) an einen logischen
Namen gebunden werden. Dieser logische Namen kann dann später einfach
in jeder DM-Aktivität ausgewählt werden und die entsprechenden Parameter
werden automatisch in der Aktivität gesetzt. Die Datenquellen-Einträge
können über entsprechende Dialoge angelegt oder editiert werden (siehe
Abbildung \ref{fig:SIMPL-DD-AddDS}). 

Ebenso kann im erweiterten DD das Late-Binding von Datenquellen realisiert
werden. Dazu werden über entsprechende Dialoge (siehe Abbildung \ref{fig:SIMPL-DD-AddAM})
sogenannte Activity-Mappings angelegt oder editiert. In einem Activity-Mapping
(siehe Listing \ref{lst:DD-Activity-Mapping}) wird eine DM-Aktivität
aus dem zugrundeliegenden Prozessmodell ausgewählt und mit einer Strategie
und einer Policy-Datei verknüpft. Die Strategie kann direkt und die
Policy-Datei über einen entsprechenden Datei-Browser ausgewählt werden.
Die Daten der Policy-Datei werden im DD hinterlegt und können so beim
Deployment ausgelesen werden. Der Inhalt der Policy-Dateien muss dabei
den in Kapitel \ref{sub:Datenquellen-Policies} vorgegebenen Konventionen
entsprechen.

Im erweiterten DD kann auch das Auditing für das aktuell modellierte
Prozessmodell aktiviert und deaktiviert werden. Der Unterschied zur
(De-)Aktivierung des Auditings in der SIMPL Admin-Konsole (siehe Kapitel
) liegt darin, dass hier das Auditing für einzelne Prozessmodelle
(de-)aktiviert werden kann, wobei über die Admin-Konsole das Auditing
für alle deployten Prozessmodelle (de-)aktiviert wird.

%
\begin{figure}
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/SIMPL_DeploymentDeskriptor.JPG}
\par\end{centering}

\caption{\label{fig:SIMPL-DD}Erweiterter Deployment-Deskriptor}

\end{figure}


\begin{center}

\begin{lstlisting}[caption={Schema des erweiterten Deployment-Deskriptors},label={lst:DD-Schema},basicstyle={\small\ttfamily},captionpos=b,float,frame=single,tabsize=4,xleftmargin=2cm,xrightmargin=2cm]
<process name = "xsd:string" attachedUddiAddress =
    "xsd:string">

    <datasources*/>     
    <activityMappings*/>          
    <auditing>xsd:boolean</auditing>

    standard-deployment-descriptor-elements

</process>

\end{lstlisting}

\par\end{center}

%
\begin{figure}
\begin{centering}
\includegraphics[width=0.6\textwidth]{img/screenshots/SIMPL_DD_AddDS.JPG}
\par\end{centering}

\caption{\label{fig:SIMPL-DD-AddDS}Dialog für das Hinzufügen einer Datenquellen-Beschreibung}

\end{figure}


\begin{center}

\begin{lstlisting}[caption={Schema der im Deployment-Deskriptor hinterlegten
Datenquelleninformationen},label={lst:DD-Datenquelle},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=2cm,xrightmargin=2cm]
<datasources dataSourceName = "xsd:string" 
    address = "xsd:string" type = "xsd:string"
    subtype = "xsd:string" language = "xsd:string"
    userName = "xsd:string" password = "xsd:string"
    format = "xsd:string"/>

\end{lstlisting}

\par\end{center}

%
\begin{figure}
\begin{centering}
\includegraphics[width=0.6\textwidth]{img/screenshots/SIMPL_DD_AddAM.JPG}
\par\end{centering}

\caption{\label{fig:SIMPL-DD-AddAM}Dialog für das Hinzufügen eines Activity
Mappings}

\end{figure}


\begin{center}

\begin{lstlisting}[caption={Schema der im Deployment-Deskriptor
hinterlegten Activity Mappings},label={lst:DD-Activity-Mapping},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=2cm,xrightmargin=2cm]
<activityMappings activity = "xsd:string" 
    strategy = "dd:STRATEGY_TYPE">       
    
    <policy policyData = "xsd:string" 
        localPath = "xsd:string"/>

</activityMappings>

\end{lstlisting}

\par\end{center}


\subsection{Benutzeroberfläche der SIMPL Eclipse Plug-Ins}

In diesem Kapitel wird die grafische Benutzeroberfläche der SIMPL
Eclipse Plug-Ins beschrieben. Abbildung \ref{fig:SIMPL-Men=0000FC}
zeigt den erweiterten Eclipse BPEL Designer und das SIMPL Menü. In
der Palette befinden sich die SIMPL DM-Aktivitäten, die wie bereits
vorhandene Aktivitäten zur Modellierung von Prozessen verwendet werden
können. Weiterhin wird das SIMPL Menü bereitgestellt, über das alle
wichtigen Einstellungen und Informationen des SIMPL Rahmenwerks vorgenommen
bzw. angezeigt werden können.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/SIMPL_Menü.JPG}
\par\end{centering}

\caption{\label{fig:SIMPL-Men=0000FC}SIMPL Menü und Eclipse BPEL Designer
mit einigen DM-Aktivitäten}

\end{figure}



\subsubsection{Admin-Konsole}

Die Admin-Konsole kann über das SIMPL Menü geöffnet werden und bietet
die Möglichkeit, Einstellungen für den SIMPL Core vorzunehmen. Dazu
gehört die Verwaltung des Auditings (siehe Abbildung \ref{fig:Auditing-Einstellungen}). 

Folgende Schaltflächen stehen durchgängig zur Verfügung:
\begin{itemize}
\item {[}Default{]}: Laden der Standard-Einstellungen
\item {[}Save{]}: Speichern aller durchgeführten Änderungen
\item {[}Reset{]}: Zurücksetzen aller durchgeführten Änderungen auf den
letzten Speicherstand
\item {[}Close{]}: Schließen der Admin-Konsole und Verwerfen aller Änderungen
\end{itemize}

\subsubsection*{Auditing}

In Abbildung \ref{fig:Auditing-Einstellungen} wird der Unterpunkt
{}``Auditing'' der Admin-Konsole gezeigt. Hier kann das Auditing
an- und abgeschaltet werden und eine Datenbank (analog wie im Deployment-Deskriptor)
für das Auditing angegeben werden.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/AdminConsole.JPG}
\par\end{centering}

\caption{\label{fig:Auditing-Einstellungen}Dialog für die Einstellungen des
Auditings}

\end{figure}



\subsubsection{Einstellungen der SIMPL Eclipse Plug-Ins}

Die Einstellungen können über das SIMPL Menü mit dem Menüpunkt {}``Settings''
geöffnet werden und bieten die Möglichkeit, Einstellungen für die
SIMPL Eclipse Plug-Ins vorzunehmen. Dazu gehört die Angabe der Adressen
der SIMPL Core Web Services, der UDDI Registry, eines RRS und des
Transformation Web Services (siehe Abbildung \ref{fig:Settings}).
Die Einstellungen werden als Eclipse Preferences integriert und stehen
als solche auch über Eclipse zur Verfügung (Eclipse Menüleiste ->
{}``Window'' -> {}``Preferences''). Über das SIMPL Menü erreicht
man direkt die SIMPL Preference Seite.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/SIMPL_Preferences.JPG}
\par\end{centering}

\caption{\label{fig:Settings}SIMPL Preference Seiten}

\end{figure}



\subsubsection{Hilfe}

Der Menüpunkt {}``Help'' leitet den Benutzer auf die Eclipse Hilfe
weiter. Dort stehen dem Benutzer über die Punkte {}``BPEL-DM Plug-In''
und {}``SIMPL Core Plug-In'' die entsprechenden Hilfe-Dokumente
der SIMPL Eclipse Plug-Ins zur Verfügung. Eine genauere Beschreibung
wird nachgeliefert, sobald die Umsetzung der Hilfe und deren Inhalt
konkret feststeht.


\subsubsection{About}

Der Menüpunkt {}``About'' öffnet das SIMPL About-Fenster, in dem
Informationen über den Versionsstand, Lizenzbedingungen, die Projekt-Homepage
und das Projektteam des SIMPL Rahmenwerks aufgeführt sind.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/SIMPL_About.JPG}
\par\end{centering}

\caption{\label{fig:About-Window}SIMPL About Fenster}

\end{figure}



\subsubsection{Nachträgliches Laden der Plug-In Daten}

Über den Menüpunkt {}``Reload Plug-In Data'' in Abbildung \ref{fig:SIMPL-Men=0000FC}
des SIMPL Menüs, können alle Daten des SIMPL Cores nachträglich abgerufen
werden. Dies ist aus folgenden Gründen nötig:
\begin{itemize}
\item Der Deployment-Deskriptor des erweiterten BPEL Designers ruft eine
Liste von unterstützten Datenquellentypen, deren Subtypen, den von
diesen unterstützten Abfragesprachen und deren Datenformaten ab. Diese
Informationen werden dann in den Dialogen (siehe Abschnitt \ref{sub:ODE-Deployment-Deskriptor})
beim Anlegen oder Editieren von Datenquellen angezeigt und können
dort ausgewählt werden.
\item Das SIMPL Core Plug-In ruft die Einstellungen des SIMPL Cores ab,
um diese in der Admin-Konsole anzeigen zu können.
\end{itemize}
Die Abfrage der entsprechenden Informationen geschieht bei der Initialisierung
der Plug-Ins, d.h. beim Start von Eclipse. Ist zu diesem Zeitpunkt
nun kein Apache Tomcat Server mit angebundenem SIMPL Core gestartet,
können die Informationen nicht abgerufen werden und die beiden Plug-Ins
sind nicht voll funktionsfähig. Um nun Eclipse nicht neustarten zu
müssen, gibt es den Menüpunkt {}``Reload Plug-In Data'', mit dem
die benötigten Informationen nachträglich vom SIMPL Core abgefragt
werden können.


\subsubsection{\label{sub:Data-Management-Aktivit=0000E4ten-GUI}Data-Management-Aktivitäten}

In Abbildung \ref{fig:Eigenschaftsfenster-einer-Data-Management-Aktivit=0000E4t}
wird die {}``PropertyView'' am Beispiel einer Query-Aktivität (siehe
Abschnitt \ref{sub:Resultierende-BPEL-Aktivit=0000E4ten}) gezeigt.
Hier kann die im Prozess ausgewählte Aktivität parametrisiert werden.
Das bedeutet, dass die Aktivität hier mit Inhalt gefüllt wird, wie
z.B. der Zieldatenquelle oder dem Befehl, der auf dieser ausgeführt
werden soll. Dazu wird eine UDDI- oder DD-Datenquelle über ihren logischen
Namen ausgewählt und ein Befehl über entsprechende grafische Elemente
oder auch einfach in der Text-Form erstellt. Durch die Auswahl einer
Datenquelle werden alle Datenquelleninformationen automatisch in der
Aktivität gesetzt.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/screenshots/SIMPL_DM_PropertySection.JPG}
\par\end{centering}

\caption{\label{fig:Eigenschaftsfenster-einer-Data-Management-Aktivit=0000E4t}Eigenschaftsfenster
einer DM-Aktivität am Beispiel einer Query Activity}

\end{figure}



\subsection{Benutzeroberfläche des RRS Eclipse Plug-Ins}

Das RRS Eclipse Plug-In wird als Eclipse View in Eclipse integriert.
Über diese View kann das in den SIMPL Settings hinterlegte RRS verwaltet
werden. Zur Verwaltung zählt das Anlegen, Bearbeiten und Löschen von
Referenzen eines RRSs. Abbildung \ref{fig:RRS-View} zeigt die View
des RRS Eclipse Plug-Ins. Die verschiedenen Verwaltungsfunktionen
können über das Kontextmenü oder über die Toolbar der View erreicht
werden. Da ein RRS nicht nur von einem Modellierer verwendet werden
kann oder auch Referenzen von Workflows oder Web Services erzeugt
werden können, enthält die View einen Refresh-Button mithilfe dessen
die Daten der View aktualisiert werden können.

%
\begin{figure}
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/RRS_View.JPG}
\par\end{centering}

\caption{\label{fig:RRS-View}Reference Resolution System View}

\end{figure}


Abbildung \ref{fig:RRS-ADD-REF} zeigt den Dialog für das Erstellen
einer neuen Referenz. Dabei werden wieder alle Angaben mit einem logischen
Namen verknüpft, der für die Bindung von Referenzvariablen und Referenzen
benötigt wird (siehe Kapitel \ref{sub:Erweiterungen-zur-Integration-Ref}).
Die RRS-Adresse wird automatisch aus den Preferences ausgelesen und
ist nicht änderbar. Die Adresse des Adapters, der die Referenz auflöst,
kann einfach ausgewählt werden. Der Mechanismus dafür entspricht dem
des SIMPL Core, da die Architektur des RRS ähnlich strukturiert ist
(Plug-In System). Die physikalische Datenquellenadresse muss zusammen
mit den Authentifizierungsinformationen von Hand eingegeben werden.
Für die Zukunft wäre hier die Anbindung einer Datenquellen-Registry
möglich, sodass eine Datenquelle per Late-Binding oder statisch ausgewählt
werden kann, ohne Daten von Hand angeben zu müssen. Der hinterlegte
Abfragebefehl wird bei der Auflösung der Referenz durch den angegebenen
Adapter ausgeführt und so die entsprechenden Daten zurückgeliefert.

%
\begin{figure}
\begin{centering}
\includegraphics[width=0.6\textwidth]{img/screenshots/RRS_AddRef.JPG}
\par\end{centering}

\caption{\label{fig:RRS-ADD-REF}Dialog für das Hinzufügen einer Referenz}

\end{figure}



\subsection{Benutzeroberfläche der Datenquellen-Registry}

In diesem Kapitel wird die Benutzeroberfläche des Eclipse Datenquellen-Registry
Plug-Ins und des Datenquellen-Registry Web Interfaces beschrieben.


\subsubsection{Datenquellen-Registry Plug-In}

Das Datenquellen-Registry Plug-In wird als Eclipse View in Eclipse
integriert. Die Datenquellen-Informationen werden aus der Datenquellen-Registry
gelesen und in einer Tabelle in der View angezeigt (siehe Abildung
\ref{fig:Datenquellen-Registry-View}).

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/UDDI_View.JPG}
\par\end{centering}

\caption{\label{fig:Datenquellen-Registry-View}Datenquellen-Registry View}

\end{figure}



\subsection{\label{sub:UDDI-Web-Interface}UDDI Web Interface}

\noindent Das UDDI Web Interface besteht aus den Komponenten: Konfiguration,
Datenquellenliste und Datenquelleneditor. Alle drei Komponenten werden
im folgenden noch einmal näher beschrieben.


\subsubsection{Konfiguration}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.8]{img/screenshots/indexscreen.JPG}
\par\end{centering}

\caption{\label{fig:Uddi-Web-Inteface-Index}UDDI Web Inteface Index}



\end{figure}


\noindent In der Konfiguration (\ref{fig:Uddi-Web-Inteface-Index})
können grundlegende Informationen, wie die Adresse der Datenquellen-Registry,
sowie Name und Passwort, die für die Schreibzugriffe verwendet werden,
hinterlegt werden können. Diese Informationen werden im Web-Apps\textbackslash{}conf
Verzeichniss des Web Interfaces gespeichert. Beim Speichern der Konfiguration,
wird Automatisch die Verfügbarkeit der UDDI-Registry unter der angegeben
Adresse überprüft.


\subsubsection{Datenquellenliste}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.8]{img/screenshots/datasourcelist.JPG}
\par\end{centering}

\caption{\label{fig:Uddi-Web-Interface-Datenquellenliste}UDDI Web Interface
Datenquellenliste}



\end{figure}


\noindent In der Datenquellenliste (\ref{fig:Uddi-Web-Interface-Datenquellenliste})
werden alle Verfügbaren Datenquellen und die grundlegenden Informationen
angezeigt. Dort können außerdem Datenquellen neu erstellt werden oder
nach Auswahl einer Datenquelle diese Editiert oder Gelöscht werden.


\subsubsection{Datenquelleneditor}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.8]{img/screenshots/edit.JPG}
\par\end{centering}

\caption{\label{fig:Uddi-Web-Interface-Editor}UDDI Web Interface Editor}



\end{figure}


\noindent Der Datenquelleneditor (\ref{fig:Uddi-Web-Interface-Editor})
wird aufgerufen, wenn eine Datenquelle neu erstellt oder editiert
wird. Alle wichtigen Informationen können dort über Textfelder eingegeben
werden und direkt in der Datenquellen-Registry gespeichert werden.
Die Datenquelle benötigt dabei folgende Informationen.
\begin{itemize}
\item Name: Ein Name für die Datenquelle, der innerhalb der Registry eindeutig
sein muss. Auf Grundlage des Namens wird der Key, der zur internen
Datenverwaltung benötigt wird, generiert.
\item Address: Die Adresse unter der die Datenquelle aufgerufen werden kann.
\item Type: Der Typ der Datenquelle (Database, Filesystem usw.)
\item Subtype: Der Subtyp der Datenquelle (RDB, ext3, usw.)
\item Policy: Der genaue Pfad zu einer Policy-Datei, die die nicht funktionalen
Anforderungen für die Datenquelle beschreibt.
\item Username: Der Benutzername, der benötigt wird um auf die Datenquelle
zuzugreifen.
\item Passwort: Das Passwort, das benötigt wird um auf die Datenquelle zuzugreifen.
\end{itemize}
\pagebreak{}


\section{\label{sec:Akteure}Akteure}

In diesem Kapitel werden die einzelnen Akteure der Software beschrieben
und ihre Abhängigkeiten untereinander definiert.


\subsection{Prozess-Modellierer}

Ein Prozess-Modellierer besitzt Fachwissen (z.B. aus der Biologie),
das er bei der Modellierung eines wissenschaftlichen Workflows verwendet.
Zur Modellierung der Workflows nutzt er den Eclipse BPEL Designer.
Dazu kann er beispielsweise BPEL-Aktivitäten erstellen, bearbeiten
und auch löschen. Hat der Prozess-Modellierer den BPEL-Prozess fertig
modelliert, kann er diesen im Anschluss auf einer Workflow-Engine
deployen und danach ausführen lassen.


\subsection{Workflow-Administrator}

Ein Workflow-Administrator ist eine Spezialisierung des Prozess-Modellierers.
D.h. er kann alle Anwendungsfälle des Prozess-Modellierers und noch
weitere administrative Anwendungsfälle ausführen. Seine Kenntnisse
liegen eher im technischen Bereich, wie z.B. bei der Konfiguration
des Rahmenwerks. Er kann beispielsweise über die Admin-Konsole während
der Prozesslaufzeit das Auditing an- und abschalten. Ebenso legt er
die Datenbank für das Speichern der Auditing-Daten fest.


\subsection{ODE Workflow-Engine}

Die ODE Workflow-Engine ist ein durch Software realisierter Akteur.
Sie führt interne Anwendungsfälle aus, die von einem Benutzer durch
andere Anwendungsfälle indirekt aufgerufen werden. Durch die Erweiterungen
kann sie DM-Aktivitäten ausführen und zurücksetzen.


\subsection{Eclipse BPEL Designer}

Der Eclipse BPEL Designer ist ebenfalls ein durch Software realisierter
Akteur. Er führt interne Anwendungsfälle aus, die von einem Benutzer
durch andere Anwendungsfälle indirekt aufgerufen werden. Der Eclipse
BPEL Designer sorgt für das Laden der Einstellungen der Admin-Konsole
und das Speichern dieser nach Änderungen. Weiterhin ist er für das
Validieren von SIMPL Extensions zuständig.


\subsection{Reference Resolution System}

Das Reference Resolution System (RRS) ist ebenfalls ein durch Software
realisierter Akteur. Es führt interne Anwendungsfälle aus, die von
einem Benutzer durch andere Anwendungsfälle indirekt aufgerufen werden.
Das RRS sorgt für das automatische Auflösen von Referenzen zur Laufzeit
von Prozessinstanzen und realisiert die Verwaltung (Erstellen, Bearbeiten
und Löschen) von Referenzen.


\subsection{Datenquellen-Administrator}

Ein Datenquellen-Administrator verwaltet Datenquellen und stellt diese
über die Datenquellen-Registry anderen Nutzern zu Verfügung. Dazu
kann er Datenquellen in der Datenquellen-Registry registrieren, die
Eigenschaften bereits registrierter Datenquellen bearbeiten und registrierte
Datenquellen auch wieder aus der Datenquellen-Registry löschen.

\pagebreak{}


\section{\label{sec:Anwendungsf=0000E4lle-(Use-Cases)}Anwendungsfälle (Use-Cases)}

Dieses Kapitel beschreibt die funktionalen Anforderungen an die Software.
Dazu werden alle Anwendungsfälle eines jeden Akteurs, die durch das
SIMPL Rahmenwerk neu hinzukommen, beschrieben und deren Zusammenhänge
in entsprechenden Diagrammen graphisch dargestellt. Das heißt, dass
bereits durch vorhandene Software (z.B. Eclipse BPEL Designer) realisierte
Anwendungsfälle nicht aufgeführt und beschrieben werden. Für die persistente
Speicherung der Admin-Konsolen Einstellungen wird vorerst eine Apache
Derby Datenbank verwendet, die im nachfolgenden als SIMPL DB bezeichnet
wird. Die SIMPL-Einstellungen werden nicht durch einen Use-Case beschrieben,
da diese vollständig den Eclips eigenen Einstellungen entsprechen
und nur als neue Unterpunkte dieser realisiert werden.




\subsection{Diagramm der Anwendungsfälle}

Abbildung \ref{fig:Gesamt-Anwendungsfall-Diagramm} zeigt das Diagramm
aller Anwendungsfälle der gesamten Software. Dadurch sollen die Funktionalität
und die Akteure des späteren Gesamtsystems sichtbar werden. Die einzelnen
Anwendungsfälle der verschiedenen Akteure werden in den folgenden
Abschnitten näher beschrieben.



%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/Overview_iter2}
\par\end{centering}

\caption{\label{fig:Gesamt-Anwendungsfall-Diagramm}Anwendungsfall-Diagramm
des gesamten Softwaresystems}

\end{figure}


\pagebreak{}


\subsection{Anwendungsfälle des Prozess-Modellierers}

Ein Prozess-Modellierer kann folgende neue Anwendungsfälle (siehe
Abbildung \ref{fig:UseCaseDiaProzessModell}) ausführen:


\begin{itemize}
\item Data-Management-Aktivität erstellen
\item Data-Management-Aktivität bearbeiten
\item Data-Management-Aktivität löschen
\item ODE Deployment-Deskriptor erstellen
\item ODE Deployment-Deskriptor bearbeiten
\item ODE Deployment-Deskriptor löschen
\item Prozess auf ODE-Server deployen
\item Prozessinstanz starten
\item Strategie für das Late-Binding auswählen
\item Neue Referenz in RRS einfügen
\item Referenz aus RRS bearbeiten
\item Referenz aus RRS löschen
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/ProzessModellierer_iter2}
\par\end{centering}

\caption{\label{fig:UseCaseDiaProzessModell}Anwendungsfall-Diagramm für den
Prozess-Modellierer}

\end{figure}



\subsubsection{Data-Management-Aktivität erstellen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Erstellung einer neuen DM-Aktivität.\tabularnewline
\hline
\hline 
Vorbedingung & Ein vorhandener BPEL-Prozess ist im Eclipse BPEL Designer geöffnet
und die BPEL Designer-Palette wird angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung & Die erstellte DM-Aktivität wurde an der selektierten Position in den
Prozess eingefügt, und der vom Benutzer eingegebene Name wird angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Die erstellte DM-Aktivität wurde an der selektierten Position in den
Prozess eingefügt, und der vom Eclipse BPEL Designer vorgeschlagene
Name wird angezeigt.\tabularnewline
\hline
\hline 
Normalablauf & 1a. Selektion einer DM-Aktivität aus der BPEL Designer Palette durch
Auswahl mit der linken Maustaste und anschließend Selektion der Stelle
des Prozesses, an der die ausgewählte DM-Aktivität eingefügt werden
soll, mit der linken Maustaste.

1b. (alternativ) Drag\&Drop einer DM-Aktivität aus der Palette an
die gewünschte Stelle im Prozess.

2. Eingabe eines Aktivitätsnamens durch den Benutzer.\tabularnewline
\hline
\hline 
Sonderfälle & 2a. Der angezeigte Namensvorschlag wird vom Benutzer bestätigt.\tabularnewline
\hline
\end{tabular}


\subsubsection{Data-Management-Aktivität bearbeiten}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Bearbeitung der Eigenschaften einer vorhandenen DM-Aktivität.\tabularnewline
\hline
\hline 
Vorbedingung & Ein vorhandener BPEL-Prozess mit mindestens einer DM-Aktivität ist
im Eclipse BPEL Designer geöffnet und eine Datenquelle wurde im Deployment-Deskriptor
für diesen Prozess spezifiziert.\tabularnewline
\hline
\hline 
Nachbedingung & Alle durchgeführten Änderungen der Eigenschaften der ausgewählten
DM-Aktivität wurden korrekt übernommen und werden in der {}``Properties-View''
angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Es konnten keine Änderungen bezüglich der Datenquelle getätigt werden
und der Statement-Editor zum Erstellen von Statements konnte nicht
geöffnet werden. Änderungen der anderen Eigenschaften wurden korrekt
übernommen und werden in der {}``Properties-View'' angezeigt.\tabularnewline
\hline
\hline 
Normalablauf & 1. Selektierung einer DM-Aktivität aus dem Prozess durch Auswahl mit
der linken Maustaste.

2. Öffnen der {}``Properties-View'' der DM-Aktivität um ihre Eigenschaften
anzuzeigen.

3. Änderung der Eigenschaften der DM-Aktivität.\tabularnewline
\hline
\hline 
Sonderfälle & 3.a Im Deplyoment-Deskriptor wurde keine Datenquelle für den Prozess
spezifiziert.\tabularnewline
\hline
\end{tabular}


\subsubsection{Data-Management-Aktivität löschen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Löschen einer DM-Aktivität.\tabularnewline
\hline
\hline 
Vorbedingung & Ein vorhandener BPEL-Prozess mit mindestens einer DM-Aktivität ist
im Eclipse BPEL Designer geöffnet.\tabularnewline
\hline
\hline 
Nachbedingung & Die ausgewählte DM-Aktivität wurde vollständig und korrekt aus dem
Prozess gelöscht. Alle ausgehenden und eingehenden Links werden entsprechend
dem Standardverhalten des Eclipse BPEL Designers neu gesetzt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1a. Selektierung einer DM-Aktivität aus dem Prozess durch Auswahl
mit der linken Maustaste.

1b. Öffnen des Kontextmenüs durch rechten Mausklick auf eine DM-Aktivität.

2a. Löschen der DM-Aktivität durch drücken der {}``entf''-Taste.

2b. Mausklick auf den Menüpunkt {}``Delete'' des Kontextmenüs.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{ODE Deployment-Deskriptor erstellen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Ein ODE Deployment-Deskriptor soll für einen Prozess erstellt werden.\tabularnewline
\hline
\hline 
Vorbedingung & Ein korrekter BPEL Prozess liegt vor.\tabularnewline
\hline
\hline 
Nachbedingung & Der ODE Deployment-Deskriptor wurde korrekt erstellt und der BPEL
Prozess kann deployt werden.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Der ODE Deployment-Deskriptor steht nicht zur Verfügung.\tabularnewline
\hline
\hline 
Normalablauf & 1. Erstellung eines ODE Deployment-Deskriptors über File->New->Other->BPEL2.0->Apache
ODE Deployment-Descriptor.

2. Konfiguration des Deployment-Deskriptors

3. Speicherung des Deployment-Deskriptors über File -> Save

\tabularnewline
\hline
\hline 
Sonderfälle & Der ODE Deployment-Deskriptor kann nicht erstellt werden.\tabularnewline
\hline
\end{tabular}


\subsubsection{ODE Deployment-Deskriptor bearbeiten}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Konfiguration des ODE Deployment-Deskriptors soll geändert werden.\tabularnewline
\hline
\hline 
Vorbedingung & Ein ODE Deployment-Deskriptor wurde korrekt erstellt.\tabularnewline
\hline
\hline 
Nachbedingung & Die Änderungen sind gespeichert und der ODE Deployment-Deskriptor
ist korrekt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Die Änderungen an der Konfiguration sind nicht gespeichert.\tabularnewline
\hline
\hline 
Normalablauf & 1. ODE Deployment-Deskriptor über Doppelklick mit der linken Maustaste
auf die Datei öffnen.

2. Tätigen der entsprechenden Änderungen

3. Speichern der Änderungen durch den Menüeintrag speichern oder Linksklick
auf das entsprechende Symbol.\tabularnewline
\hline
\hline 
Sonderfälle & Der ODE Deployment-Deskriptor kann nicht gespeichert werden.\tabularnewline
\hline
\end{tabular}


\subsubsection{ODE Deployment-Deskriptor löschen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Ein ODE Deployment-Deskriptor soll gelöscht werden.\tabularnewline
\hline
\hline 
Vorbedingung & Ein ODE Deployment -Deskriptor wurde korrekt erstellt.\tabularnewline
\hline
\hline 
Nachbedingung & Der ODE Deployment-Deskriptor ist gelöscht.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Der ODE Deployment-Deskriptor ist nicht gelöscht.\tabularnewline
\hline
\hline 
Normalablauf & 1. ODE Deployment-Deskriptor auswählen und über Edit->Delete löschen
oder alternativ Auswählen des Deployment-Deskriptors mit der linken
Maustaste und anschließendes Drücken von \textquotedbl{}Entf\textquotedbl{}.\tabularnewline
\hline
\hline 
Sonderfälle & Der ODE Deployment-Deskriptor kann nicht gelöscht werden.\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Prozess-auf-ODE-Server-deployen}Prozess auf ODE-Server
deployen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Deployen eines Prozesses auf der Apache ODE Workflow-Engine.\tabularnewline
\hline
\hline 
Vorbedingung & Ein Prozess ist im Eclipse BPEL Designer geöffnet, die Apache ODE
Workflow-Engine korrekt in Eclipse eingebunden, die Server-View wird
angezeigt und ein ODE Deployment-Descriktor wurde korrekt erstellt
bzw. ist bereits vorhanden.\tabularnewline
\hline
\hline 
Nachbedingung & Die Prozess-Dateien wurden auf die Apache ODE Workflow-Engine kopiert
und der Prozess wurde erfolgreich deployed.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & 2a. Der ODE-Server ist nicht gestartet und der Prozess wurde nicht
deployed.

2b. Der ODE-Server ist gestartet, aber der Prozess wurde nicht deployed.\tabularnewline
\hline
\hline 
Normalablauf & Es gibt mehrere Möglichkeite dies zu erledigen. Beispielhaft sei eine
erläutert :

1. Hinzufügen des Prozesses zum ODE-Server in der Eclipse Server-View:
\begin{itemize}
\item Rechter Mausklick auf den ODE-Server
\item Auswahl des Menüpunkts {}``Add and Remove''
\item Hinzufügen der BPEL Prozess-Datei
\end{itemize}
2. Starten des ODE-Servers über rechten Mausklick und klicken auf
{}``Start''.\tabularnewline
\hline
\hline 
Sonderfälle & 2a. ODE-Server startet nicht aufgrund eines Fehlers.

2b. Beim Deployen des Prozesses tritt ein Fehler auf.\tabularnewline
\hline
\end{tabular}


\subsubsection{Prozessinstanz starten }

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Start einer Prozessinstanz eines Prozessmodells auf der Apache ODE
Workflow-Engine.\tabularnewline
\hline
\hline 
Vorbedingung & Das Prozessmodell wurde erfolgreich auf der Apache ODE Workflow-Engine
deployt (siehe Anwendungsfall {}``\ref{sub:Prozess-auf-ODE-Server-deployen}
Prozess auf ODE-Server deployen'').\tabularnewline
\hline
\hline 
Nachbedingung & Prozessinstanz wurde gestartet.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Die Prozessinstanz wird verworfen.\tabularnewline
\hline
\hline 
Normalablauf & Instanzierung des Prozessmodells und Start der Prozessinstanz durch
Senden einer entsprechenden SOAP-Nachricht an den Endpunkt des Prozesses.
Es gibt mehrere Möglichkeiten. Beispielhaft wird eine erklärt :

1. Auswählen des WSDL Files

2. Auswahl von Web Services->Test with Web Service Explorer. im Kontextmenü.

3. Prozess auswählen und {}``Invoke a WSDL Operation'' öffen.

4. Im Textfenster unter {}`` Input string'' die Parameter eingeben
und mit {}``GO'' absenden.\tabularnewline
\hline
\hline 
Sonderfälle & 1a. Fehler beim Starten der Prozessinstanz, z.B. durch eine SOAP-Nachricht
mit falschem Inhalt.\tabularnewline
\hline
\end{tabular}


\subsubsection{Strategie für das Late-Binding auswählen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Auswahl einer Strategie für das Late-Binding einer Datenquelle in
einer DM-Aktivität.\tabularnewline
\hline
\hline 
Vorbedingung & Ein BPEL-Prozess mit ODE Deployment-Deskriptor und ein WS-Policy-Dokument
mit Anforderungen an die Datenquelle müssen erstellt sein. Der ODE
Deployment-Deskriptor muss geöffnet sein.\tabularnewline
\hline
\hline 
Nachbedingung & Die Strategie für eine DM-Aktivität ist im ODE Deployment-Deskriptor
hinterlegt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & \tabularnewline
\hline
\hline 
Normalablauf & 1. Auswahl einer DM-Aktivität aus der Liste mit DM-Aktivitäten.

2. Auswahl einer Strategie über das Strategie-Dropdown-Menü.

3. Auswahl einer WS-Policy-Datei über den Button {}``WS-Policy Datei
auswählen''.

4. Speichern des ODE Deployment-Deskriptor über das {}``Speichern''-Symbol
in der Symbolleiste.\tabularnewline
\hline
\hline 
Sonderfälle & \tabularnewline
\hline
\end{tabular}


\subsubsection{Neue Referenz in RRS einfügen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Eine neue Referenz soll ins RRS eingefügt werden.\tabularnewline
\hline
\hline 
Vorbedingung & Die RRS-View ist geöffnet und das RRS ist erreichbar.\tabularnewline
\hline
\hline 
Nachbedingung & Die neue Referenz wurde korrekt im RRS gespeichert und wird in der
RRS-View angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Es wird eine entsprechende Fehlermeldung angezeigt, die den Benutzer
über die aufgetretenen Fehler informiert.\tabularnewline
\hline
\hline 
Normalablauf & 1. Klick des {[}New{]} Buttons der Toolbar oder Auswahl des entsprechenden
Menü-Punktes des Kontext-Menüs

2. Angabe des Namens, des Statements, der Adresse der Datenquelle
und der Auswahl eines Adapters der Referenz in dem entsprechenden
Pop-up Fenster

3. Klick auf den Button {[}Save{]}.\tabularnewline
\hline
\hline 
Sonderfälle & 3a. Beim Speichern der neue Referenz tritt ein Fehler auf, da z.B.
das RRS nicht erreichbar ist.\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Referenz-aus-RRS l=0000F6schen}Referenz aus RRS löschen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Löschen einer vorhandenen Referenz aus dem RRS.\tabularnewline
\hline
\hline 
Vorbedingung & Die RRS-View ist geöffnet, das RRS ist erreichbar und die zu löschende
Referenz wurde ausgewählt.\tabularnewline
\hline
\hline 
Nachbedingung & Die entsprechende Referenz wurde vollständig und korrekt aus dem RRS
und der Referenzen-Tabelle entfernt und kann nun nicht mehr verwendet
werden.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Die zu löschende Referenz bleibt im RRS und in der Referenzen-Tabelle
unverändert und es wird eine entsprechende Fehlermeldung angezeigt,
die den Benutzer über die aufgetretenen Fehler informiert.\tabularnewline
\hline
\hline 
Normalablauf & 1. Klick des {[}Delete{]} Buttons der Toolbar oder Auswahl des entsprechenden
Menü-Punktes des Kontext-Menüs.\tabularnewline
\hline
\hline 
Sonderfälle & 1a. Beim Löschen der Referenz tritt ein Fehler auf, da z.B. das RRS
nicht erreichbar ist.\tabularnewline
\hline
\end{tabular}


\subsubsection{Referenz aus RRS bearbeiten}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Bearbeiten einer vorhandenen Referenz des RRS.\tabularnewline
\hline
\hline 
Vorbedingung & Die RRS-View ist geöffnet, das RRS ist erreichbar und die zu bearbeitende
Referenz ist ausgewählt.\tabularnewline
\hline
\hline 
Nachbedingung & Die geänderten Werte der Referenz wurden korrekt im RRS gespeichert,
die Referenz wurde aktualisiert und die aktualisierten Werte werden
in der Referenzen-Tabelle angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Die bearbeitete Referenz bleibt im RRS und in der Referenzen-Tabelle
unverändert und es wird eine entsprechende Fehlermeldung angezeigt,
die den Benutzer über die aufgetretenen Fehler informiert.\tabularnewline
\hline
\hline 
Normalablauf & 1. Klick des {[}Edit{]} Buttons der Toolbar oder Auswahl des entsprechenden
Menü-Punktes des Kontext-Menüs

2. Angabe der neuen Parameter der Referenz in dem entsprechenden Pop-up
Fenster

3. Klick auf den Button {[}Save{]}.\tabularnewline
\hline
\hline 
Sonderfälle & 3a. Beim Speichern der Änderungen tritt ein Fehler auf, da z.B. das
RRS nicht erreichbar ist.\tabularnewline
\hline
\end{tabular}


\subsection{Anwendungsfälle des Workflow-Administrators}

Ein Workflow-Administrator kann folgende neue Anwendungsfälle (siehe
Abbildung \ref{fig:UseCaseDiaWFAdmin}) ausführen:
\begin{itemize}
\item Admin-Konsole öffnen
\item Auditing aktivieren
\item Auditing deaktivieren
\item Auditing-Datenbank festlegen/ändern
\item Globale Einstellungen festlegen/ändern
\item Einstellungen der Admin-Konsole speichern
\item Einstellungen der Admin-Konsole zurücksetzen
\item Default-Einstellungen der Admin-Konsole laden
\item Admin-Konsole schließen
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/WorkflowAdmin_iter2}
\par\end{centering}

\caption{\label{fig:UseCaseDiaWFAdmin}Anwendungsfall-Diagramm für den Workflow-Administrator}

\end{figure}



\subsubsection{\label{sub:Admin-Konsole-=0000F6ffnen}Admin-Konsole öffnen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Öffnen der Admin-Konsole.\tabularnewline
\hline
\hline 
Vorbedingung & Eclipse mit dem SIMPL Core Plug-In und dem SIMPL Core Client Plug-In
ist geöffnet.\tabularnewline
\hline
\hline 
Nachbedingung & Anstoßen des Anwendungsfalls {}``\ref{sub:Admin-Konsole-laden} SIMPL
Admin-Konsole laden'' des Eclipse BPEL Designers.

Wenn der angestoßene Anwendungsfall erfolgreich ausgeführt wurde,
wird die Admin-Konsole mit einer Liste aller Menüpunkte (Auditing,
Global Settings) angezeigt und kann verwendet werden.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1. Klick auf das SIMPL Menü in der Menüleiste.

2. Klick auf den Menüeintrag {[}Admin Console{]}.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{Auditing aktivieren}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Auditing von SIMPL aktivieren.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole ist geöffnet, der Unterpunkt {}``Auditing'' wird
angezeigt und das Auditing-Häkchen ist nicht gesetzt.\tabularnewline
\hline
\hline 
Nachbedingung & Das Auditing-Häkchen ist gesetzt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1. Setzen des Auditing-Häkchens.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{Auditing deaktivieren}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Auditing von SIMPL deaktivieren.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole ist geöffnet, der Unterpunkt {}``Auditing'' wird
angezeigt und das Auditing-Häkchen ist gesetzt.\tabularnewline
\hline
\hline 
Nachbedingung & Das Auditing-Häkchen ist nicht gesetzt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1. Zurücksetzen des Auditing-Häkchens.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{Auditing-Datenbank festlegen/ändern}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Festlegung/Änderung einer Datenbank für das Speichern der Auditing-Informationen.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole ist geöffnet und der Unterpunkt {}``Auditing''
wird angezeigt. Das Auditing {}``Häkchen'' ist gesetzt.\tabularnewline
\hline
\hline 
Vorbedingung im Sonderfall & Die Admin-Konsole ist geöffnet und der Unterpunkt {}``Auditing''
wird angezeigt. Das Auditing {}``Häkchen'' ist nicht gesetzt.\tabularnewline
\hline
\hline 
Nachbedingung & Die festgelegte/geänderte Datenbank für das Auditing wird in der Admin-Konsole
angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Die festgelegte/geänderte Datenbank für das Auditing wird in der Admin-Konsole
angezeigt. Es erscheint ein Hinweis, dass das Auditing nicht aktiv
ist, und die Datenbank somit keine Daten erhält.\tabularnewline
\hline
\hline 
Normalablauf & 1. Angabe der Datenbank-Adresse über einen Unified Resource Locator
(URL) und alternativ die Auswahl einer Datenbank über die Datenbank-Registry).\tabularnewline
\hline
\end{tabular}


\subsubsection{Globale Einstellungen festlegen/ändern}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Festlegung/Ändern der globalen Einstellungen.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole ist geöffnet und der Unterpunkt {}``Global Settings''
wird angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung & Die festgelegten/geänderten globalen Einstellungen werden in der Admin-Konsole
angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1. Eingabe/Änderung der Werte in entsprechenden Textfeldern.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Einstellungen-der-Admin-Konsole-speichern}Einstellungen
der Admin-Konsole speichern}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Festlegung der in der Admin-Konsole getätigten/geänderten Einstellungen
und deren Speicherung in der SIMPL DB.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole wird angezeigt, und es wurde mindestens ein Wert
geändert.\tabularnewline
\hline
\hline 
Nachbedingung & Anwendungsfall {}``\ref{sub:Admin-Konsole-speichern} SIMPL Admin-Konsole
speichern'' des Eclipse BPEL Designers wird angestoßen.

Wenn der angestoßene Anwendungsfall erfolgreich ausgeführt wurde,
wurden alle Werte der Admin-Konsole korrekt gespeichert und alle veralteten
Werte mit den Neuen überschrieben. Die Festlegungen/ Änderungen wurden
in den Einstellungen entsprechend übernommen.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & 1a.\&1b. Der Benutzer erhält eine Fehlermeldung, die ihn über den
entsprechenden Fehler informiert. Die Änderungen werden verworfen
und so die Werte auf den letzten Speicherstand zurückgesetzt.\tabularnewline
\hline
\hline 
Normalablauf & 1. Klick auf den Button {[}Save{]}.\tabularnewline
\hline
\hline 
Sonderfälle & 1a. Das Auditing-Häkchen ist gesetzt, und vom Benutzer wurde keine
Auditing-Datenbank zum Speichern der Auditing-Daten festgelegt.

1b. Das Auditing-Häkchen ist gesetzt und eine Auditing-Datenbank angegeben.
Die angegebene Auditing-Datenbank kann aber nicht verwendet werden,
da sie z.B. nicht erreichbar ist oder die Authentifizierung fehlgeschlagen
ist.\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Einstellungen-der-Admin-Konsole-zur=0000FCcksetzen}Einstellungen
der Admin-Konsole zurücksetzen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Zurücksetzen des Inhalts der Admin-Konsole auf die zuletzt gespeicherten
Werte.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole wird angezeigt, und es wurde mindestens ein Wert
geändert.\tabularnewline
\hline
\hline 
Nachbedingung & Anstoßen des Anwendungsfalls {}``\ref{sub:Admin-Konsole-laden} SIMPL
Admin-Konsole laden'' des Eclipse BPEL Designers.

Wenn der angestoßene Anwendungsfall erfolgreich ausgeführt wurde,
wurden alle geänderten Werte der Admin-Konsole auf die zuletzt gespeicherten
Einstellungen zurückgesetzt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1. Klick auf den Button {[}Reset{]}.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Default-Einstellungen-der-Admin-Konsole-laden}Default-Einstellungen
der Admin-Konsole laden}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Laden der Standardwerte in der Admin-Konsole.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole wird angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung & Anstoßen des Anwendungsfalls {}``\ref{sub:Admin-Konsole-Defaults-laden}
SIMPL Admin-Konsole Defaults laden'' des Eclipse BPEL Designers.

Wenn der angestoßene Anwendungsfall erfolgreich ausgeführt wurde,
wurden alle Werte der Admin-Konsole auf die gespeicherten Standardwerte
zurückgesetzt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1. Klick auf den Button {[}Default{]}.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Admin-Konsole-schlie=0000DFen}Admin-Konsole schließen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Schließen der Admin-Konsole.\tabularnewline
\hline
\hline 
Vorbedingung & Die Admin-Konsole wird angezeigt. Es wurden keine Änderungen in der
Admin-Konsole seit dem letzten Speichervorgang durchgeführt.\tabularnewline
\hline
\hline 
Vorbedingung im Sonderfall & Die Admin-Konsole wird angezeigt. Es wurde mindestens ein Wert in
der Admin-Konsole seit dem letzten Speichervorgang geändert.\tabularnewline
\hline
\hline 
Nachbedingung & 1a. Die Admin-Konsole wurde geschlossen.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & 3b1. Der Anwendungsfall {}``\ref{sub:Admin-Konsole-speichern} SIMPL
Admin-Konsole speichern'' des Eclipse BPEL Designers wird angestoßen.
Wenn der angestoßene Anwendungsfall erfolgreich ausgeführt wurde,
wurden alle Festlegungen/Änderungen in den Einstellungen entsprechend
übernommen und gespeichert.

3b2. Die Admin-Konsole wurde geschlossen und alle Änderungen wurden
verworfen.

3b3. Die Admin-Konsole wird weiterhin angezeigt und alle geänderten
Werte bleiben erhalten.\tabularnewline
\hline
\hline 
Normalablauf & 1a. Klick auf den Button {[}Close{]}.

2b. Es öffnet sich ein Dialog mit einer Sicherheitsabfrage, ob der
Benutzer die durchgeführten Änderungen speichern möchte.

3b1. Klick auf den Button {[}Yes{]} des Dialogfensters.

3b2. Klick auf den Button {[}No{]} des Dialogfensters.

3b3. Klick auf den Button {[}Cancel{]} des Dialogfensters.\tabularnewline
\hline
\end{tabular}


\subsection{Anwendungsfälle der ODE Workflow-Engine}

Die ODE Workflow-Engine kann durch unsere Erweiterungen folgende Anwendungsfälle
(siehe Abbildung \ref{fig:UseCaseDiaODEWFEngine}) ausführen:
\begin{itemize}
\item Data-Management-Aktivität ausführen
\item Data-Management-Aktivität zurücksetzen
\item Datenquelle per Strategie auswählen
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/ODEwfEngine_iter2}
\par\end{centering}

\caption{\label{fig:UseCaseDiaODEWFEngine}Anwendungsfall-Diagramm für die
ODE Workflow-Engine}

\end{figure}



\subsubsection{\label{sub:Data-Management-Aktivit=0000E4t-ausf=0000FChren}Data-Management-Aktivität
ausführen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{13.5cm}|}
\hline 
Ziel & Ausführen einer DM-Aktivität.\tabularnewline
\hline
\hline 
Vorbedingung & Es wurde ein Prozess, der mindestens eine DM-Aktivität enthält, deployed
und es wurde eine Instanz des Prozesses erzeugt. Eine DM-Aktivität
wurde über den Kontrollfluss des Prozesses erreicht.\tabularnewline
\hline
\hline 
Nachbedingung & Die DM-Aktivität und die darin enthaltene Datenmanagementoperation
wurden erfolgreich ausgeführt.\tabularnewline
\hline
\hline 
Nachbedingung\\
im\\
Sonderfall & 1a. Die Aktivität befindet sich im Endzustand {}``Terminated''.

2a. Die Aktivität befindet sich im Endzustand {}``Terminated''.

4a. Die Aktivität befindet sich im Endzustand {}``Terminated''.\tabularnewline
\hline
\hline 
Normalablauf & 1. Die DM-Aktivität befindet sich im Zustand {}``Ready''.

2. Die Ausführung der DM-Aktivität wird gestartet.

3. Der Datasource Service des SIMPL Cores erhällt alle Informationen
die notwendig sind, damit die DM-Operationen durchgeführt werden können.

4. Die DM-Operation wurde in der Datenquelle erfolgreich ausgeführt,
und die Ausführung der DM-Aktivität ist damit beendet. Die DM-Aktivität
befindet sich im Zustand \textquotedbl{}Complete\textquotedbl{}.

5. Die nächste(n) Aktivität(en) im Kontrollfluss wird(/werden) initialisiert.\tabularnewline
\hline
\hline 
Sonderfälle & 1a.1. In der Vateraktivität tritt ein Fehler auf.

1a.2. Es wird ein {}``Terminate\_Activity Event'' von der Vateraktivität
an die entsprechende DM-Aktivität gesendet und die Aktivität wird
beendet.

1a.3. Der Use Case {}``\ref{sub:Data-Management-Aktivit=0000E4t-zur=0000FCcksetzen}
Data-Management-Aktivität zurücksetzen'' wird angestoßen.

2a.1. In der Vateraktivität tritt ein Fehler auf.

2a.2. Es wird ein {}``Terminate\_Activity Event'' von der Vateraktivität
an die entsprechende DM-Aktivität gesendet und die Aktivität wird
beendet.

2a.3. Der Use Case {}``\ref{sub:Data-Management-Aktivit=0000E4t-zur=0000FCcksetzen}
Data-Management-Aktivität zurücksetzen'' wird angestoßen.

3.1 Während der Ausführung der DM-Aktivität durch den Datasource Service
kommt es zu einem Fehler (z.B. ein Syntaxfehler, oder die Datenbank
ist nicht erreichbar, Verbindungsabbruch)

3.2. Der Use Case {}``\ref{sub:Data-Management-Aktivit=0000E4t-zur=0000FCcksetzen}
Data-Management-Aktivität zurücksetzen'' wird angestoßen.\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Data-Management-Aktivit=0000E4t-zur=0000FCcksetzen}Data-Management-Aktivität
zurücksetzen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Rückgängig machen einer laufenden DM-Aktivität, so dass der Zustand
der Datenquelle vor Ausführung der DM-Aktivität wiederhergestellt
wird. \tabularnewline
\hline
\hline 
Vorbedingung & Im Normalablauf einer DM-Aktivität tritt ein Fehler auf (siehe Sonderfälle
1.1, 2.1, und 3.1 des Anwendungsfalls {}``\ref{sub:Data-Management-Aktivit=0000E4t-ausf=0000FChren}
Data-Management-Aktivität ausführen'').\tabularnewline
\hline
\hline 
Nachbedingung & Der Zustand vor Ausführung der DM-Aktivität wurde erfolgreich wiederhergestellt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & keine\tabularnewline
\hline
\hline 
Normalablauf & 1. Alle Änderungen in der Datenquelle werden zurückgesetzt.\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsubsection{Datenquelle per Strategie auswählen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Eine Datenquelle wird Ausgewählt\tabularnewline
\hline
\hline 
Vorbedingung & Für die Datenquelle und die Automatische auswahl wurden WsPolicy's
erstellt und sind verfügbar\tabularnewline
\hline
\hline 
Nachbedingung & Eine Datenquelle wurde anhand einer Strategie ausgewählt\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & \tabularnewline
\hline
\hline 
Normalablauf & 1. Datenquellen Registry wird gelesen

2. Alle Policys der Datenquelle werden mit den Sucheigenschaften verglichen
und anhand der Strategie (first find) ausgewählt\tabularnewline
\hline
\hline 
Sonderfälle & keine\tabularnewline
\hline
\end{tabular}


\subsection{Anwendungsfälle des Eclipse BPEL Designers}

Der Eclipse BPEL Designer kann durch unsere Erweiterungen folgende
Anwendungsfälle (siehe Abbildung \ref{fig:UseCaseDiaBPELDesigner})
ausführen:
\begin{itemize}
\item SIMPL Admin-Konsole laden
\item SIMPL Admin-Konsole Defaults laden
\item SIMPL Admin-Konsole speichern
\item Datenquellen aus UDDI-Registry abrufen
\item BPEL-Datei transformieren
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/BPELdesigner_iter2}
\par\end{centering}

\caption{\label{fig:UseCaseDiaBPELDesigner}Anwendungsfall-Diagramm für den
Eclipse BPEL Designer}

\end{figure}



\subsubsection{\label{sub:Admin-Konsole-laden}SIMPL Admin-Konsole laden}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Laden der Inhalte der Admin-Konsole.\tabularnewline
\hline
\hline 
Vorbedingung & Einer der Anwendungsfälle {}``\ref{sub:Admin-Konsole-=0000F6ffnen}
Admin-Konsole öffnen'' oder {}``\ref{sub:Einstellungen-der-Admin-Konsole-zur=0000FCcksetzen}
Einstellungen der Admin-Konsole zurücksetzen'' wurde ausgeführt.\tabularnewline
\hline
\hline 
Nachbedingung & Alle Werte der SIMPL DB mit den aktuellen Einstellungen der Admin-Konsole
wurden geladen und werden im Fenster {}``Admin Console'' und dessen
Unterfenstern angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & 3a. Der Anwendungsfall {}``\ref{sub:Admin-Konsole-Defaults-laden}
SIMPL Admin-Konsole Defaults laden'' wird angestoßen. Wenn dieser
Anwendungsfall erfolgreich ausgeführt wurde, wurden die in der SIMPL-DB
hinterlegten Default-Einstellungen geladen und werden im Fenster {}``Admin
Console'' und dessen Unterfenstern angezeigt. Sollte ein Laden aus
der Datenquelle nicht möglich sein, werden die im Quellcode hinterlegten
Default-Einstellungen geladen.

3b. Die in der Admin-Konsole angezeigten Werte bleiben unverändert.
Falls zuvor keine Werte angezeigt wurden, bleiben die Felder der Admin-Konsole
leer.

\tabularnewline
\hline
\hline 
Normalablauf & 1. Laden aller zuletzt gespeicherten Werte aus der SIMPL DB.

2. Füllen der Felder der Admin-Konsole mit den geladenen Werten.\tabularnewline
\hline
\hline 
Sonderfälle & 1a. Beim Laden der Werte tritt ein Fehler auf, da z.B. die SIMPL DB
nicht erreichbar ist.

2a. Es wird eine entsprechende Fehlermeldung angezeigt und der Benutzer
wird über ein Dialogfenster gefragt, ob er die in der SIMPL DB hinterlegten
Default-Einstellungen laden möchte oder nicht.

3a. Klick auf den Button {[}Yes{]}.

3b. Klick auf den Button {[}No{]}.

\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Admin-Konsole-Defaults-laden}SIMPL Admin-Konsole Defaults
laden}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Laden der Default-Werte der Admin-Konsole.\tabularnewline
\hline
\hline 
Vorbedingung & Der Anwendungsfäll {}``\ref{sub:Default-Einstellungen-der-Admin-Konsole-laden}
Default-Einstellungen der Admin-Konsole laden'' oder der Sonderfall
\emph{3a} des Anwendungsfalls {}``\ref{sub:Admin-Konsole-laden}
SIMPL Admin-Konsole laden'' wurde ausgeführt.\tabularnewline
\hline
\hline 
Nachbedingung & Alle Werte der SIMPL DB mit den Default-Einstellungen der Admin-Konsole
wurden geladen und werden im Fenster {}``Admin Console'' und dessen
Unterfenstern angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Im Quellcode hinterlegte Default-Werte werden geladen und im Fenster
{}``Admin Console'' und dessen Unterfenstern angezeigt.\tabularnewline
\hline
\hline 
Normalablauf & 1. Laden aller Default-Werte aus der SIMPL DB.

2. Füllen der Felder der Admin-Konsole mit den geladenen Werten.\tabularnewline
\hline
\hline 
Sonderfälle & 1a. Beim Laden der Werte tritt ein Fehler auf, da z.B. die SIMPL DB
nicht erreichbar ist.

\tabularnewline
\hline
\end{tabular}


\subsubsection{\label{sub:Admin-Konsole-speichern}SIMPL Admin-Konsole speichern}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Persistente Speicherung der Einstellungen der Admin-Konsole.\tabularnewline
\hline
\hline 
Vorbedingung & Der Anwendungsfall {}``\ref{sub:Einstellungen-der-Admin-Konsole-speichern}
Einstellungen der Admin-Konsole speichern'' oder der Sonderfall \emph{3b1}
des Anwendungsfalls {}``\ref{sub:Admin-Konsole-schlie=0000DFen}
Admin-Konsole schließen'' wurde ausgeführt.\tabularnewline
\hline
\hline 
Nachbedingung & Alle Werte der Admin-Konsole wurden korrekt auf der SIMPL DB gespeichert.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & 1a. Alle geänderten Werte der Admin-Konsole werden nicht in der SIMPL
DB gespeichert. Es wird eine entsprechende Fehlermeldung angezeigt
und ein erneuter Speicherversuch kann durchgeführt werden. Die Werte
werden solange in der Admin-Konsole angezeigt, bis diese geschlossen
wird.\tabularnewline
\hline
\hline 
Normalablauf & 1. Speichern der Werte auf der SIMPL DB.\tabularnewline
\hline
\hline 
Sonderfälle & 1a. Beim Speichern der Werte tritt ein Fehler auf, da z.B. die SIMPL
DB nicht erreichbar ist.\tabularnewline
\hline
\end{tabular}


\subsubsection{Datenquellen aus UDDI-Registry abrufen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Abrufen einer Liste aller in der Registry registrierten Datenquellen.\tabularnewline
\hline
\hline 
Vorbedingung & Die Datenquellen-Registry ist erreichbar.\tabularnewline
\hline
\hline 
Nachbedingung & Eine Liste mit allen in der Registry registrierten Datenquellen steht
zur Verfügung.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & \tabularnewline
\hline
\hline 
Normalablauf & 1. Mit Datenquellen-Registry verbinden

2. Verfügbare Datenquellen abfragen\tabularnewline
\hline
\hline 
Sonderfälle & \tabularnewline
\hline
\end{tabular}


\subsubsection{BPEL-Datei transformieren}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Umwandlung einer BPEL-Datei in Standard-BPEL-Quellcode.\tabularnewline
\hline
\hline 
Vorbedingung & Eine BPEL-Datei (BPEL-Prozess) muss vorhanden sein und RRS-Transformation
Service muss angebunden und erreichbar sein.\tabularnewline
\hline
\hline 
Nachbedingung & Es wurde ein korrekter standard-konformer BPEL-Prozess, der die gleiche
Funktionalität wie der originale Prozess besitzt und zur Verwendung
von Referenzen um entsprechende Aktivitäten oder Events erweitert
wurde, erzeugt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Es wurde kein neuer BPEL-Prozess erzeugt, der originale BPEL-Prozess
ist unverändert und es wird eine entsprechende Fehlermeldung ausgegeben.\tabularnewline
\hline
\hline 
Normalablauf & 1. Auslesen des originalen Prozesses

2. Aufrufen des Transformation Service mit dem originalen BPEL-Prozess
(und vielleicht anderen Sachen?) als Eingabe, um entsprechende Dereferenzierungsaktivitäten
oder Events für Referenzen positioniert einzufügen.

Positioniertes Einfügen entsprechender Dereferenzierungsaktivitäten
oder Events für Referenzen (siehe \ref{sub:Transformation-des-Modells})

3. Generierung des neuen BPEL-standard-konformen erweiterten Prozesses\tabularnewline
\hline
\hline 
Sonderfälle & 3a. Bei der Generierung tritt ein Fehler auf\tabularnewline
\hline
\end{tabular}


\subsection{Anwendungsfälle des RRS Eclipse Plug-Ins}

Das RRS Eclipse Plug-In kann folgende Anwendungsfälle (siehe Abbildung
\ref{fig:UseCaseDiaRRS}) ausführen:
\begin{itemize}
\item Referenz laden
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/diagrams/RRS_Eclipse_Plug-In_iter2}
\par\end{centering}

\caption{\label{fig:UseCaseDiaRRS}Anwendungsfall-Diagramm für das RRS Eclipse
Plug-In}

\end{figure}



\subsubsection{Referenz laden}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Die Referenz soll aus dem RRS geladen werden in den RRS Eclipse View
geladen werden.\tabularnewline
\hline
\hline 
Vorbedingung & Die RRS View wurde im Eclipse geöffnet.\tabularnewline
\hline
\hline 
Nachbedingung & Die Referenz wurde erfolgreich geladen und wird nun im RRS View angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Es wird ein Fehler geworfen, der Informationen über das zugrundeliegende
Problem liefert.\tabularnewline
\hline
\hline 
Normalablauf & 1. Die Referenz wird beim Start des RRS View aus dem RRS geladen und
anschließend dargestellt. \tabularnewline
\hline
\hline 
Sonderfälle & 1a. Beim Laden der Referenz tritt ein Fehler auf, da z.B. das RRS
nicht erreicchbar ist\tabularnewline
\hline
\end{tabular}


\subsection{Anwendungsfälle der Datenquellen-Administratoren}

Ein Datenquellen-Administrator kann folgende Anwendungsfälle (siehe
Abbildung \ref{fig:UseCaseDiaDQAdmin}) ausführen:
\begin{itemize}
\item Datenquelle in UDDI-Registry registrieren
\item Datenquelle aus UDDI-Registry entfernen
\item Datenquelle aus UDDI-Registry bearbeiten
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/DQAdmin_iter2}
\par\end{centering}

\caption{\label{fig:UseCaseDiaDQAdmin}Anwendungsfall-Diagramm für die Datenquellen-Administratoren}

\end{figure}



\subsubsection{Datenquelle in UDDI-Registry registrieren}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Registrierung einer Datenquelle in der Datenquellen-Registry.\tabularnewline
\hline
\hline 
Vorbedingung & Die Datenquellen-Registry ist erreichbar und die Datenquellenübersicht
wird angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung & Eine neue Datenquelle wurde anhand der Benutzerangaben in der Datenquellen-Registry
korrekt registriert und kann nun in Workflows verwendet werden.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & \tabularnewline
\hline
\hline 
Normalablauf & 1. Drücken des {}``New'' Buttons

2. Eingeben der erfoderlichen Daten

3. {}``Save'' drücken.

4. Daten werden in der Registry gespeichert.\tabularnewline
\hline
\hline 
Sonderfälle & 4a) Es wurden nicht alle erforderlichen Daten eingegeben. Wiederholung
von Schritt 2,3,4\tabularnewline
\hline
\end{tabular}


\subsubsection{Datenquelle aus UDDI-Registry entfernen}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Entfernen einer vorhandenen Datenquelle aus der Datenquellen-Registry\tabularnewline
\hline
\hline 
Vorbedingung & Die Datenquellen-Registry ist erreichbar und die Datenquellenübersicht
wird angezeigt.\tabularnewline
\hline
\hline 
Nachbedingung & Die vom Benutzer ausgewählte Datenquelle wurde korrekt und vollständig
aus der Datenquellen-Registry entfernt und kann nun nicht mehr verwendet
werden.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Datenquelle wurde nicht entfernt.\tabularnewline
\hline
\hline 
Normalablauf & 1. Auswahl der Datenquelle mit dem Radiobutton

2. Drücken des {}``Delete'' Buttons

3. Datenquelle wird entfernt\tabularnewline
\hline
\hline 
Sonderfälle & 1a) Keine Datenquelle wurde ausgewählt

2a) Drücken des {}``Delete'' Buttons

3a) Meldung erscheint, das keine Datenquelle ausgewählt wurde\tabularnewline
\hline
\end{tabular}


\subsubsection{Datenquelle aus UDDI-Registry bearbeiten}

\begin{tabular}{|>{\columncolor{lightgray}}{l}|>{\raggedright}p{11cm}|}
\hline 
Ziel & Bearbeiten einer vorhandenen Datenquelle aus der Datenquellen-Registry\tabularnewline
\hline
\hline 
Vorbedingung & Die Datenquellen-Registry ist erreichbar und der Benutzer hat die
erforderlichen Rechte.\tabularnewline
\hline
\hline 
Nachbedingung & Die vom Benutzer ausgewählte Datenquelle wurde korrekt und vollständig
anhand der vom Benutzer durchgeführten Änderungen (Änderung der Eigenschaften,
der Adresse, usw.) aktualisiert.\tabularnewline
\hline
\hline 
Nachbedingung im Sonderfall & Nichts passiert\tabularnewline
\hline
\hline 
Normalablauf & 1. Auswahl der Datenquelle mit dem Radiobutton

2. Drücken des {}``edit'' Buttons

3. Bearbeiten der Werte der Datenquelle

4. Drücken des {}``Save'' Buttons\tabularnewline
\hline
\hline 
Sonderfälle & 1) Es wurde keine Datenquelle gewählt\tabularnewline
\hline
\end{tabular}


\subsection{Komponenten und ihre Anwendungsfälle}

In diesem Abschnitt werden in Tabelle \ref{tab:Komponenten-Anwendungsf=0000E4lle}
alle Anwendungsfälle den verschiedenen Komponenten des SIMPL Rahmenwerks,
die an der Ausführung der entsprechenden Funktionalität beteiligt
sind, zugeordnet. Die mit {}``x'' markierte Komponente ist dabei
an der Ausführung des Anwendungsfalls beteiligt. Es ist durchaus möglich,
dass Anwendungsfälle durch mehrere Komponenten ausgeführt werden.
Zum Beispiel wird das Auditing in der Admin-Konsole (SIMPL Core Plug-In)
aktiviert, die Ausführung des Auditings wird allerdings durch den
SIMPL Core realisiert.

%
\begin{table}
\caption{\label{tab:Komponenten-Anwendungsf=0000E4lle}Komponenten und ihre
Anwendungsfälle}


\centering{}\begin{tabular}{|>{\raggedright}m{4cm}|>{\centering}m{1.2cm}|>{\centering}m{1.2cm}|>{\centering}m{1.2cm}|>{\centering}m{1.7cm}|>{\centering}m{1.5cm}|>{\centering}m{1.5cm}|>{\centering}m{1.4cm}|}
\hline 
\textbf{Anwendungsfall} & \textbf{SIMPL Core} & \textbf{SIMPL Core}\\
\textbf{Plug-In} & \textbf{BPEL-DM}\\
\textbf{Plug-In} & \textbf{SIMPL Extension- Activity Plug-In} & \textbf{Eclipse BPEL Designer Plug-In} & \textbf{RRS}

\textbf{Eclipse}

\textbf{Plug-In} & \textbf{UDDI Webinterface / UDDI Eclipse Plug-In}\tabularnewline
\hline
\hline 
Data-Management-Aktivität erstellen &  &  & x &  &  &  & \tabularnewline
\hline 
Data-Management-Aktivität bearbeiten &  &  & x &  &  &  & \tabularnewline
\hline 
Data-Management-Aktivität löschen &  &  & x &  &  &  & \tabularnewline
\hline 
ODE Deployment Deskriptor erstellen &  &  &  &  & x &  & \tabularnewline
\hline 
ODE Deployment Deskriptor bearbeiten &  &  &  &  & x &  & \tabularnewline
\hline 
ODE Deployment Deskriptor löschen &  &  &  &  & x &  & \tabularnewline
\hline 
Prozess auf ODE-Server deployen &  &  &  &  & x &  & \tabularnewline
\hline 
Prozessinstanz starten &  &  &  &  & x &  & \tabularnewline
\hline 
\selectlanguage{english}%
Strategie für das Late-Binding auswählen\selectlanguage{ngerman}
 &  &  &  &  & x &  & \tabularnewline
\hline
\hline 
Admin-Konsole öffnen &  & x &  &  &  &  & \tabularnewline
\hline 
Auditing aktivieren &  & x &  &  &  &  & \tabularnewline
\hline 
Auditing deaktivieren &  & x &  &  &  &  & \tabularnewline
\hline 
Auditing-Datenbank festlegen/ändern &  & x &  &  &  &  & \tabularnewline
\hline 
Globale Einstellungen festlegen/ändern &  & x &  &  &  &  & \tabularnewline
\hline 
Einstellungen der Admin-Konsole speichern &  & x &  &  &  &  & \tabularnewline
\hline 
Einstellungen der Admin-Konsole zurücksetzen &  & x &  &  &  &  & \tabularnewline
\hline 
Default-Einstellungen der Admin-Konsole laden &  & x &  &  &  &  & \tabularnewline
\hline 
Admin-Konsole schließen &  & x &  &  &  &  & \tabularnewline
\hline 
Referenz laden &  &  &  &  &  & x & \tabularnewline
\hline
\end{tabular}
\end{table}


%
\begin{table}
\begin{centering}
\begin{tabular}{|>{\raggedright}m{4cm}|>{\centering}m{1.2cm}|>{\centering}m{1.2cm}|>{\centering}m{1.2cm}|>{\centering}m{1.7cm}|>{\centering}m{1.5cm}|>{\centering}m{1.5cm}|>{\centering}m{1.4cm}|}
\hline 
\textbf{Anwendungsfall} & \textbf{SIMPL Core} & \textbf{SIMPL Core}\\
\textbf{Plug-In} & \textbf{BPEL-DM}\\
\textbf{Plug-In} & \textbf{SIMPL Extension- Activity Plug-In} & \textbf{Eclipse BPEL Designer Plug-In} & \textbf{RRS Eclipse Plug-In} & \textbf{UDDI Webinterface / UDDI Eclipse Plug-In}\tabularnewline
\hline
\hline 
Neue Referenz in RRS einfügen &  &  &  &  &  & x & \tabularnewline
\hline 
Referenz aus RRS löschen &  &  &  &  &  & x & \tabularnewline
\hline 
Referenz aus RRS bearbeiten &  &  &  &  &  & x & \tabularnewline
\hline
\hline 
Data-Management-Aktivität ausführen &  &  &  & x &  &  & \tabularnewline
\hline 
Data-Management-Aktivität zurücksetzen &  &  &  & x &  &  & \tabularnewline
\hline
\hline 
SIMPL Admin-Konsole laden & x & x &  &  &  &  & \tabularnewline
\hline 
SIMPL Admin-Konsole Defaults laden & x & x &  &  &  &  & \tabularnewline
\hline 
SIMPL Admin-Konsole speichern & x & x &  &  &  &  & \tabularnewline
\hline 
Datenquelle aus UDDI-Registry abrufen &  &  &  &  & x &  & - / x\tabularnewline
\hline 
BPEL-Datei transformieren &  &  &  &  & x &  & \tabularnewline
\hline 
SIMPL Extensions validieren &  &  &  &  & x &  & \tabularnewline
\hline
\hline 
Datenquelle in UDDI-Registry registrieren &  &  &  &  &  &  & x / -\tabularnewline
\hline 
Datenquelle aus UDDI-Registry entfernen &  &  &  &  &  &  & x / -\tabularnewline
\hline 
Datenquelle aus UDDI-Registry bearbeiten &  &  &  &  &  &  & x / -\tabularnewline
\hline
\end{tabular}
\par\end{centering}


\end{table}


\pagebreak{}


\section{\label{sec:Konzepte-und-Realisierungen}Konzepte und Realisierungen}

In diesem Kapitel werden alle Konzepte, die für SIMPL benötigt werden,
und deren Realisierung erläutert. Dazu zählt z.B. die Beschreibung
eines Referenzen-Konzepts für BPEL, das es ermöglicht, mit Referenzen
auf Daten innerhalb von Workflows zu arbeiten oder die Identifizierung
und Definition von benötigten DM-Aktivitäten, die zur Realisierung
einer generischen Unterstützung von verschiedenen Abfragesprachen,
wie z.B. der Structured Query Language (SQL) oder der XML Query Language
(XQuery), für BPEL benötigt werden. Weiterhin werden Authentifizierung
und Autorisierung im Rahmen von SIMPL erläutert. Darüber hinaus wird
am Ende dieses Kapitels die Realisierung des Datenquellen-Auditings
und das dafür zugrunde liegende Event-Modell beschrieben.


\subsection{\label{sub:Daten-Referenzen-in-BPEL}Daten-Referenzen in BPEL (IAAS-Referenzen)}

{\small Da bereits ein Konzept und umfassende Erkentnisse zur Bereitstellung
und Verwaltung von Referenzen in BPEL vorliegt \cite{key-3}, werden
an dieser Stelle nur die Ergebnisse des Dokuments zusammengefasst
und an die Anforderungen dieses Projekts angepasst.}{\small \par}

In BPEL werden Daten immer in Variablen gespeichert und die Werte
(\emph{by value}) innerhalb des Workflows weitergegeben. Dies hat
zur Folge, dass gerade bei großen Datenmengen, wie sie in wissenschaftlichen
Workflows normal sind, die Performanz der Workflow Engine stark durch
das Transportieren der Daten beeinflusst wird. Um dies zu verhindern,
sollen Referenzen auf Daten eingeführt werden. Diese werden dann zwischen
den einzelnen Web Services weitergegeben (Daten werden \emph{by reference}
übergeben) und die Daten bleiben, sofern sie nicht im Workflow benötigt
werden, auf ihrer Datenquelle und werden dort auch bearbeitet.

Zur Umsetzung dieses Konzepts muss eine neue Art von BPEL Variablen
eingeführt werden, sogenannte Referenzvariablen, die dazu genutzt
werden können, auf Daten zu verweisen. Dadurch müssen nur noch Referenzen
zwischen den Web Services und Workflows weitergeleitet werden, und
nicht mehr die Daten selbst. Für wissenschaftliche Workflows reduziert
sich dadurch der Transport von großen Datenmengen zwischen den Web
Services und dem Workflow erheblich.

Zur Bereitstellung solcher Referenzen für Web Services und Workflows
müssen diese extern verwaltet werden und auch extern abrufbar sein.
So kann ein globales oder unternehmensweites Variablenkonzept erstellt
werden, das es ermöglicht, dieselben Daten in mehreren Workflows zu
nutzen und nur einmal zentral zur Verfügung zu stellen.

Die Umsetzung der Referenzen wird durch sogenannte Endpoint References
realisiert, die in Abschnitt \ref{sub:Endpoint-References} beschrieben
werden. Das externe Verwaltungssystem der Referenzen, das sogenannte
Reference Resolution System, wird in Abschnitt \ref{sub:Reference-Resolution-System}
näher erläutert. Die Einbindung der Referenzen in BPEL (Modellierungswerkzeug
\& Workflow Engine) beschreibt Abschnitt \ref{sub:Realisierung-von-Referenzen}.


\subsubsection{\label{sub:Reference-Resolution-System}Reference Resolution System}

Abbildung \ref{fig:RRS} zeigt die Architektur des Reference Resolution
Systems (RRS). Am unteren Ende der Abbildung werden die verschiedenen
möglichen Nutzer des Systems gezeigt: Workflows und Web Services,
die den Wert einer Referenz auslesen, Referenzen auslesen oder Referenzen
im System anlegen, aktualisieren und löschen können.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.5\textwidth]{img/diagrams/RRSdiagramm}
\par\end{centering}

\caption{\label{fig:RRS}Die Architektur des Reference Resolution Systems (RRS).}

\end{figure}


Auch wenn auf eine Trennung von Nutzern nach Zugriffsrechten (Benutzer
vs. Administrator) aus Gründen der Flexibilität (ermöglicht automatische
Erstellung von neuen Referenzen zur Prozesslaufzeit) verzichtet wird,
so werden doch zwei entsprechende Web Service Schnittstellen bereitgestellt.
Dadurch ist eine spätere Erweiterung um Zugriffsrechte leicht realisierbar.
Im Folgenden werden alle drei Schnittstellen des RRS kurz beschrieben:
\begin{itemize}
\item Die erste Schnittstelle ist der \emph{Reference Retrieval Web Service}
mit der Methode \emph{get} und einer \emph{Endpoint reference} (EPR)
als Eingabe. Das Konzept der Endpoint References wird im Web Services
Addressing Standard (siehe \cite{key-25}) beschrieben und kann ohne
Anpassungen für die Repräsentation einer Referenz genutzt werden.
Der Rückgabewert der Methode ist der Wert, der durch die angegebene
EPR referenziert wurde.
\item Die zweite Schnittstelle ist der \emph{Reference Management Web Service},
der drei Methoden bereitstellt. Die Methode \emph{insert,} um eine
neue Referenz zu erstellen. Dabei ist die Eingabe der Wert der Referenz,
wo dieser Wert gespeichert wird und wie er dort wieder ausgelesen
werden kann. Dies könnte beispielsweise durch entsprechende SQL-Befehle
angegeben werden. Der Rückgabewert ist eine Meldung, die die neu generierte
EPR enthält. Als Zweites die \emph{update} Methode, die für die Aktualisierung
von gespeicherten Werten einer Referenz benötigt wird. Dabei ist die
Eingabe der neue Wert der Referenz und wie dieser Wert gespeichert
wird. Der Rückgabewert ist eine Meldung, ob die Aktualisierung erfolgreich
war. Die \emph{delete} Methode löscht eine Referenz aus dem RRS, d.h.
der Wert und alle sonstigen Informationen der Referenz werden aus
dem System entfernt. Die Eingabe ist dabei die EPR, die entfernt werden
soll und der Rückgabewert ist eine Meldung, ob die Referenz erfolgreich
entfernt wurde.
\item Die dritte Schnittstelle ist der \emph{Reference Metadata Web Service},
der drei Methoden bereitstellt. Die Methode \emph{getEPR,} um eine
einzelne Referenz auslesen zu können. Dies wird bei der Transformation
eines Prozessmodells benötigt (siehe Abschnitt \ref{sub:Transformation-des-Modells}).
Die Methode \emph{getAllEPR,} um alle Referenzen eines RRS auslesen
zu können und diese beispielsweise in der RRS Management View in Eclipse
anzeigen zu können. Die Methode \emph{getAllAdapters,} um alle verwendbaren
Adapter eines RRS abzufragen, sodass diese beispielsweise beim Anlegen
neuer Referenzen angezeigt werden können.
\end{itemize}
Die Hauptkomponente ist allerdings das Reference Resolution System
selbst. Es verbindet die drei Web Service Schnittstellen und bietet
die Möglichkeit, eine Menge von Adaptern für die Integration verschiedenster
Datenquellen anzubinden. Jeder dieser Adapter besteht dabei aus einem
Lookup-Service für gespeicherte Queries und Informationen sowie aus
einem ausführenden Service, mit dem Queries auf den Datenquellen ausgeführt
werden können. Anhand einer gegebenen Referenz wird dazu der passende
Adapter gesucht, ausgewählt und für das Auflösen von Referenzen verwendet.
Im Rahmen des Projektes wird nur ein SIMPL Adapter angeboten, der
die Verbindung zu allen Datenquellen ermöglicht, die vom SIMPL Core
unterstützt werden. Abbildung \ref{fig:RRS} zeigt am oberen Ende
einige solcher Adapter, wobei das RRS erweiterbar ist und mit Adaptern
für alle Arten von Datenquellen ergänzt werden kann.

In \cite{key-3} werden mehrere mögliche Anbindungen des RRS in der
Workflow-Umgebung genannt: {}``Ein RRS pro Workflow-Umgebung'',
{}``Ein RRS pro Web Service'' und {}``Ein RRS pro Datenquelle''.
Im Zusammenhang mit unseren Gegebenheiten, vor allem im Hinblick darauf,
dass die Workflow-Engine lokal auf dem Benutzer-Rechner ausgeführt
wird, bietet sich die Variante {}``Ein RRS pro Workflow-Engine''
an. Das RRS muss dabei nicht zwangsweise auf dem Rechner liegen auf
dem auch die Workflow-Engine ausgeführt wird. Allerdings benötigt
man dann eine Authentifizierung um die nachfolgenden Vorteile zu erhalten,
die im Moment aus der identischen Lokalität des RRS und der Workflow-Engine
resultieren:
\begin{itemize}
\item Jeder Prozess-Modellierer (Workflow-Administrator) kann Referenzen
nach Bedarf selbst sofort erstellen und verwalten.
\item Die Referenzen können nur lokal geändert werden und sind nicht global
(von außen) editierbar, dadurch benötigen wir keinen Zugriffsschutz.
\item Wird bei der Modellierung von BPEL-Prozessen festgestellt, dass entsprechende
Referenzen benötigt werden, können diese sofort angelegt und auch
sofort in der Prozess-Modellierung verwendet werden.
\end{itemize}

\subsubsection{\label{sub:Endpoint-References}Referenzen und Endpoint References}

Nachdem die Architektur des Systems beschrieben wurde, folgt die Beschreibung
des wichtigsten Teils des Systems, der Referenzen selbst. Dazu wird
die Repräsentation der Referenzen anhand des WS-Addressing Konzepts
der \emph{Endpoint References} (EPR's) \cite{key-25} beschrieben.
Das Ziel bei der Definition der Referenzen ist, diese so flexibel
und erweiterbar wie möglich zu realisieren und zu versuchen die vollständige
Abgeschlossenheit der EPR's zu erreichen. Vollständige Abgeschlossenheit
bedeutet dabei, dass alle für die Auflösung einer Referenz benötigten
Informationen in der EPR selbst hinterlegt sind. Listing \ref{lst:EPR-Schema}
zeigt das Schema einer EPR und wie diese zur Repräsentation einer
Referenz genutzt werden. Im Schema und allen nachfolgenden Listings
werden dabei folgende BNF Konventionen verwendet: {}``?'' bezeichnet
Optionalität (0 oder 1), {}``{*}'' (0 oder mehr), {}``+'' (1 oder
mehr) und {}``|'' steht für eine Auswahlmöglichkeit.

\begin{center}

\begin{lstlisting}[caption={EPR Schema \cite{key-3}},label={lst:EPR-Schema},basicstyle={\small\ttfamily},captionpos=b,float,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<wsa:EndpointReference> 
	<wsa:Address> 
		xs:anyURI 
	</wsa:Address> 
	<wsa:ReferenceProperties> 
		<rrs:resolutionSystem> 
			(xs:String | xs:anyURI | 
			xs:QName) 
		</rrs:resolutionSystem> 
	</wsa:ReferenceProperties> 
	<wsa:ReferenceParameters> 
		(xs:anyURI | 
		xs:any) 
	</wsa:ReferenceParameters> 
	<wsa:PortType>xs:QName</wsa:PortType> 
	<wsa:ServiceName PortName="xs:NCName"?>
		xs:QName 
	</wsa:ServiceName> 
	<wsp:Policy>Policy</wsp:Policy>? 
</wsa:EndpointReference>

\end{lstlisting}

\par\end{center}

Die verschiedenen Bestandteile einer EPR werden dabei für folgende
Zwecke benötigt: Der \texttt{Address} Teil verweist auf den Endpunkt
des RRS, das die Werte der Referenzen verwaltet. 

In den \texttt{ReferenceProperties} wird der Adapter des RRS, der
für das Auflösen der Referenz zuständig ist, angegeben. Alle Informationen,
die der entsprechende Adapter zur Auflösung der Referenz benötigt,
werden in den \texttt{ReferenceParameters} angegeben. Diese Informationen
können entweder direkt angegeben werden, wie z.B. eine SQL-Query oder
aber auch zentral gespeichert und anschließend über einen \emph{Uniform
Resource Identifier} (URI) referenziert werden. Beide Möglichkeiten
haben Vorteile: Die direkte Angabe erlaubt es, die Query in der EPR
während der Laufzeit zu ändern. Mit der Verwendung von gespeicherten
Queries wird dafür sichergestellt, dass immer die gleiche Query ausgeführt
wird und so niemand ungewollte Queries ausführen kann. \texttt{PortType}
und \texttt{ServiceName} sind technische Parameter, die das dynamische
Binden des RRS erlauben sollen. \texttt{Policy} ist optional und erlaubt
das Hinzufügen von nichtfunktionalen Eigenschaften für die Ausführung
der Queries. So kann z.B. \emph{Quality of Context} (QoC) (Aktualität,
Korrektheit, usw.), der für die zurückgelieferten Daten gelten soll,
angegeben werden.

Weitere Details zu den Design-Entscheidungen und deren Nutzen finden
sich in \cite{key-3} unter \emph{{}``Main Design Issues and Benefits
of the Architecture''}.


\subsubsection{\label{sub:Realisierung-von-Referenzen}Realisierung von Referenzen
in BPEL}

In \cite{key-3} werden zwei verschiedene Ansätze (siehe Abbildung
\ref{fig:AltRealisierungRefBPEL}) zur Integration des Referenzen-Konzepts
in BPEL beschrieben und deren Vor- und Nachteile erläutert. 

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/ReferenzUmsetzungDiagramm}
\par\end{centering}

\caption{\label{fig:AltRealisierungRefBPEL}Alternativen zur Realisierung von
Referenzen in BPEL, vgl. \cite{key-3}}

\end{figure}


Für beide Konzepte muss ein entsprechendes Modellierungswerkzeug erweitert
werden. In der Laufzeitumgebung unterscheiden sich dann die Konzepte.
Die erste Variante besteht darin, den erweiterten BPEL-Quellcode unverändert
auf einer erweiterten Workflow-Engine auszuführen. Das hat natürlich
den entscheidenen Nachteil, dass nur noch eine entsprechend erweiterte
Workflow-Engine diese Prozesse ausführen kann. Die zweite Variante
umgeht dieses Problem, indem der veränderte BPEL-Quellcode in Standard-BPEL-Quellcode
transformiert wird. Wir konzentrieren uns hier auf die Beschreibung
der zweiten Variante, da diese einen universelleren Ansatz liefert,
auf nahezu alle standard-konformen Workflow-Engines portiert werden
kann und somit die Ausführungsumgebung des generierten BPEL-Quellcodes
nicht eingeschränkt wird.


\subsubsection*{Erweiterung des Modellierungswerkzeugs}

Wie bereits erwähnt, muss auf jeden Fall das Modellierungswerkzeug
erweitert werden, um BPEL Prozesse mit Referenzen modellieren zu können.
Zur Modellierung von solchen \texttt{<referenceVariable>} muss ein
neuer Variablentyp eingeführt werden. Den Aufbau dieser Variablen
zeigt das Schema in Listing \ref{lst:<referenceVariable>-Schema}.

\begin{center}

\begin{lstlisting}[caption={Code eines \texttt{<referenceVariable>}-Schemas
\cite{key-3}},label={lst:<referenceVariable>-Schema},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<referenceVariable name="refName" 
    valueType="xsd: schema" 
	referenceType="onInstantiation | fresh |
	periodic | external" 
	period="duration"? 
	external="partnerLink"? />*

\end{lstlisting}

\par\end{center}

Dieses Schema ist eine Erweiterung des Standard BPEL Variablen-Schemas.
Das Attribut \texttt{valueType} spiegelt den Datentyp der referenzierten
Variable wider. Die Referenz-Variable selbst ist implizit vom Typ
\texttt{xsd:EPR} und dient dazu, die eigentliche Referenz zu speichern.
Über das Attribut \texttt{referenceType} kann angegeben werden, wie
aktuell referenzierte Werte sein sollen, also wann und wie oft die
in den Referenzen hinterlegten Werte aktualisiert werden sollen. In
\cite{key-3} werden vier solcher Aktualitätskonstanten vorgestellt,
wobei eine Vielzahl weiterer solcher Konstanten denkbar ist. Ihre
Bedeutung und Verwendung wird nachfolgend bei der Beschreibung der
Modelltransformation aufgezeigt.


\subsubsection*{\label{sub:Transformation-des-Modells}Transformation des Modells}

Die Integration eines Modelltransformation-Zwischenschritts vor dem
Deployment des Prozesses erlaubt uns, ein virtuelles Referenz-Handling
für Prozesse zu realisieren, ohne dabei die den Prozess ausführende
Engine zu modifizieren. Die Grundidee ist dabei, die Sprache BPEL
nur im Modellierungswerkzeug, in dem wir zwischen normalen Variablen
und Referenzvariablen unterscheiden, zu erweitern. Der zusätzliche
Transformationsschritt generiert dabei standard-konforme BPEL Konstrukte
für die Handhabung von Referenzen und speist diese in das originale
Prozess-Modell ein. Für jede Referenz, die im Prozessmodell deklariert
ist, werden dafür vier entsprechende Variablendeklarationen, wie in
Listing \ref{lst:VariablenDeklaration} dargestellt, generiert.

\begin{center}

\begin{lstlisting}[caption={Code der generierten Variablen-Deklaration,
vgl. \cite{key-3}},label={lst:VariablenDeklaration},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=2cm,xrightmargin=2cm]
<variable name="refName" type="xsd:schema"/> 
<variable name="refNameEPR_Name" type="xsd:string"/>
<variable name="refNameEPR_Meta" type="xsd:EPR"/>
<variable name="refNameEPR_Ret" type="xsd:EPR"/>

\end{lstlisting}

\par\end{center}

Die erste Variable wird dabei für die Haltung des eigentlichen Werts
genutzt und die Zweite um den logischen Namen einer Referenz zu halten.
Die beiden anderen Variablen halten die EPR der Referenz, die aus
dem RRS über den Metadata Web Service abgerufen bzw. an den Retrieval
Service geschickt wird. Weiterhin muss das RRS im Prozessmodel sichtbar
sein. Dies wird durch die Generierung entsprechender \texttt{<partnerLink>}s
realisiert (siehe Listing \ref{lst:RRS-PartnerLinks}). Dabei muss
sowohl ein Partner Link für den Metadata Web Service als auch für
den Retrieval Web Service erstellt werden.

\begin{center}

\begin{lstlisting}[caption={Code der RRS Partner Links},label={lst:RRS-PartnerLinks},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:partnerLink name="RRS_RET_Type" 
    partnerLinkType="tns:RRS_RET_Type"
    partnerRole="get"/>

<bpel:partnerLink name="RRS_MetaData"
    partnerLinkType="tns:RRS_MD_Type"
    partnerRole="getEPR"/>

\end{lstlisting}

\par\end{center}

Um die Referenzen zur Laufzeit auflösen zu können, müssen die EPRs
in den Prozess geladen werden. Dazu werden entsprechende Invoke-Aktivitäten
auf den Metadata Web Service des RRS in das Prozessmodell eingefügt
und die so eingelesenen EPRs in die \emph{refNameEPR\_Meta}-Variable
gespeichert.

Zu guter Letzt zeigt Listing \ref{lst:Dereferenzierungsaktivit=0000E4t}
die tatsächliche Dereferenzierung einer Referenz über den Retrieval
Web Service des RRS. Der Modelltransformationsansatz speist Variablendeklarationen
und Dereferenzierungsaktivitäten in den Workflow ein, um die Aktualisierung
der Werte der Referenzen auszuführen. Auf den exakten Ablauf einer
Transformation und deren Umsetzung wird am Ende dieses Abschnitts
nocheinmal genauer eingegangen.


\begin{lstlisting}[caption={Code einer Dereferenzierungs-Aktivität,
vgl. \cite{key-3}},label={lst:Dereferenzierungsaktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:invoke name="refName_Refresh_#" 
    partnerLink="RRS_RET_Type"
    operation="get" 
    portType="ns:RRSRetrievalService"
    inputVariable="refNameEPR_Ret" 
    outputVariable="refName">

\end{lstlisting}


Wie bereits weiter oben erwähnt, ermöglicht das Attribut \texttt{referenceType}
dem Modellierer, eine von verschiedenen Aktualisierungsoptionen für
die Werte der Referenzen auszuwählen. Im Rahmen des Projektes werden
dabei nur die beiden Aktualisierungsoptionen \emph{fresh} und \emph{onInstantiation}
umgesetzt, \emph{periodic} und \emph{external} sind zwei mögliche
Erweiterungen. Abhängig von der Auswahl des Modellierers müssen die
Dereferenzierungsaktivitäten an der entsprechenden Position im Prozess
folgendermaßen eingefügt werden:
\begin{itemize}
\item \emph{onInstantiation (default)}:\emph{ }Bei der Instanzierung des
Prozesses werden die Werte vom RRS abgefragt und die Variablen entsprechend
gesetzt. Diese Einstellung ist für die Definition von Konstanten,
die beim Prozessstart gesetzt werden und während der ganzen Laufzeit
des Prozesses unverändert bleiben, sinnvoll. Für jede Referenzvariable,
die auf \emph{onInstantiation} gesetzt ist, wird die RRS Invoke-Aktivität
aus Listing \ref{lst:Dereferenzierungsaktivit=0000E4t} zu einer Sequenz,
die bei der Prozessinstanzierung ausgeführt wird, hinzugefügt. Die
Sequenz dieser Invokes wird dabei direkt nach dem CreateInstance-Receive
des Prozessmodells einfügt. Der Fall, dass es mehrere CreateInstance-Receives
gibt, wird vernachlässigt, da er im wissenschaftlichen Bereich eher
eine untergeordnete Rolle spielt.
\item \emph{fresh}:\emph{ }So frisch wie nur möglich - der Wert wird jedesmal
abgefragt, wenn auf die Variable zugegriffen wird. Diese Einstellung
ist nützlich, falls auf sich oft ändernde externe Werte, wie z.B.
Sensordaten, zugegriffen werden soll. Hier muss die Dereferenzierungsaktivität
direkt vor jeder Aktivität, die den Wert der Referenz liest, ausgeführt
werden.
\item \emph{periodic(Erweiterung)}: Im Attribut \texttt{period} kann ein
Zeitwert, wie z.B. 10 min, angegeben werden. Dieses Attribut beschreibt
das maximale Alter (Zeitspanne seit letzter Aktualisierung), das ein
lokal gespeicherter temporärer Wert einer Referenz haben darf. Nachdem
diese Zeitspanne abgelaufen ist, wird der Wert aus dem RRS abgefragt
und die temporäre Variable aktualisiert. Dafür wird ein \texttt{<onAlarm>}
Element im globalen \texttt{<eventHandlers>} Element während der Transformation
eingefügt. Diese Konstruktion liefert die periodische Aktualisierung
von Werten über das wiederholte Abfragen dieser Werte aus dem RRS.
\item \emph{external(Erweiterung)}: Ein externes Event im Bereich der Web
Service Orchestrierung ist typischerweise eine Nachricht, die an die
Prozessinstanz geschickt wird (oder ein Signal, das für alle Instanzen
eines Prozessmodells gültig ist). Wird dieser Wert als \texttt{referenceType}
gesetzt, können Aktualisierungen der Werte von außen, durch das Senden
entsprechender Nachrichten an die Prozess-Engine ausgelöst werden.
Der Service, von dem solch eine Nachricht erwartet wird, kann im Attribut
\texttt{external} angegeben werden. Im Transformationsschritt wird
dazu ein \texttt{<onEvent>} Konstrukt im globalen \texttt{<eventHandlers>}
Element eingefügt.
\end{itemize}
Da die Transformation eines Prozessmodells relativ schnell sehr komplex
wird (verschachtelte Sequenzen, Flows, ...) wird die Transformation
nur beispielthaft umgesetzt. Die Einschränkungen liegen dabei darin,
dass zum einen nur die oberste Sequenz des Prozessmodells transformiert
wird (im BPEL Designer als {}``main'' bezeichnet) und zum anderen
eine Dereferenzierung nur in einer Assign-Aktivität mittels eines
Befehls (\emph{val(\$refName)}) angestoßen werden kann und in allen
anderen Fällen die Referenz und nicht die Daten verwendet werden.
Da die Transformation bereits in diesem rudimentären Status sehr komplex
ist, wird diese nachfolgend Schritt für Schritt erklärt. Die oben
angegebenen Beschreibungen dienen dazu als Grundlage und werden zum
Teil noch weiter verfeinert.

Ein Prozessmodell wird nur transformiert falls es Referenzvariablen
enthält und diese auch vollständig spezifiziert sind, d.h. ein Datentyp
und eine Aktualisierungskonstante angegeben ist. Falls dies zutrifft,
kann die Transformation über den in Kapitel \ref{sub:Erweiterungen-zur-Integration-Ref}
beschriebenen Button angestoßen werden, falls nicht wird eine entsprechende
Fehlermeldung ausgegeben. Abbildung \ref{fig:BeispielRRSProzess}
zeigt das im Folgenden als Beispiel verwendete Prozessmodell und Abbildung
\ref{fig:VarVorTransformation} dessen Variablen vor der Transformation.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.3\textwidth]{img/screenshots/SimpleRefProcess}
\par\end{centering}

\caption{\label{fig:BeispielRRSProzess}Beispiel Prozessmodell mit Referenzvariablen}

\end{figure}


%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.3\textwidth]{img/screenshots/RefVariablesNormal.JPG}
\par\end{centering}

\caption{\label{fig:VarVorTransformation}Variablen eines Prozessmodells vor
der Transformation}

\end{figure}

\begin{itemize}
\item Als erstes wird ein neues Projekt für die transformierten Dateien
erstellt. Abbildung \ref{fig:RefWorkspace} zeigt ein BPEL-Projekt
und das zugehörige neue Projekt für die transformierten Dateien, dessen
Namen um das Kürzel {}``\_TF'' erweitert wird.
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.3\textwidth]{img/screenshots/RefProjectWorkspace.JPG}
\par\end{centering}

\caption{\label{fig:RefWorkspace}Workspace mit einem BPEL Projekt und dessen
transformierter Kopie}

\end{figure}

\begin{itemize}
\item Im nächsten Schritt werden nun die benötigten WSDLs des RRS (Retrieval
und Metadata) über die in den Preferences hinterlegten Adressen heruntergeladen
und im neu erstellten Projekt gespeichert.
\item Nun wird die eigentliche Transformation angestoßen, d.h. die BPEL-Datei
wird an den Transformation Web Service geschickt und dort transformiert:

\begin{itemize}
\item Der Transformator erzeugt die RRS PartnerLinks aus Listing \ref{lst:RRS-PartnerLinks}
für den Retrieval Web Service und den Metadata Web Service (siehe
Abbildung \ref{fig:VarNachTransformation}).
\item Anschließend werden die in Listing \ref{lst:VariablenDeklaration}
genannten Variablen erzeugt (siehe Abbildung \ref{fig:VarNachTransformation}).
\item Nun wird die in Abbildung \ref{fig:BeispielRRSProzessTransformiert}
dargestellte {}``prepareEPR''-Sequence erzeugt. In dieser werden
alle verwendeten EPRs aus dem RRS abgerufen und in den entsprechenden
{}``refNameEPR\_Meta''-Variablen gespeichert. Damit dies allerdings
funktioniert müssen zuerst alle EPR-Namen (identisch mit den Referenzvariablennamen)
in den entsprechenden {}``refNameEPR\_Name''-Variablen hinterlegt
werden. Dies geschieht über die {}``setEPR\_Names''-Assign-Aktivität
in der die Namen als fixe Werte hinterlegt werden. Nun können die
EPRs über die entsprechenden {}``init\_refNameEPR\_Meta''-Invoke-Aktivitäten
abgerufen werden. Dazu dienen die {}``refNameEPR\_Name''-Variablen
als Eingabevariablen und die {}``refNameEPR\_Meta''-Variablen zur
Speicherung der Rückgabewerte (EPRs). Um nun die EPRs später auflösen
zu können müssen diese noch in das Nachrichtenformat des Retrieval
Web Service umgewandelt werden. Dazu werden die EPRs einfach in der
{}``copyEPRs''-Assign-Aktivität aus den {}``refNameEPR\_Meta''-Variablen
in die {}``refNameEPR\_Ret''-Variablen kopiert.
\item Danach wird die oberste Sequenz des Prozessmodells durchlaufen und
folgende Änderungen durchgeführt:

\begin{itemize}
\item Im Moment gibt es nur einen Fall in dem dereferenziert wird, diesen
zeigt Abbildung \ref{fig:BeispielRRSAssignExpression}. Dabei wird
über eine XPath-Expression angegeben, dass der Wert der Referenzvariablen
kopiert werden soll und nicht die EPR. Generell gilt, dass in allen
anderen Fällen z.B. falls eine Referenzvariable in einer Invoke- oder
Reply-Aktivität hinterlegt ist, immer die zugehörige EPR der Referenzvariablen
verwendet wird und nicht die referenzierten Daten. An dieser Stelle
müssen noch entsprechende Erweiterungen und ein geeignetes Konzept
für die Unterscheidung zwischen EPRs und den referenzierten Daten
in Kommunikationsaktivitäten erarbeitet werden.
\item Dereferenzierung: Für alle Referenzvariablen, die als Aktualisierungskonstante
\emph{onInstantiation} gesetzt hatten, werden {}``refNameRefresh\_0''-Invoke-Aktivitäten
(siehe Listing \ref{lst:Dereferenzierungsaktivit=0000E4t}) direkt
nach der {}``prepareEPR''-Sequence eingefügt. Für alle Referenzvariablen,
die als Aktualisierungskonstante \emph{fresh} gesetzt hatten, werden
{}``refNameRefresh\_1''-Invoke-Aktivitäten (siehe Listing \ref{lst:Dereferenzierungsaktivit=0000E4t})
direkt vor der jeweiligen Aktivität eingefügt. Die Zahl erhöht sich
dabei für jede eingefügte {}``refNameRefresh\_\#''-Invoke-Aktivität.
\item Sonst: Alle Referenzvariablen, die in Kommunikationsaktivitäten (Invoke,
Receive und Reply) verwendet werden, werden bei der Transformation
durch die entsprechenden {}``refNameEPR\_Ret''-Variablen ausgetauscht.
Ist allerdings tatsächlich gewünscht, dass eine EPR als Rückgabewert
des Prozessmodells verwendet werden soll, dann muss vorerst die Prozess-WSDL
noch von Hand entsprechend angepasst werden.
\item Für die Zukunft wäre hier eine entsprechende Erweiterung sinnvoll,
die zum Einen automatisch die Prozess-WSDL anpasst und zum Anderen
eine Auswahlmöglichkeit zwischen referenzierten Daten und Referenzen
in den jeweiligen Kommunikationsaktivitäten liefert.
\end{itemize}
%
\begin{figure}
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/screenshots/RefAssignExpression.JPG}
\par\end{centering}

\caption{\label{fig:BeispielRRSAssignExpression}Beispiel für das Anstoßen
der Dereferenzierung einer Referenzvariablen über eine Assign-Aktivität}

\end{figure}


\end{itemize}
\item Die transformierte BPEL-Datei wird im neu erstellten Projekt gespeichert.
\item Damit die beiden RRS Web Services aufgerufen werden können, müssen
diese in der Prozess-WSDL bekannt gemacht werden. Dazu wird die originale
WSDL-Datei eingelesen, die RRS-WSDLs importiert, die RRS Partner Link
Typen definiert und die so veränderte WSDL in das neu erstellte Projekt
gespeichert.
\item Zu guter Letzt werden alle unveränderten Dateien, wie z.B. XSD-Schemas,
nicht transformierte BPEL-Dateien und WSDLs in das neu erstellte Projekt
kopiert.
\item Nun erhalten wir für unser Beispiel das in Abbildung \ref{fig:BeispielRRSProzessTransformiert}
abgebildete Prozessmodell und dessen Variablen und Partner Links (siehe
Abbildung \ref{fig:VarNachTransformation}) nach der Transformation.
\end{itemize}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.4\textwidth]{img/screenshots/SimpleRefProcessTransformed}
\par\end{centering}

\caption{\label{fig:BeispielRRSProzessTransformiert}Transformiertes Beispiel
Prozessmodell}

\end{figure}
%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.3\textwidth]{img/screenshots/RefVariablesTransformed.JPG}
\par\end{centering}

\caption{\label{fig:VarNachTransformation}Variablen eines Prozessmodells nach
der Transformation}

\end{figure}



\subsection{\label{sub:Container-Referenzen-in-BPEL}Container-Referenzen in
BPEL (IPVS-Referenzen)}

Die Container-Referenzen sind einfache BPEL-Variablen, denen ein Datentyp
mit z.T. spezieller Struktur zugewiesen wird und die alle für den
Verweis auf eine Datenstruktureinheit notwendigen Informationen beinhalten.
So können in BPEL-Variablen Verweise auf Datenstruktureinheiten (Tabellen,
Schema, XML-Dokumente, Ordner, Dateien, usw.) von Datenquellen modelliert
werden. Diese Container-Referenzen (BPEL-Variablen) können dann bei
der Modellierung von Prozessen verwendet werden. Als Beispiel für
einen Datentyp mit spezieller Struktur wird die Verwendung von Container-Referenzen
in Abfragebefehlen von DM-Aktivitäten umgesetzt. Dafür wird der in
Listing \ref{lst:ContainerReferenceType} dargestellte Datentyp bereitgestellt,
mithilfe dessen die Angabe eines Schema- und Tabellennamens einer
SQL-Abfrage in einer BPEL-Variable hinterlegt werden kann.

\begin{center}

\begin{lstlisting}[caption={Schema des ContainerReferenceType-Datentyps},label={lst:ContainerReferenceType},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=2cm,xrightmargin=2cm]
<xsd:complexType name="ContainerReferenceType">
    <xsd:sequence>
        <xsd:element name="schema" type="xsd:string" 
            maxOccurs="1" minOccurs="0"/>
        <xsd:element name="table" type="xsd:string" 
            maxOccurs="1" minOccurs="1"/> 
    </xsd:sequence> 	
</xsd:complexType> 

\end{lstlisting}

\par\end{center}

Weiterhin können natürlich auch alle einfachen Datentypen (String,
Boolean, Integer, ...) für Container-Referenzen verwendet werden.
Um zwischen speziellen und einfachen Container-Referenzen in den Abfragebefehlen
unterscheiden zu können, werden diese entsprechend gekennzeichnet:
\emph{\#bpelVariable\#} signalisiert den Verweis auf eine einfache
Container-Referenz und \emph{{[}bpelVariable{]}} den Verweis auf eine
speziell strukturierte Container-Referenz. Die so formatiert in den
Abfragebefehlen hinterlegten BPEL-Variablen werden dann in der Workflow-Engine
aufgelöst und durch die aktuellen Werte der BPEL-Variablen ersetzt.

Durch dieses Konzept lassen sich dann Prozessmodelle mit DM-Aktivitäten
erstellen, die parametrisierbare Abfragebefehle enthalten. Um das
Verständnis zu erhöhen, wird dies nachfolgend an einem kleinen Beispiel
verdeutlicht (siehe Listing \ref{lst:ContainerReference-Beispiel}).
\begin{lstlisting}[caption={Auszug aus einem Prozessmodell
mit Container-Referenzen},label={lst:ContainerReference-Beispiel},basicstyle={\small\ttfamily},captionpos=b,frame=single,numbers=left,stepnumber=1,tabsize=4,xleftmargin={1cm},xrightmargin={1cm}]
***

<bpel:variable name="target" type="simpl:containerReferenceType"/>
<bpel:variable name="columns" type="ns1:string"/>

***

<bpel:extensionActivity>             
    <simpl:queryActivity name="QueryActivity" 
        dsKind="DB2" dsType="Database" 
        dsAddress="dd:myDB2" dsLanguage="SQL"  
        queryTarget="[target]"
        dsStatement="SELECT #columns# FROM DATA">
    </simpl:queryActivity>
</bpel:extensionActivity>

***

\end{lstlisting}


Das Beispiel basiert auf einem einfachen Prozessmodell mit einer Query-Aktivität.
Weiterhin werden zwei Container-Referenzen benötigt, eine vom Typ
\emph{string} für die Angabe der Spaltennamen einer Relation (Zeile
4) und eine vom Typ \emph{containerReferenceType} für die Angabe der
Zielrelation der Query-Aktivität (Zeile 3). Die Container-Referenzen
können nun über eine Assign-Aktivität auf einen festen Wert gesetzt
werden oder wie in unserem Fall aus der Eingabe des Prozesses zur
Laufzeit gelesen werden. In Zeile 12 hinterlegen wir nun im queryTarget-Attribut
der Query-Aktivität die Container-Referenz aus Zeile 3. In Zeile 13
hinterlegen wir im Abfragebefehl die Container-Referenz aus Zeile
4. Nun können wir das so erstellte Prozessmodell deployen und mit
geeigneten Werten für die hinterlegten Container-Referenzen instanzieren.
In ODE werden dann die Container-Referenzen aufgelöst und durch die
entsprechenden Werte ersetzt. So kann man ein- und dasselbe Prozessmodell
mit verschiedenen Eingaben immer wieder instanzieren und ausführen
ohne es neu deployen zu müssen.


\subsection{\label{sub:Data-Management-Aktivit=0000E4ten}Data-Management-Aktivitäten}

In diesem Abschnitt werden die zu realisierenden Datenmanagement-Patterns
zur Umsetzung einer generischen Unterstützung verschiedener Abfragesprachen
für BPEL vorgestellt und im weiteren Verlauf deren Realisierung für
die verschiedenen Datenquellen, d.h. für Dateisysteme, Datenbanken
und Sensornetze, erläutert. Aus den in Abschnitt \ref{sub:Umsetzung-der-Datenmanagement}
identifizierten Funktionen, die für die Umsetzung der Datenmanagement-Patterns
benötigt werden, werden dann in Abschnitt \ref{sub:Resultierende-BPEL-Aktivit=0000E4ten}
neue benötigte BPEL-Aktivitäten abstrahiert, die dann später die entsprechenden
Funktionen beinhalten und diese an die Datenquellen zur Ausführung
schicken.


\subsubsection{\label{sub:Datenmanagement-Patterns}Datenmanagement-Patterns}

In diesem Abschnitt werden alle Datenmanagement-Patterns, die zur
Realisierung einer generischen Anbindung von verschiedenen Datenquellen
benötigt werden, aufgeführt und beschrieben. Abbildung \ref{fig:Klassenhierarchie-der-Datenmanagement-Patterns}
zeigt die oberen Ebenen (0. Ebene bis 2.Ebene) der Klassenhierarchie
der verschiedenen Datenman-\\
agement-Patterns. Diese Hierarchie kann bei Bedarf beliebig um
weitere Patternklassen oder Patterns ergänzt werden. Die nachfolgenden
Beschreibungen orientieren sich an dieser Hierarchie und erläutern
sie gleichzeitig etwas detaillerter. Darüber hinaus werden nachfolgend
weitere Pattern-Klassen und Patterns eingeführt, die die Hierarchie
ab der 2. Ebene verfeinern und beschreiben. Die Klassenhierarchie
wird dabei von oben nach unten durchlaufen und ist aus Gründen der
Lesbarkeit auf mehrere Diagramme aufgeteilt, die in den entsprechenden
Beschreibungen folgen. Weiterhin wird in den Beschreibungen der Datenmanagement-Patterns
auf deren Anwendbarkeit auf verschiedene Datenquellentypen Bezug genommen.
Die Datenquellentypen sind dabei relationale Datenbanken, XML-Datenbanken,
Dateisysteme und Sensornetz-Datenbanken. Die Beschreibungen im Zusammenhang
mit Sensornetz-Datenbanken stützen sich dabei auf die TinyDB \cite{key-14},
die eine Schnittstelle für das Abfragen von Sensordaten mit einer
SQL-ähnlichen Sprache bereitstellt.

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/DM-Patterns}
\par\end{centering}

\caption{\label{fig:Klassenhierarchie-der-Datenmanagement-Patterns}Klassenhierarchie
der Datenmanagement-Patterns}



\end{figure}


Die Datenmanagement-Patterns gliedern sich hinsichtlich des Verarbeitungsortes
der von ihnen zu verarbeitenden Daten in drei grundlegende Klassen:
\begin{itemize}
\item \textbf{Single External Data Source Patterns}, die die Verarbeitung
von Daten in genau einer externen Datenquelle realisieren,
\item \textbf{Process Cache Patterns}, die die Verarbeitung von Daten in
genau einer internen Datenquelle, dem Prozessspeicher bzw. Cache,
realisieren und
\item \textbf{Multiple Data Source Patterns}, die die Verarbeitung von Daten
in mehr als einer Datenquelle realisieren, wobei der Prozessspeicher
hier auch als eine Datenquelle angesehen wird.
\end{itemize}
Daraus folgt direkt der weitere Aufbau der Klassenhierarchie, denn
alle Unterklassen der Klasse \textbf{Single External Data Source Patterns}
erfüllen ebenso deren grundlegende Eigenschaft. D.h. dass auch alle
Unterklassen Daten nur extern in genau einer Datenquelle verarbeiten
können. Etwas konkreter bedeutet dies, dass Daten nur auf einer externen
Datenquelle beispielsweise eingefügt, gelöscht, aktualisiert oder
abgefragt werden können. Wobei die abgefragten Daten auch in der gleichen
Datenquelle gespeichert werden, von der sie abgefragt wurden, z.B.
in einen temporären Datencontainer. Genau dasselbe gilt für die Unterklassen
der Klasse \textbf{Process Cache Patterns} mit dem Unterschied, dass
diese eben nur Daten in bzw. aus dem Prozessspeicher einfügen, abfragen,
löschen, usw. können.

In der nächsten Ebene (2.Ebene) der Klassenhierarchie werden die Klassen
dann bereits anhand der benötigten Funktionalitäten weiter verfeinert
(vgl. \cite{key-2}). Dazu gehören beispielsweise die Möglichkeiten,
Daten abzufragen (\textbf{Query Patterns}), neue Datenstrukturen zu
erstellen, zu ändern und zu verwerfen (\textbf{Data Setup Patterns})
oder auch Funktionalitäten, um Daten zwischen verschiedenen Datenquellen
zu verschieben oder zu kopieren (\textbf{Data Transport Patterns}).

Alle weiteren Ebenen (ab der 3.Ebene) verfeinern die Klassenhierarchie
noch weiter oder liefern die letztendlich durch BPEL-Aktivitäten umzusetzenden
Patterns. Die nachfolgenden Beschreibungen orientieren sich an den
sieben Klassen der 2.Ebene und erläutern die verschiedenen Ausprägungen
(Patterns) bzw. die Verfeinerungen (Unterklassen) dieser Klassen,
in den weiteren Ebenen.


\paragraph*{Query Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/diagrams/QueryPatterns}
\par\end{centering}

\caption{\label{fig:QueryPatterns}Übersicht über die Query Patterns-Klasse
und deren Patterns}



\end{figure}


Die Klasse Query Patterns beschreibt die Notwendigkeit, mithilfe von
entsprechenden Befehlen, wie z.B. SQL-Befehlen, XQuery-Befehlen oder
Systemaufrufen bei Dateisystemen, externe Daten anfordern zu können.
Die aus den Queries resultierenden Daten werden dabei auf der Datenquelle
gespeichert, von der sie auch abgefragt wurden. Da sich die verschiedenen
Datenquellentypen in der Art der Anfrage und der beteiligten Datenstrukturen/Datenmodelle
unterscheiden, gibt es drei verschiedene Ausprägungen (Patterns) der
Klasse, wie in Abbildung \ref{fig:QueryPatterns} zu sehen ist.
\begin{itemize}
\item Set Query Pattern: Für die Anfrage von relationalen (mengenorientierten)
Daten beispielsweise mittels SQL-Befehlen aus einer relationalen Datenbank
oder mittels SQL-ähnlichen Befehlen aus einer \\
Sensornetz-Datenbank (TinyDB).
\item Tree Query Pattern: Für die Anfrage von baumartigen Daten beispielsweise
mittels XQuery-Befehlen aus einer XML-Datenbank.
\item File Query Pattern: Für die Anfrage von verschiedenartig strukturierten
oder strukturlosen Daten mittels Systemaufrufen aus einem Dateisystem.
\end{itemize}

\paragraph*{Data IUD Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/diagrams/DataIUDPatterns}
\par\end{centering}

\caption{\label{fig:Data-IUD-Patterns}Übersicht über die Data IUD Patterns-Klasse
und deren Patterns}



\end{figure}


Die Klasse Data IUD Patterns beschreibt die Möglichkeit, auf Daten
verschiedene Datenmanipulations-Operationen ausführen zu können. Die
Daten und somit auch die möglichen Datenmanipulations-Operationen
unterscheiden sich nach der zugrundeliegenden Datenquelle und Datenstruktur.
Die Patterns dieser Klasse können für relationale Datenbanksysteme,
XML-Datenbanksysteme und Dateisysteme verwendet werden. Die Sensornetzdatenbank
TinyDB unterstützt das Manipulieren von Daten nicht, und dadurch sind
die Data IUD Patterns nicht für die TinyDB verwendbar (Beispiele siehe
Abschnitt \ref{sub:Sensornetze}).

Abbildung \ref{fig:Data-IUD-Patterns} zeigt die Data IUD Patternklasse,
die sich in folgende fünf operationsspezifische Unterklassen gliedert:
\begin{itemize}
\item \textbf{Data Insert Patterns} für das Einfügen neuer Daten.
\item \textbf{Data Update Patterns} für das Aktualisieren vorhandener Daten
durch beispielweise Aktualisierungsroutinen.
\item \textbf{Data Delete Patterns} für das Löschen vorhandener Daten.
\item \textbf{Data Replace Patterns} für das Ersetzen vorhandener Daten
durch neue Daten.
\item \textbf{Data Rename Patterns} für das Umbenennen vorhandener Daten.
\end{itemize}
Alle fünf Patternklassen werden durch die in Abbildung \ref{fig:Data-IUD-Patterns}
gezeigten Patterns umgesetzt, die sich aufgrund der beteiligten Datenstrukturen/Datenmodelle
unterscheiden. Im folgenden werden diese Patterns zusammengefasst
beschrieben, d. h. es folgt eine Beschreibung für jedes Datenmodell:
\begin{itemize}
\item Set Insert/Update/Delete Pattern: Diese Patterns beschreiben die Möglichkeit,
auf mengenorientierten externen Daten z.B. in einem relationalen Datenbanksystem
verschiedene Daten-\\
manipulationsoperationen ausführen zu können. Zu diesen Operationen
zählen das mengen- und tupelorientierte Einfügen (Set Insert Pattern),
Aktualisieren (Set Update Pattern) und Löschen (Set Delete Pattern)
von mengenorientierten Daten.
\item Tree Insert/Delete/Replace/Rename Pattern: Diese Patterns beschreiben
die Möglichkeit, verschiedene Datenmanipulationsoperationen auf Knoten,
Sequenzen von Knoten oder auch Teilbäumen von baumartigen externen
Daten z.B. in einem XML-Datenbanksystem ausführen zu können. Zu diesen
Operationen zählen das Einfügen (Tree Insert Pattern), Ersetzen (Tree
Replace Pattern), Umbenennen (Tree Rename Pattern) und Löschen (Tree
Delete Pattern) von Knoten, Sequenzen von Knoten und Teilbäumen.
\item Node Content Insert/Delete/Replace Pattern: Diese Patterns beschreiben
die Möglichkeit, verschiedene Datenmanipulationsoperationen in Knoten
von baumartigen externen Daten z.B. in einem XML-Datenbanksystem ausführen
zu können. Zu diesen Operationen zählen das Einfügen (Node Content
Insert Pattern), Ersetzen (Node Content Replace Pattern) und Löschen
(Node Content Delete Pattern) von Werten und Attributwerten innerhalb
von Knoten.
\item File Content Insert/Delete/Replace Pattern: Diese Patterns beschreiben
die Möglichkeit, verschiedene Datenmanipulationsoperationen innerhalb
von Dateien eines Dateisystems ausführen zu können. Zu diesen Operationen
zählen das Einfügen (File Content Insert Pattern), Ersetzen (File
Content Replace Pattern) und Löschen (File Content Delete Pattern)
von Dateiinhalten.
\end{itemize}

\paragraph*{Data Setup Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/diagrams/DataSetupPatterns}
\par\end{centering}

\caption{\label{fig:Data-Setup-Patterns}Übersicht über die Data Setup Patterns-Klasse
und deren Patterns}



\end{figure}


Die Klasse Data Setup Patterns liefert die Möglichkeit, Datenstrukturen
zu ändern. So können während der Prozessausführung die Datenquellen
konfiguriert oder neue Datenstruktureinheiten (Tabellen, Schema, XML-Dokumente,
Ordner, Dateien, Buffer-Tabellen, usw.) erstellt, geändert oder verworfen
werden.

Abbildung \ref{fig:Data-Setup-Patterns} zeigt die Data Setup Patternklasse
(Data Setup Patterns), die sich in folgende drei operationsspezifische
Unterklassen gliedert:
\begin{itemize}
\item \textbf{Data Setup Create Patterns}: Für das Erstellen neuer Datenstruktureinheiten.
\item \textbf{Data Setup Alter Patterns}: Für das Ändern bereits vorhandener
Datenstruktureinheiten.
\item \textbf{Data Setup Drop Patterns}: Für das Verwerfen vorhandener Datenstruktureinheiten.
\end{itemize}
Alle drei Patternklassen werden durch die in Abbildung \ref{fig:Data-Setup-Patterns}
gezeigten Patterns umgesetzt, die sich aufgrund der beteiligten Datenstrukturen/Datenmodelle
unterscheiden. Im folgenden werden diese Patterns zusammengefasst
beschrieben, d. h. es folgt eine Beschreibung für jedes einzelne Datenmodell.
\begin{itemize}
\item Create/Alter/Drop Set Container Pattern: Diese Patterns beschreiben
die Möglichkeit, neue Relationen in einem relationalen Datenbanksystem
zu erzeugen (Create Set Container Pattern), die Datenstrukturen vorhandener
Relationen zu bearbeiten (Alter Set Container Pattern) oder Relationen
zu löschen (Drop Set Container Pattern). In Sensornetz-Datenbanken
können mithilfe dieser Patterns auch Buffer-Tabellen erstellt und
gelöscht werden (Beispiele siehe Abschnitt \ref{sub:Sensornetze}).
\item Create/Alter/Drop Tree Container Pattern: Diese Patterns beschreiben
die Möglichkeit, neue XML-Dokumente in einem XML-Datenbanksystem zu
erzeugen (Create Tree Container Pattern), die Datenstrukturen vorhandener
XML-Dokumente zu bearbeiten (Alter Tree Container Pattern) oder XML-Dokumente
zu Löschen (Drop Tree Container Pattern).
\item Create/Alter/Drop File Directory Pattern: Diese Patterns beschreiben
die Möglichkeit, neue Ordner in einem Dateisystem zu erzeugen (Create
File Directory Pattern), vorhandene Ordner zu Bearbeiten (Alter File
Directory Pattern) oder zu löschen (Drop File Directory Pattern).
Ein Beispiel für die Bearbeitung eines vorhandenen Ordners ist das
Ändern seiner Zugriffsrechte.
\item Create/Alter/Drop File Pattern: Diese Patterns beschreiben die Möglichkeit,
neue Dateien in einem Dateisystem zu erzeugen (Create File Pattern),
vorhandene Dateien zu bearbeiten (Alter File Pattern) oder zu löschen
(Drop File Pattern). Ein Beispiel für die Bearbeitung einer vorhandenen
Datei ist das Ändern ihres Schreibschutzes.
\end{itemize}

\paragraph*{Stored Procedure Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.6]{img/diagrams/StoredProcedurePatterns}
\par\end{centering}

\caption{\label{fig:Stored-Procedure-Patterns}Übersicht über die Stored Procedure
Patterns-Klasse und deren Patterns}



\end{figure}


Abbildung \ref{fig:Stored-Procedure-Patterns} zeigt die Klasse Stored
Procedure Patterns, die im Moment nur eine Ausprägung hat, das Stored
Procedure Pattern. Trotzdem wurde für die Verarbeitung von Stored
Procedures eine extra Klasse eingeführt, so dass man in Zukunft weitere
Patterns dieser Klasse hinzufügen kann, wenn dafür Bedarf besteht.
Das Stored Procedure Pattern kann für relationale und XML-Datenbanksysteme
verwendet werden. Es wird benötigt, da die komplexe Verarbeitung von
Daten meist durch Stored Procedures realisiert wird, und es so für
die Verarbeitung von externen Daten unbedingt erforderlich ist, dass
Stored Procedures auch aus einem Prozess heraus aufgerufen werden
können. Dateisysteme und Sensornetze mit einer TinyDB unterstützen
dieses Pattern nicht, da es dort keinen vergleichbaren Ansatz zu Stored
Procedures gibt.


\paragraph*{Data Transport Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/diagrams/DataTransportPatterns}
\par\end{centering}

\caption{\label{fig:Data-Transport-Patterns}Übersicht über die Data Transport
Patterns-Klasse und deren Unterklassen}

\end{figure}


Die Klasse Data Transport Patterns liefert die Möglichkeit, Daten
zwischen zwei Datenquellen oder auch zwischen einer Datenquelle und
einem Cache (Prozessspeicher) zu verschieben oder zu kopieren.

Abbildung \ref{fig:Data-Transport-Patterns} zeigt die Data Transport
Patternklasse (Data Transport Patterns), die sich in folgende zwei
logische Unterklassen gliedert:
\begin{itemize}
\item \textbf{Process Cache Data Transport Patterns}: Für das Kopieren von
externen Daten in den Prozessspeicher (Data Retrieval to Process Cache
Patterns) und das Kopieren von internen Daten aus dem Prozessspeicher
auf eine externe Datenquelle (Process Cache WriteBack Patterns).
\item \textbf{External Data Transport Patterns}: Für das externe Kopieren
oder Verschieben von externen Daten in derselben Datenstruktur, wie
z.B. das Kopieren von relationalen Daten in eine relationale Datenbank
(Similar Data Transport Patterns) und für das externe Kopieren oder
Verschieben von externen Daten aus einer Datenstruktur in eine andere,
wie z.B. das Kopieren von relationalen Daten in eine XML-Datenbank
(Diverse Data Transport Patterns).
\end{itemize}
Diese beiden Unterklassen gliedern sich in weitere vier Unterklassen,
die im folgenden in extra Abschnitten näher beschrieben werden.


\paragraph*{Process Cache WriteBack Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.6]{img/diagrams/ProcessCacheWriteBackPatterns}
\par\end{centering}

\caption{\label{fig:Process-Cache-WriteBack-Patterns}Übersicht über die Process
Cache WriteBack Patterns-Klasse und deren Patterns}

\end{figure}


Die Klasse Process Cache WriteBack Patterns realisiert die Synchronisation
bzw. das Zurückschreiben eines lokalen Datencaches im Prozessspeicher
auf die originale Datenquelle.

Abbildung \ref{fig:Process-Cache-WriteBack-Patterns} zeigt die Process
Cache WriteBack Patterns, die sich in folgende drei Patterns gliedern: 
\begin{itemize}
\item Set Cache WriteBack Pattern: Realisiert das Zurückschreiben von mengenorientierten
Daten. Dieses Pattern ist auf relationale Datenbanken anwendbar. Es
ist nicht für die TinyDB verwendbar, da bei TinyDB keine Datenmanipulation
möglich ist.
\item Tree Cache WriteBack Pattern: Realisiert das Zurückschreiben von baumartigen
Daten z.B. auf XML-Datenbanken.
\item File Cache WriteBack. Pattern: Realisiert das Zurückschreiben von
Dateiinhalten auf Dateisysteme.
\end{itemize}

\paragraph*{Data Retrieval to Process Cache Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.6]{img/diagrams/DataRetrievaltoProcessCachePatterns}
\par\end{centering}

\caption{\label{fig:Data-Retrieval-2PC-Patterns}Übersicht über die Data Retrieval
to Process Cache Patterns-Klasse und deren Patterns}

\end{figure}


Die Klasse Data Retrieval to Process Cache Patterns kann für alle
Datenquellentypen verwendet werden. Sie dient dazu, externe Daten
in einen BPEL-Prozess zu laden, um diese dort verarbeiten zu können.
Die verschiedenen Ausprägungen der Data Retrieval to Process Cache
Patterns aus Abbildung \ref{fig:Data-Retrieval-2PC-Patterns} liefern
dafür entsprechende Datenstrukturen, in die man die angefragten externen
Daten innerhalb des BPEL-Prozesses ablegen kann. Diese Datenstrukturen
verhalten sich dabei wie Caches im BPEL-Prozess, die keine Verbindung
zur originalen Datenquelle besitzen.

Die Data Retrieval to Process Cache Patterns gliedern sich in folgende
drei Patterns: 
\begin{itemize}
\item Set Retrieval 2PC Pattern: Das Set Retrieval 2PC Pattern liefert eine
mengenorientierte Datenstruktur, um externe mengenorientierte Daten
im Prozessspeicher abzulegen. Es ist für relationale Datenbanken und
Sensornetze mit TinyDB anwendbar.
\item Tree Retrieval 2PC Pattern: Das Tree Retrieval 2PC Pattern ist z.B.
für XML-Datenbanken anwendbar und liefert eine baumartige Datenstruktur,
um externe baumartige Daten im Prozessspeicher abzulegen.
\item File Retrieval 2PC Pattern: Das File Retrieval 2PC Pattern ist für
Dateisysteme anwendbar und liefert eine Datenstruktur, in die man
aus einem Dateisystem abgefragte Daten innerhalb des BPEL-Prozesses
ablegen kann.
\end{itemize}

\paragraph*{Similar Data Transport Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.6\textwidth]{img/diagrams/SimilarDataTransportPatterns}
\par\end{centering}

\caption{\label{fig:Similar-Data-Transport-Patterns}Übersicht über die Similar
Data Transport Patterns-Klasse und deren Patterns}

\end{figure}


Die Klasse Similar Data Transport Patterns kann für alle Datenquellentypen
verwendet werden. Sie dient dazu, externe Daten von externen Datenquellen
auf andere externe Datenquellen zu verschieben oder zu kopieren, wobei
die Datenstruktur der zu verschiebenden/kopierenden Daten unverändert
bleibt.

Abbildung \ref{fig:Similar-Data-Transport-Patterns} zeigt die Similar
Data Transport Patterns, die sich in folgende zwei Klassen gliedern: 
\begin{itemize}
\item \textbf{Similar Data Move Patterns}: Für das Verschieben von externen
Daten auf externen Datenquellen, wobei die Datenstruktur unverändert
bleibt und die originalen Daten gelöscht werden.
\item \textbf{Similar Data Copy Patterns}: Für das Kopieren von externen
Daten auf externen Datenquellen, wobei die Datenstruktur und die originalen
Daten unverändert bleiben.
\end{itemize}
Beide Patternklassen werden durch die in Abbildung \ref{fig:Similar-Data-Transport-Patterns}
gezeigten Patterns umgesetzt, die sich aufgrund der beteiligten Datenstrukturen/Datenmodelle
unterscheiden. Im Folgenden werden diese Patterns zusammengefasst
beschrieben, d. h. es folgt eine Beschreibung für jedes einzelne Datenmodell.
\begin{itemize}
\item Move/Copy Set2Set Pattern: Liefert die Möglichkeit, externe mengenorientierte
Daten von einer externen Datenquelle auf eine andere externe Datenquelle
zu kopieren oder zu verschieben. Die Datenstruktur der Daten bleibt
dabei unverändert mengenorientiert. Dieses Pattern ist für relationale
Datenbanken anwendbar.
\item Move/Copy Tree2Tree Pattern: Liefert die Möglichkeit, externe baumorientierte
Daten von einer externen Datenquelle auf eine andere externe Datenquelle
zu kopieren oder zu verschieben. Die Datenstruktur der Daten bleibt
dabei unverändert baumorientiert. Dieses Pattern ist für XML-Datenbanken
anwendbar.
\item Move/Copy File2File Pattern: Liefert die Möglichkeit, externe Daten
aus Dateien von einer externen Datenquelle auf eine andere externe
Datenquelle zu kopieren oder zu verschieben. Die Datenstruktur der
Daten bleibt dabei unverändert. Dieses Pattern ist für Dateisysteme
anwendbar.
\end{itemize}

\paragraph*{Diverse Data Transport Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.6\textwidth]{img/diagrams/DiverseDataTransportPatterns}
\par\end{centering}

\caption{\label{fig:Diverse-Data-Transport-Patterns}Übersicht über die Diverse
Data Transport Patterns-Klasse und deren Patterns}

\end{figure}


Die Klasse Diverse Data Transport Patterns kann für alle Datenquellentypen
verwendet werden. Sie dient dazu, externe Daten von externen Datenquellen
auf andere externe Datenquellen zu verschieben oder zu kopieren, wobei
sich die Datenstruktur der zu verschiebenden/kopierenden Daten ändert,
d.h. die Daten werden in eine andere Datenstruktur überführt.

Abbildung \ref{fig:Diverse-Data-Transport-Patterns} zeigt die Diverse
Data Transport Patterns, die sich in folgende zwei Klassen gliedern: 
\begin{itemize}
\item \textbf{Diverse Data Move Patterns}: Für das Verschieben von externen
Daten auf externen Datenquellen mit veränderter Datenstruktur. Die
originalen Daten werden gelöscht.
\item \textbf{Diverse Data Copy Patterns}: Für das Kopieren von externen
Daten auf externen Datenquellen mit veränderter Datenstruktur. Die
originalen Daten bleiben unverändert.
\end{itemize}
Beide Patternklassen werden durch die in Abbildung \ref{fig:Diverse-Data-Transport-Patterns}
gezeigten Patterns umgesetzt, die sich aufgrund der beteiligten Datenstrukturen/Datenmodelle
unterscheiden. Im Folgenden werden nur drei dieser Patterns beschrieben,
da bei den verbleibenden drei Patterns jeweils nur eine umgekehrte
Datenmodell-Transformation durchgeführt wird.
\begin{itemize}
\item Move/Copy Set2Tree Pattern: Liefert die Möglichkeit, externe mengenorientierte
Daten z.B. aus einer relationalen Datenbank oder einer Sensornetz-Datenbank
auf eine XML-Datenbank als baumartige Daten zu kopieren oder zu verschieben.
Dieses Pattern ist für relationale Datenbanken, Sensortnetz- und XML-Datenbanken
anwendbar, wobei die relationalen bzw. Sensornetz-Datenbanken nur
als Quelle und die XML-Datenbanken nur als Ziel der Kopier- bzw. Verschiebe-Operation
verwendet werden können.
\item Move/Copy File2Set Pattern: Liefert die Möglichkeit, externe Daten
z.B. aus Dateisystemen auf eine relationale Datenbank als mengenorientierte
Daten zu kopieren oder zu verschieben. Dieses Pattern ist für Dateisysteme
und relationale Datenbanken anwendbar, wobei die Dateisysteme nur
als Quelle und die relationalen Datenbanken nur als Ziel der Kopier-
bzw. Verschiebe-Operation verwendet werden können. Die Sensornetz-Datenbank
TinyDB kann hier nicht als Ziel angegeben werden, da auf ihr keine
Datenmanipulation möglich ist.
\item Move/Copy File2Tree Pattern: Liefert die Möglichkeit, externe Daten
z.B. aus Dateisystemen auf eine XML-Datenbank als baumartige Daten
zu kopieren oder zu verschieben. Dieses Pattern ist für Dateisysteme
und XML-Datenbanken anwendbar, wobei die Dateisysteme nur als Quelle
und die XML-Datenbanken nur als Ziel der Kopier- bzw. Verschiebe-Operation
verwendet werden können.
\end{itemize}

\paragraph*{Cache Access Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/CacheAccessPatterns}
\par\end{centering}

\caption{\label{fig:Cache-Access-Patterns}Übersicht über die Cache Access
Patterns-Klasse und deren Unterklassen}

\end{figure}


Die Klasse Cache Access Patterns beschreibt die Notwendigkeit, auf
den im BPEL-Prozess erzeugten Prozessspeicher in geeigneter Weise
zugreifen zu können. Die weiteren Unterklassen unterscheiden sich
durch die zugrundeliegende Datenstruktur der Daten im Prozessspeicher.
Die einzelnen Patterns dieser Klassen liefern verschiedene Zugriffsmöglichkeiten
auf die Daten im Prozessspeicher. Da diese Zugriffsmöglichkeiten je
nach Datenstruktur variieren, wird auf diese in den nachfolgenden
Beschreibungen näher eingegangen.

Abbildung \ref{fig:Cache-Access-Patterns} zeigt die Cache Access
Patterns, die sich in folgende drei Klassen gliedern:
\begin{itemize}
\item \textbf{Set Cache Access Patterns}: Die Set Cache Access Patterns
liefern die Möglichkeit, auf den im BPEL-Prozess erzeugten mengenorientierten
Prozessspeicher sequentiell und direkt (wahlfrei) zugreifen zu können.

\begin{itemize}
\item Set Cache Sequential Access Pattern: Liefert den sequentiellen Zugriff
auf die mengenorientierte Datenstruktur, d.h. die Relation wird von
ihrem ersten Element bis zu ihrem letzten Element oder umgekehrt schrittweise
durchlaufen, wobei in einem Schritt immer nur das vorherige oder das
nächste Element der Relation erreicht werden kann.
\item Set Cache Direct Access Pattern: Liefert den direkten (wahlfreien)
Zugriff auf die mengenorientierte Datenstruktur, d.h. jedes beliebige
Element der Relation kann direkt z.B. über einen Index ausgewählt
werden.
\end{itemize}
\item \textbf{Tree Cache Access Patterns}: Die Tree Cache Access Patterns
liefern die Möglichkeit, auf den erzeugten baumorientierten Prozessspeicher
hierarchisch, sequentiell und direkt (wahlfrei) zugreifen zu können. 

\begin{itemize}
\item Tree Cache Hierarchical Access Pattern: Liefert den hierarchischen
Zugriff, der durch entsprechende Funktionen realisiert wird, die die
Kindknoten oder den Vaterknoten des ausgewählten Knoten liefern. Über
den Wurzelknoten als Startpunkt kann so der ganze Baum hierarchisch
in beiden Richtungen (Wurzel -> Blatt vs. Blatt ->Wurzel) durchlaufen
werden.
\item Tree Cache Sequential Access Pattern: Liefert den sequentiellen Zugriff
auf einen Baum. Dies wird durch entsprechende Funktionen realisiert,
die den linken oder rechten Geschwisterknoten bzw. den nächsten Knoten
der nächst tieferen (höheren) Ebene, falls die aktuelle Ebene bereits
durchlaufen wurde, des ausgewählten Knoten liefern. Über den Wurzelknoten
als Startpunkt kann jede Ebene des ganzen Baums sequentiell durchlaufen
werden. Dabei kann in jedem Schritt immer nur der nächste oder vorherige
Knoten aus der Knotensequenz erreicht werden.
\item Tree Cache Direct Access Pattern: Liefert den direkten Zugriff auf
einen einzelnen Knoten im Baum beispielsweise durch die Angabe eines
XPath-Ausdrucks (siehe \cite{key-24}), mit dem der entsprechende
Knoten im Baum gesucht und zurückgegeben wird, falls ein solcher Knoten
existiert.
\end{itemize}
\item \textbf{File Cache Access Patterns}: Die File Cache Access Patterns
liefern die Möglichkeit, auf Dateiinhalte eines erzeugten Prozessspeichers
in geeigneter Weise (z.B. sequentiell oder wahlfrei) zugreifen zu
können. Die Klasse kann durch weitere dateiformatspezifische Unterklassen
verfeinert werden. Im Moment wird nur das Dateiformat Comma Separated
Values (CSV) näher betrachtet und beschrieben.

\begin{itemize}
\item CSV File Cache Access Patterns: Die CSV File Cache Access Patterns
liefern die Möglichkeit, auf den erzeugten CSV-Datencache sequentiell
und direkt (wahlfrei) zugreifen zu können.

\begin{itemize}
\item CSV File Cache Sequential Access Pattern: Liefert den sequentiellen
Zugriff auf die CSV-Daten, d.h. die Daten werden von der ersten Zeile
bis zu der letzten Zeile zeilenweise durchlaufen, wobei in einem Schritt
immer nur die vorherige oder die nachfolgende Zeile erreichbar ist.
\item CSV File Cache Direct Access Pattern: Liefert den direkten (wahlfreien)
Zugriff auf die CSV-Daten, d.h. jede beliebige Zeile der Daten kann
direkt z.B. über einen Index ausgewählt werden.
\end{itemize}
\end{itemize}
\end{itemize}

\paragraph*{Cache IUD Patterns}

%
\begin{figure}[H]
\begin{centering}
\includegraphics[width=1\textwidth]{img/diagrams/CacheIUDPatterns}
\par\end{centering}

\caption{\label{fig:Cache-IUD-Patterns}Übersicht über die Cache IUD Patterns-Klasse
und deren Patterns}

\end{figure}


Die Klasse Cache IUD Patterns beschreibt die Notwendigkeit, dass in
einen Prozessspeicher auch Daten eingefügt, aktualisiert, umbenannt,
ersetzt und wieder aus diesem gelöscht werden können.

Abbildung \ref{fig:Cache-IUD-Patterns} zeigt die Cache IUD Patternklasse,
die sich in folgende fünf operationsspezifische Unterklassen gliedert:
\begin{itemize}
\item \textbf{Cache Insert Patterns} für das Einfügen neuer Daten in den
Prozessspeicher.
\item \textbf{Cache Update Patterns} für das Aktualisieren vorhandener Daten
im Prozessspeicher durch beispielweise Aktualisierungsroutinen.
\item \textbf{Cache Delete Patterns} für das Löschen vorhandener Daten im
Prozessspeicher.
\item \textbf{Cache Replace Patterns} für das Ersetzen vorhandener Daten
im Prozessspeicher durch neue Daten.
\item \textbf{Cache Rename Patterns} für das Umbenennen vorhandener Daten
im Prozessspeicher.
\end{itemize}
Alle fünf Patternklassen werden durch die in Abbildung \ref{fig:Cache-IUD-Patterns}
gezeigten Patterns umgesetzt, die sich aufgrund der beteiligten Datenstrukturen/Datenmodelle
unterscheiden. Im Folgenden werden diese Patterns zusammengefasst
beschrieben, d. h. es folgt eine Beschreibung für jedes einzelne Datenmodell.
\begin{itemize}
\item Set Cache Insert/Update/Delete Pattern: Diese Patterns beschreiben
die Möglichkeit, auf mengenorientierten internen Daten im Prozessspeicher
verschiedene Datenmanipulationsoperationen ausführen zu können. Zu
diesen Operationen zählen das mengen- und tupelorientierte Einfügen
(Set Cache Insert Pattern), Aktualisieren (Set Cache Update Pattern)
und Löschen (Set Cache Delete Pattern) von mengenorientierten Daten.
\item Tree Cache Insert/Delete/Replace/Rename Pattern: Diese Patterns beschreiben
die Möglichkeit, verschiedene Datenmanipulationsoperationen auf Knoten,
Sequenzen von Knoten oder auch Teilbäumen von baumartigen internen
Daten im Prozessspeicher ausführen zu können. Zu diesen Operationen
zählen das Einfügen (Tree Cache Insert Pattern), Ersetzen (Tree Cache
Replace Pattern), Umbenennen (Tree Cache Rename Pattern) und Löschen
(Tree Cache Delete Pattern) von Knoten, Sequenzen von Knoten und Teilbäumen.
\item Node Content Cache Insert/Delete/Replace Pattern: Diese Patterns beschreiben
die Möglichkeit, verschiedene Datenmanipulationsoperationen in Knoten
von baumartigen internen Daten im Prozessspeicher ausführen zu können.
Zu diesen Operationen zählen das Einfügen (Node Content Cache Insert
Pattern), Ersetzen (Node Content Cache Replace Pattern) und Löschen
(Node Content Cache Delete Pattern) von Werten und Attributwerten
innerhalb von Knoten.
\item File Content Cache Insert/Delete/Replace Pattern: Diese Patterns beschreiben
die Möglichkeit, verschiedene Datenmanipulationsoperationen innerhalb
von Daten, die aus Dateien ausgelesen wurden, im Prozessspeicher ausführen
zu können. Zu diesen Operationen zählen das Einfügen (File Content
Cache Insert Pattern), Ersetzen (File Content Cache Replace Pattern)
und Löschen (File Content Cache Delete Pattern) von Daten im Prozessspeicher.
\end{itemize}
Tabelle \ref{tab:=0000DCbersicht-der-Datenmanagement-Patterns} zeigt
eine Übersicht aller Datenmanagement-Patterns, die für den Umgang
mit verschiedenen Datenquellentypen benötigt werden, und welche Patterns
für welche Datenquellentypen verwendet werden können (durch {}``x''
markiert). Die External Data Transport Patterns werden nicht in der
Tabelle aufgeführt, da sie im Rahmen dieses Projekts nicht umgesetzt
werden.

%
\begin{table}[H]


\caption{\label{tab:=0000DCbersicht-der-Datenmanagement-Patterns}Übersicht
der Datenmanagement-Patterns und der von diesen unterstützten Datenquellentypen}


\centering{}\begin{tabular}{|>{\raggedright}p{5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{2cm}|>{\centering}p{1.5cm}|}
\hline 
Datenmanagement-Pattern & rel. DB & XML-DB & Dateisys. & Sensor.-DB & Cache\tabularnewline
\hline
\hline 
Set Query Pattern & x &  &  & x & \tabularnewline
\hline 
Tree Query Pattern &  & x &  &  & \tabularnewline
\hline 
File Query Pattern &  &  & x &  & \tabularnewline
\hline 
Set Insert Pattern & x &  &  &  & \tabularnewline
\hline 
Set Update Pattern & x &  &  &  & \tabularnewline
\hline 
Set Delete Pattern & x &  &  &  & \tabularnewline
\hline 
Tree Insert Pattern &  & x &  &  & \tabularnewline
\hline 
Tree Delete Pattern &  & x &  &  & \tabularnewline
\hline 
Tree Replace Pattern &  & x &  &  & \tabularnewline
\hline 
Tree Rename Pattern &  & x &  &  & \tabularnewline
\hline 
Node Content Insert Pattern &  & x &  &  & \tabularnewline
\hline 
Node Content Delete Pattern &  & x &  &  & \tabularnewline
\hline 
Node Content Replace Pattern &  & x &  &  & \tabularnewline
\hline 
File Content Insert Pattern &  &  & x &  & \tabularnewline
\hline 
File Content Delete Pattern &  &  & x &  & \tabularnewline
\hline 
File Content Replace Pattern &  &  & x &  & \tabularnewline
\hline 
Create Set Container Pattern & x &  &  &  & \tabularnewline
\hline 
Alter Set Container Pattern & x &  &  &  & \tabularnewline
\hline 
Drop Set Container Pattern & x &  &  &  & \tabularnewline
\hline 
Create Tree Container Pattern &  & x &  &  & \tabularnewline
\hline 
Alter Tree Container Pattern &  & x &  &  & \tabularnewline
\hline 
Drop Tree Container Pattern &  & x &  &  & \tabularnewline
\hline 
Create File Directory Pattern &  &  & x &  & \tabularnewline
\hline 
Alter File Directory Pattern &  &  & x &  & \tabularnewline
\hline 
Drop File Directory Pattern &  &  & x &  & \tabularnewline
\hline 
Create File Pattern &  &  & x &  & \tabularnewline
\hline 
Alter File Pattern &  &  & x &  & \tabularnewline
\hline 
Drop File Pattern &  &  & x &  & \tabularnewline
\hline 
Stored Procedure Pattern & x & x &  &  & \tabularnewline
\hline 
Set Retrieval 2PC Pattern & x &  &  & x & x\tabularnewline
\hline 
Set Cache Sequential Access Pattern &  &  &  &  & x\tabularnewline
\hline 
Set Cache Direct Access Pattern &  &  &  &  & x\tabularnewline
\hline 
Set Cache Insert Pattern &  &  &  &  & x\tabularnewline
\hline 
Set Cache Update Pattern &  &  &  &  & x\tabularnewline
\hline 
Set Cache Delete Pattern &  &  &  &  & x\tabularnewline
\hline 
Set Cache WriteBack Pattern & x &  &  &  & x\tabularnewline
\hline
\end{tabular}
\end{table}


%
\begin{table}[H]
\centering{}\begin{tabular}{|>{\raggedright}p{5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{2cm}|>{\centering}p{1.5cm}|}
\hline 
Datenmanagement-Pattern & rel. DB & XML-DB & Dateisys. & Sensor.-DB & Cache\tabularnewline
\hline
\hline 
Tree Retrieval 2PC Pattern &  & x &  &  & x\tabularnewline
\hline 
Tree Cache Hierarchical Access Pattern &  &  &  &  & x\tabularnewline
\hline 
Tree Cache Sequential Access Pattern &  &  &  &  & x\tabularnewline
\hline 
Tree Cache Direct Access Pattern &  &  &  &  & x\tabularnewline
\hline 
Tree Cache Insert Pattern &  &  &  &  & x\tabularnewline
\hline 
Tree Cache Delete Pattern &  &  &  &  & x\tabularnewline
\hline 
Tree Cache Replace Pattern &  &  &  &  & x\tabularnewline
\hline 
Tree Cache Rename Pattern &  &  &  &  & x\tabularnewline
\hline 
Node Content Cache Insert Pattern &  &  &  &  & x\tabularnewline
\hline 
Node Content Cache Delete Pattern &  &  &  &  & x\tabularnewline
\hline 
Node Content Cache Replace Pattern &  &  &  &  & x\tabularnewline
\hline 
Tree Cache WriteBack Pattern &  & x &  &  & x\tabularnewline
\hline 
File Retrieval 2PC Pattern &  &  & x &  & x\tabularnewline
\hline 
CSV File Cache Sequential Access Pattern &  &  &  &  & x\tabularnewline
\hline 
CSV File Cache Direct Access Pattern &  &  &  &  & x\tabularnewline
\hline 
File Content Cache Insert Pattern &  &  &  &  & x\tabularnewline
\hline 
File Content Cache Delete Pattern &  &  &  &  & x\tabularnewline
\hline 
File Content Cache Replace Pattern &  &  &  &  & x\tabularnewline
\hline 
File Cache WriteBack Pattern &  &  & x &  & x\tabularnewline
\hline
\end{tabular}
\end{table}



\subsubsection{\label{sub:Umsetzung-der-Datenmanagement}Umsetzung der Datenmanagement-Patterns}

In diesem Abschnitt wird die Realisierung der verschiedenen Datenmanagement-Patterns
aus Abschnitt \ref{sub:Datenmanagement-Patterns} im Zusammenhang
mit den jeweiligen Datenquellentypen beschrieben. Einige Patterns
werden dabei nicht oder nur für manche Datenquellen aufgrund ihrer
Komplexität umgesetzt.


\subsubsection*{\label{sub:DMPatterns-Umsetzung-RDB}Relationale Datenbanken}

Hier wird die Umsetzung der in Abschnitt \ref{sub:Datenmanagement-Patterns}
beschriebenen Patterns im Bereich der SQL-\\
Datenbanken durch bestehende SQL-Befehle oder, falls erforderlich,
durch die Definition neuer zu implementierender Funktionen beschrieben.
\begin{itemize}
\item Set Query Pattern: Realisierung durch SQL-SELECT.

\begin{itemize}
\item Beispiel: 

\begin{itemize}
\item SELECT info FROM customer
\end{itemize}
\end{itemize}
\item Set Insert Pattern: Realisierung durch SQL-INSERT.

\begin{itemize}
\item Beispiele: 

\begin{itemize}
\item INSERT INTO department VALUES (\textquoteright{}E31\textquoteright{},
\textquoteright{}architecture\textquoteright{}, \textquoteright{}00390\textquoteright{},
\textquoteright{}E01\textquoteright{})
\item INSERT INTO department SELECT {*} FROM old\_department
\end{itemize}
\end{itemize}
\item Set Update Pattern: Realisierung durch SQL-UPDATE.

\begin{itemize}
\item Beispiel: UPDATE employee SET job = \textquoteright{}laborer\textquoteright{}
WHERE empno = \textquoteright{}000290\textquoteright{}
\end{itemize}
\item Set Delete Pattern: Realisierung durch SQL-DELETE.

\begin{itemize}
\item Beispiel: DELETE FROM department WHERE deptno = \textquoteright{}D11\textquoteright{}
\end{itemize}
\item Create Set Container Pattern: Realisierung durch SQL-CREATE SCHEMA,
SQL-CREATE TABLE, SQL-CREATE VIEW und weitere SQL-CREATE Befehle. 

\begin{itemize}
\item Beispiele: 

\begin{itemize}
\item CREATE SCHEMA internal AUTHORIZATION admin
\item CREATE TABLE tdept (deptno CHAR(3) NOT NULL, deptname VARCHAR(36)
\\
NOT NULL, mgrno CHAR(6), admrdept CHAR(3) NOT NULL, \\
PRIMARY KEY(deptno)) IN internal 
\item CREATE VIEW internal.departmentView AS \\
SELECT deptno, deptname FROM internal.tdept
\end{itemize}
\end{itemize}
\item Drop Set Container Pattern: Realisierung durch SQL-DROP.

\begin{itemize}
\item Beispiele: 

\begin{itemize}
\item DROP SCHEMA internal
\item DROP TABLE tdept
\item DROP VIEW internal.departmentView
\end{itemize}
\end{itemize}
\item Alter Set Container Pattern: Wird nicht umgesetzt. Realisierung über
SQL-ALTER Befehle möglich.

\begin{itemize}
\item Beispiel: ALTER TABLE department DROP CONSTRAINT deptno
\end{itemize}
\item Stored Procedure Pattern: Realisierung durch SQL-CALL.

\begin{itemize}
\item Beispiel: CALL parts\_on\_hand (?,?,?) \textit{(? = Parameter der
Prozedur)}
\end{itemize}
\item Set Retrieval 2PC Pattern: Realisierung durch die Definition und Bereitstellung
einer entsprechenden BPEL-Aktivität. Diese Aktivität liefert die Möglichkeit,
dass durch einen SQL-SELECT Befehl abgefragte Daten (siehe Query Pattern)
in den BPEL-Prozess geladen und in einer entsprechenden BPEL-Variable
ablegt werden können. Dazu müssen neue Variablentypen bereitgestellt
werden, die den Strukturen der zu haltenden Daten entsprechen, also
mengenorientierte Daten halten können. Die Daten werden dazu über
das \emph{Service Data Objects Application Programming Interface}
(SDO API) abstrahiert. Wie in \cite{key-2} beschrieben, wurde dieses
Konzept bereits durch die \emph{Business Integration Suite} und dem
darin enthaltenen \emph{WebSphere Integration Developer} mit der Bezeichnung
\emph{{}``Retrieve Set Activity''} realisiert. Dabei werden in einer
Retrieve Set Activity externe Daten in eine XML-Struktur in den Prozessspeichers
geladen. Eine etwas ausführlichere Beschreibung dieses Ansatzes liefert
\cite{key-2}. Unser Ansatz beschränkt sich zunächst auf die Möglichkeiten,
die durch die SDO API und die \emph{Data Access Services} (DAS) API
bereitgestellt werden.
\item Set Cache Sequential/Direct Access Pattern: Um diese Patterns zu realisieren,
müssen Methoden in BPEL bereitgestellt werden, die einen sequentiellen
und direkten Zugriff auf den durch das Set Retrieval 2PC Pattern erzeugten
Prozessspeicher ermöglichen. Die SDO API liefert dafür bereits einige
Methoden, die verwendet werden können und auf die wir uns zunächst
beschränken. Weiterhin soll bei einem sequentiellen Zugriff auch mit
einer ForEach-Aktivität (siehe \cite{key-4}) über die mengenorientierten
Daten iteriert werden können.
\item Set Cache Insert/Update/Delete Pattern: Erweitern die Set Cache Access
Patterns Methoden um die Möglichkeiten, Tupel innerhalb der mengenorientierten
Datenstruktur im Prozessspeicher zu aktualisieren, einzufügen und
zu löschen. Die SDO API liefert dafür bereits einige Methoden, die
verwendet werden können und auf die wir uns zunächst beschränken.
\item Set Cache WriteBack Pattern: Um die Daten aus dem Prozessspeicher
zurück auf die originale Datenbank zu übertragen, muss eine neue BPEL-Aktivität
erstellt werden, durch die der Benutzer angibt, dass die Daten zurückgeschrieben
werden sollen. Diese Aktivität nutzt dann intern die Funktionalität
der Data IUD Patterns und Cache Access Patterns sowie weitere SQL-Befehle,
um die Daten aus dem Prozesscache auf die Datenbank zu übertragen.
Die SDO API und die DAS API liefern dafür bereits einige Methoden,
die verwendet werden können und auf die wir uns zunächst beschränken.
\end{itemize}

\subsubsection*{XML-Datenbanken}

Hier wird die Umsetzung der in Abschnitt \ref{sub:Datenmanagement-Patterns}
beschriebenen Patterns im Bereich der XQuery-Datenbanken durch bestehende
XQuery-Befehle oder, falls erforderlich, durch die Definition neuer
zu implementierender Funktionen beschrieben.
\begin{itemize}
\item Tree Query Pattern: Realisierung durch entsprechende FLWOR-Befehle.

\begin{itemize}
\item Beispiel: FOR \$d IN fn:doc({}``department.xml'')/employees/employee
RETURN \$d/name
\end{itemize}
\item Tree Insert Pattern: Realisierung durch entsprechende Befehle der
XQuery Update Facility (siehe \cite{key-22}).

\begin{itemize}
\item Beispiel: INSERT NODE <phone>123456</phone> AFTER \\
fn:doc(\textquotedbl{}department.xml\textquotedbl{})/employees/employee{[}1{]}/name
\end{itemize}
\item Tree Delete Pattern: Realisierung durch entsprechende Befehle der
XQuery Update Facility.

\begin{itemize}
\item Beispiel: DELETE NODE fn:doc(\textquotedbl{}department.xml\textquotedbl{})/employees/employee{[}1{]}/phone{[}last(){]}
\end{itemize}
\item Tree Replace Pattern: Realisierung durch entsprechende Befehle der
XQuery Update Facility.

\begin{itemize}
\item Beispiel: REPLACE NODE fn:doc(\textquotedbl{}department.xml\textquotedbl{})/employees/employee{[}1{]}/phone
WITH \\
fn:doc(\textquotedbl{}department2.xml\textquotedbl{})/employees/employee{[}20{]}/phone 
\end{itemize}
\item Tree Rename Pattern: Realisierung durch entsprechende Befehle der
XQuery Update Facility.

\begin{itemize}
\item Beispiel: RENAME NODE fn:doc(\textquotedbl{}department.xml\textquotedbl{})/employees/employee{[}1{]}/phone{[}2{]}
AS \textquotedbl{}privatePhone\textquotedbl{}
\end{itemize}
\item Node Content Insert Pattern: Realisierung durch entsprechende Befehle
der XQuery Update Facility.

\begin{itemize}
\item Beispiel:
\end{itemize}
\item Node Content Delete Pattern: Realisierung durch entsprechende Befehle
der XQuery Update Facility.

\begin{itemize}
\item Beispiel:
\end{itemize}
\item Node Content Replace Pattern: Realisierung durch entsprechende Befehle
der XQuery Update Facility.

\begin{itemize}
\item Beispiel: REPLACE VALUE OF NODE fn:doc(\textquotedbl{}department.xml\textquotedbl{})/expectedSales/total\\
WITH fn:doc(\textquotedbl{}department.xml\textquotedbl{})/expectedSales/total
+ 50000
\end{itemize}
\item Create Tree Container Pattern: Wird nicht realisiert.
\item Alter Tree Container Pattern: Wird nicht realisiert.
\item Drop Tree Container Pattern: Wird nicht realisiert.
\item Stored Procedure Pattern: Wird nicht realisiert.
\item Tree Retrieval 2PC Pattern: Die Umsetzung erfolgt nach der Beschreibung
des Set Retrieval 2PC Patterns für relationale Datenbanken, wobei
hier XQuery-Befehle verwendet und baumartige Daten in einer BPEL-Variable
abgelegt werden.
\item Tree Cache Hierarchical/Sequential/Direct Access Pattern: Werden nicht
realisiert.
\item Tree Cache Insert/Delete/Replace/Rename Pattern: Werden nicht realisiert.
\item Node Content Cache Insert/Delete/Replace Pattern: Werden nicht realisiert.
\item Tree Cache WriteBack Pattern: Wird nicht realisiert.
\end{itemize}

\subsubsection*{Dateisysteme}

Hier wird die Umsetzung der in Abschnitt \ref{sub:Datenmanagement-Patterns}
beschriebenen Patterns im Bereich der Dateisysteme durch entsprechende
Systemaufrufe des dem Dateisystem zugrundeliegenden Betriebssystems
beschrieben. Die Umsetzung der Patterns für Dateisysteme beschränkt
sich dabei auf das CSV-Dateiformat.
\begin{itemize}
\item File Query Pattern: Realisierung durch einen GET-Befehl, der intern
java.io Methoden verwendet, um Inhalte aus Dateien oder komplette
Dateien aus einem Dateisystem zu lesen. Für das Abfragen von Dateiinhalten
muss noch ein Konzept erarbeitet werden, wie entsprechende Daten gezielt
über einen Befehl ausgewählt und abgefragt werden können. Eine Möglichkeit
wäre z.B. einen Filter-Dialog zur Angabe von Suchparametern über die
GUI bereitzustellen, der es ermöglicht Dateiinhalte zu suchen und
zurückzugeben. Das Abfragen von Dateiinhalten wird nicht realisiert.
\item File Content Insert/Delete/Replace Pattern: Realisierung durch einen
entsprechenden PUT- bzw. REMOVE-Befehl (RM), die intern java.io Methoden
verwenden, um Inhalte in Dateien zu schreiben, zu ersetzen und aus
ihnen zu löschen. Ein Ersetzen wird bei Dateien intern durch das Löschen
des alten Wertes und anschließendem Einfügen des neuen Wertes ausgeführt.
Dafür muss noch ein Konzept erarbeitet werden, wie entsprechende Informationen
gezielt über einen Befehl eingefügt, ersetzt und gelöscht werden können.
Es wird nur das Einfügen, Ersetzen und Löschen von vollständigen Dateiinhalten
umgesetzt. Das Einfügen, Ersetzen und Löschen von Dateiinhalten wird
nicht realisiert.
\item Create/Alter/Drop File Pattern: Realisierung z.B. durch die Verwendung
entsprechender Erzeugungsbefehle, wie MKFILE zur Erzeugung oder RMFILE
für das Löschen von Dateien. Diese werden intern wieder durch java.io-Methoden
realisiert. Hier sollte es auf jeden Fall möglich sein, Dateien in
einem Dateisystem zu erzeugen. Ebenso sollte das Löschen auf der gleichen
Ebene, d.h. von ganzen Dateien, möglich sein. Andere Operationen wie
z.B. das Ändern der Zugriffrechte von Dateien mit dem Befehl CHMOD
werden nicht umgesetzt.
\item Create/Alter/Drop File Directory Pattern: Realisierung ebenso wie
bei den Create/Alter/Drop File Patterns, hier allerdings für Ordner,
die z.B. mit dem Erzeugungsbefehl MKDIR erstellt und mit RMDIR gelöscht
werden können. Weitere Operationen werden nicht realisiert.
\item File Retrieval 2PC Pattern: Die Umsetzung erfolgt nach der Beschreibung
des Set Retrieval Patterns für relationale Datenbanken, wobei hier
entsprechende Dateisystem-Befehle (siehe Query Pattern) verwendet
werden. Nur vollständige Dateiinhalt können in einer BPEL-Variable
abgelegt werden. Weiterhin beschränkt sich die Umsetzung dieses Patterns
auf das CSV-Dateiformat.
\item CSV File Cache Sequential/Direct Access Pattern: Um diese Patterns
zu realisieren, werden die CSV-Daten bei der Ausführung des File Retrieval
2PC Patterns in eine relationale Datenstruktur im Prozessspeicher
überführt. Das ist ohne Probleme möglich, da die CSV-Datenstruktur
sehr der einer Relation ähnelt. Dadurch können auch für diese Patterns
die durch die Set Cache Access Patterns bereitgestellten Methoden
verwendet werden.
\item CSV File Cache Insert/Delete/Replace Pattern: Erweitern die CSV File
Cache Access Patterns Methoden um die Möglichkeiten, Werte innerhalb
des Datencaches des BPEL-Prozesses zu ersetzen, einzufügen und zu
löschen. Die SDO API liefert dafür bereits einige Methoden, die verwendet
werden können. Da auch hier nur CSV-Daten verarbeitet werden, kann
aus den oben beschriebenen Gründen auch hier wieder auf die Funktionalität
für mengenorientierte Daten (Set Cache Patterns) zurückgegriffen werden.
\item File Cache WriteBack Pattern: Wird nur für das CSV-Dateiformat umgesetzt.
\end{itemize}

\subsubsection*{\label{sub:Sensornetze}Sensornetze}

Hier wird die Umsetzung der in Abschnitt \ref{sub:Datenmanagement-Patterns}
beschriebenen Patterns im Bereich der Sensornetze und deren Datenbanken
durch bestehende sensornetzspezifische SQL-Befehle oder, falls erforderlich,
durch die Definition neuer zu implementierender Funktionen beschrieben.
Alle SQL-Befehlsbeispiele beziehen sich hier auf den SQL-Dialekt der
Sensornetz-Datenbank TinyDB (siehe \cite{key-14}).
\begin{itemize}
\item Set Query Pattern: Realisierung durch ein entsprechendes SQL-SELECT
der Sensornetz-Datenbank. Eine Abfrage läuft auf der Sensornetz-Datenbank
dabei folgendermaßen ab: Die Sensornetz-Datenbank liest die durch
den Select-Befehl angeforderten Werte aus den jeweiligen Sensoren
des Sensornetzes aus, filtert diese und verknüpft sie zu einer Ergebnismenge,
die dann als Ergebnis der Abfrage zurückgegeben wird. Alternativ zu
normalen Abfragen besteht die Möglichkeit, sensornetzintern in einem
Buffer Werte zwischenzuspeichern. Realisiert wird dies durch im Arbeitsspeicher
von Sensoren erstellte Tabellen (siehe Create Sensor Buffer Container
Pattern), die mit momentanen Sensorwerten gefüllt werden können, um
später die Daten zeitversetzt abrufen zu können. Die gewünschten Werte
werden dabei mit einem entsprechenden SQL-SELECT Befehl in den Buffer
geschrieben. Die TinyDB liefert noch ein weiteres Konzept für Abfragen.
Dabei können, falls eine bestimmte Bedingung gilt (z.B. Temperatur
> 20\textdegree{}C), sogenannte \emph{commands }aufgerufen werden,
die dann bestimmte Methoden anstoßen. Der Code für diese Methoden
wird auf die entsprechenden Sensoren übertragen und dort dann bei
Bedarf ausgeführt.

\begin{itemize}
\item Befehlsstruktur: 

\begin{itemize}
\item SELECT select-list {[}FROM sensors{]} WHERE where-clause {[}GROUP
BY gb-list {[}HAVING having-list{]}{]}{[}TRIGGER ACTION command-name{[}(param){]}{]}
{[}EPOCH DURATION integer{]}
\item Werte in Buffer-Tabelle einfügen: SELECT field1, field2, ... FROM
sensors SAMPLE PERIOD x INTO name
\end{itemize}
\item Beispiele: 

\begin{itemize}
\item SELECT nodeid, temp EPOCH DURATION 1024
\item SELECT field1, field2 FROM sensors SAMPLE PERIOD 100 INTO name \\
(Einfügen von Werten, über SELECT, in die Buffer-Tabelle \emph{name})
\item SELECT temp FROM sensors WHERE temp > thresh TRIGGER ACTION SetSnd(512)
EPOCH DURATION 512

\begin{itemize}
\item \emph{Bemerkungen: Hier wird alle 512ms die Temperatur an den Sensoren
abgefragt und falls diese einen gewissen Wert übersteigt, wird über
den }\textbf{\emph{command}}\emph{ SetSnd(512) für 512ms ein Signalton
ausgegeben.}
\end{itemize}
\end{itemize}
\end{itemize}
\item Create/Drop Set Container Pattern: Es können Tabellen im Arbeitsspeicher
der Sensoren erstellt werden, die dann Werte von Sensoren aufnehmen
und halten können. Die Erstellung solcher Tabellen wird durch SQL-CREATE
BUFFER und das Löschen des gesamten Buffers durch SQL-DROP realisiert.

\begin{itemize}
\item Eine Buffer-Tabelle erstellen: CREATE BUFFER name SIZE x ( field1
type1, field2 type2, ... )

\begin{itemize}
\item \emph{Bemerkungen: }\textbf{x}\emph{ ist die Anzahl der maximal möglichen
Zeilen, }\textbf{\emph{type1}}\emph{,}\textbf{\emph{ type2}}\emph{,
usw. sind Datentypen aus der Menge \{uint8, uint16, uint16, int8,
int16, int32\} und }\textbf{\emph{field1}}\emph{, }\textbf{\emph{field2}}\emph{,
usw. sind Spaltennamen, die wie der Tabellenname jeweils 8 Zeichen
lang sein dürfen.}
\end{itemize}
\item Alle Buffer-Tabellen löschen: DROP ALL
\end{itemize}
\item Set Retrieval 2PC Pattern: Realisierung ebenso wie bei SQL-Datenbanken
beschrieben.
\item Set Cache Sequential/Direct Access Pattern: Realisierung ebenso wie
bei SQL-Datenbanken beschrieben.
\item Set Cache Insert/Update/Delete/Rename Pattern: Realisierung ebenso
wie bei SQL- Datenbanken beschrieben.
\end{itemize}

\subsubsection*{Datentransport zwischen mehreren externen Datenquellen}

Hier wird die Umsetzung der in Abschnitt \ref{sub:Datenmanagement-Patterns}
beschriebenen External Data Transport Patterns beschrieben. Dies sind
die Similar Data Transport Patterns und die Diverse Data Transport
Patterns.
\begin{itemize}
\item Similar/Diverse Data Move Patterns: Die Patterns dieser Klasse werden
dadurch realisiert, dass entsprechende vorhandene Patterns der Quell-
und Zieldatenquelle und des Prozessspeichers genutzt werden. Am Beispiel
des Move Set2Set Patterns würde dies folgendermaßen aussehen:

\begin{itemize}
\item Mithilfe des Set Retrieval 2PC Patterns werden die Daten aus der Quell-Datenbank
abgefragt und in den Prozessspeicher geladen.
\item Mit dem Create Set Container Pattern wird auf der Ziel-Datenbank eine
neue Tabelle erzeugt.
\item Anschließend werden die abgefragten Daten mit dem Set Cache WriteBack
Pattern in die erstellte Tabelle auf der Ziel-Datenbank eingefügt
und
\item die Ursprungstabelle der abgefragten Daten mit dem Drop Set Container
Pattern auf der Quell-Datenbank gelöscht.
\end{itemize}
\item Similar/Diverse Data Copy Patterns: Die Patterns dieser Klasse werden
ebenfalls dadurch realisiert, dass entsprechende vorhandene Patterns
der Quell- und Zieldatenquelle und des Prozessspeichers genutzt werden.
Am Beispiel des Copy Set2Set Patterns würde dies folgendermaßen aussehen:

\begin{itemize}
\item Mithilfe des Set Retrieval 2PC Patterns werden die Daten aus der Quell-Datenbank
abgefragt und in den Prozessspeicher geladen.
\item Mit dem Create Set Container Pattern wird auf der Ziel-Datenbank eine
neue Tabelle erzeugt.
\item Abschließend werden die abgefragten Daten mit dem Set Cache WriteBack
in die erstellte Tabelle auf der Ziel-Datenbank eingefügt.
\end{itemize}
\end{itemize}
Tabelle \ref{tab:Umsetzung-DMPatterns-DQTypen} zeigt eine Übersicht,
welche Datenmanagement-Patterns für welche Datenquellentypen umgesetzt
werden. Ein {}``x'' markiert dabei die vollständige Umsetzung eines
Patterns für einen Datenquellentyp.

%
\begin{table}
\caption{\label{tab:Umsetzung-DMPatterns-DQTypen}Übersicht über die Umsetzung
der Datenmanagement-Patterns für die verschiedenen Datenquellentypen}


\centering{}\begin{tabular}{|>{\raggedright}p{5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{2cm}|>{\centering}p{1.5cm}|}
\hline 
Datenmanagement-Pattern & rel. DB & XML-DB & Dateisys.

(CSV) & Sensor.-DB & Cache\tabularnewline
\hline
\hline 
Set Query Pattern & x &  &  &  & \tabularnewline
\hline 
Tree Query Pattern &  &  &  &  & \tabularnewline
\hline 
File Query Pattern &  &  & x &  & \tabularnewline
\hline 
Set Insert Pattern & x &  &  &  & \tabularnewline
\hline 
Set Update Pattern & x &  &  &  & \tabularnewline
\hline 
Set Delete Pattern & x &  &  &  & \tabularnewline
\hline 
Tree Insert Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Delete Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Replace Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Rename Pattern &  &  &  &  & \tabularnewline
\hline 
Node Content Insert Pattern &  &  &  &  & \tabularnewline
\hline 
Node Content Delete Pattern &  &  &  &  & \tabularnewline
\hline 
Node Content Replace Pattern &  &  &  &  & \tabularnewline
\hline 
File Content Insert Pattern &  &  & x &  & \tabularnewline
\hline 
File Content Delete Pattern &  &  & x &  & \tabularnewline
\hline 
File Content Replace Pattern &  &  &  &  & \tabularnewline
\hline 
Create Set Container Pattern & x &  &  &  & \tabularnewline
\hline 
Alter Set Container Pattern &  &  &  &  & \tabularnewline
\hline 
Drop Set Container Pattern & x &  &  &  & \tabularnewline
\hline 
Create Tree Container Pattern &  &  &  &  & \tabularnewline
\hline 
Alter Tree Container Pattern &  &  &  &  & \tabularnewline
\hline 
Drop Tree Container Pattern &  &  &  &  & \tabularnewline
\hline
\end{tabular}
\end{table}


%
\begin{table}[H]
\centering{}\begin{tabular}{|>{\raggedright}p{5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{2cm}|>{\centering}p{1.5cm}|}
\hline 
Datenmanagement-Pattern & rel. DB & XML-DB & Dateisys.

(CSV) & Sensor.-DB & Cache\tabularnewline
\hline
\hline 
Create File Directory Pattern &  &  & x &  & \tabularnewline
\hline 
Alter File Directory Pattern &  &  &  &  & \tabularnewline
\hline 
Drop File Directory Pattern &  &  & x &  & \tabularnewline
\hline 
Create File Pattern &  &  & x &  & \tabularnewline
\hline 
Alter File Pattern &  &  &  &  & \tabularnewline
\hline 
Drop File Pattern &  &  & x &  & \tabularnewline
\hline 
Stored Procedure Pattern & x &  &  &  & \tabularnewline
\hline 
Set Retrieval 2PC Pattern & x &  &  &  & \tabularnewline
\hline 
Set Cache Sequential Access Pattern &  &  &  &  & \tabularnewline
\hline 
Set Cache Direct Access Pattern &  &  &  &  & \tabularnewline
\hline 
Set Cache Insert Pattern &  &  &  &  & \tabularnewline
\hline 
Set Cache Update Pattern &  &  &  &  & \tabularnewline
\hline 
Set Cache Delete Pattern &  &  &  &  & \tabularnewline
\hline 
Set Cache WriteBack Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Retrieval 2PC Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache Hierarchical Access Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache Sequential Access Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache Direct Access Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache Insert Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache Delete Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache Replace Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache Rename Pattern &  &  &  &  & \tabularnewline
\hline 
Node Content Cache Insert Pattern &  &  &  &  & \tabularnewline
\hline 
Node Content Cache Delete Pattern &  &  &  &  & \tabularnewline
\hline 
Node Content Cache Replace Pattern &  &  &  &  & \tabularnewline
\hline 
Tree Cache WriteBack Pattern &  &  &  &  & \tabularnewline
\hline 
File Retrieval 2PC Pattern &  &  & x &  & \tabularnewline
\hline 
CSV File Cache Sequential Access Pattern &  &  &  &  & \tabularnewline
\hline 
CSV File Cache Direct Access Pattern &  &  &  &  & \tabularnewline
\hline 
File Content Cache Insert Pattern &  &  &  &  & \tabularnewline
\hline 
File Content Cache Delete Pattern &  &  &  &  & \tabularnewline
\hline 
File Content Cache Replace Pattern &  &  &  &  & \tabularnewline
\hline 
File Cache WriteBack Pattern &  &  &  &  & \tabularnewline
\hline
\end{tabular}
\end{table}



\subsubsection{\label{sub:Resultierende-BPEL-Aktivit=0000E4ten}Resultierende BPEL-Aktivitäten}

In diesem Abschnitt werden die durch Abschnitt \ref{sub:Umsetzung-der-Datenmanagement}
identifizierten BPEL-Aktivitäten aufgezählt und ihre Funktion noch
einmal kurz beschrieben. Dazu gehört z.B. auch, welche Attribute welchen
Typs für die einzelnen Aktivitäten benötigt werden. Generell gilt,
dass alle Aktivitäten mindestens die fünf Attribute \textbf{\emph{dsType}},
\textbf{\emph{dsKind}}, \textbf{\emph{dsLanguage, dsAddress}} und\emph{
}\textbf{\emph{dsStatement}} vom Typ String besitzen. Das Attribut
\textbf{\emph{dsType}} dient zur Angabe des Datenquellentyps, für
den die Aktivität ausgeführt wird, also ob es sich um ein Dateisystem,
eine Datenbank oder ein Sensornetz handelt. Das Attribut \textbf{\emph{dsKind}}
dient zur Angabe der genaueren Datenquellenart, d.h. um was für ein
Dateisystem, was für eine Datenbank oder welche Art von Sensornetz
es sich handelt. Das Attribut \textbf{\emph{dsLanguage}} dient zur
Angabe der verwendeten Abfragesprache. Diese Informationen sind wichtig,
um intern den richtigen SQL-Dialekt bzw. Befehlssatz für die entsprechende
Datenquelle auszuwählen. Das Attribut \textbf{\emph{dsAddress}} dient
zur Angabe der Datenquellenadresse und \textbf{\emph{dsStatement}}\emph{
}zur Haltung des entsprechenden Systemaufrufs bzw. SQL- oder XQuery-Befehls,
der ausgeführt werden soll. Da jede der definierten Aktivitäten diese
fünf Attribute besitzt, werden diese nachfolgend als \textbf{\emph{simpl-attributes
}}(vgl. standard-attributes in \cite{key-4}) in den Listings angegeben
und nur falls benötigt weitere aktivitätsspezifische Attribute beschrieben.
Listing \ref{lst:simpl-attributes} führt die fünf Datenmanagement-Attribute
nocheinmal auf. Weiterhin werden die verschiedenen Ausprägungen der
einzelnen Aktivitäten im Hinblick auf die zugrundeliegende Datenquelle
aufgezeigt, sodass am Ende ein vollständiger Überblick aller definierten
Aktivitäten und ihrer Ausprägungen vorliegt. Generell gibt es durch
die verschiedenen Datenquellen keine strukturellen Unterschiede in
den Aktivitäten. Dadurch spielen datenquellenspezifische Eigenschaften
keine Rolle in der graphischen Oberfläche, wodurch eine einheitliche
Benutzeroberfläche für alle Aktivitäten realisiert werden kann. Alle
Abfragebefehle sollen über entsprechende graphische Elemente angegeben
werden können, indem sie einfach {}``zusammengeklickt'' werden können
(siehe Abbildung \ref{fig:Eigenschaftsfenster-einer-Data-Management-Aktivit=0000E4t}).
Dadurch soll eine einfachere Handhabung realisiert werden, damit der
Benutzer schnellstmöglich und ohne detaillierte Kenntnisse der Abfragesprache
alle zur Verfügung gestellten Daten- und Datenquellenbefehle für alle
unterstützten Datenquellen modellieren kann. Trotz der Einschränkungen,
die ohne Zweifel durch die grafische Erstellung der Befehle bestehen,
steht dem Benutzer der volle Sprachumfang der jeweiligen Datenquellensprache
bzw. der vollständige Befehlssatz der Datenquelle zur Verfügung. Der
volle Sprachumfang kann dabei mindestens, wie in Abbildung \ref{fig:Eigenschaftsfenster-einer-Data-Management-Aktivit=0000E4t}
dargestellt, über die Angabe von Befehlen im Abfragebefehls-Textfeld
genutzt werden. So weit es möglich ist, wird allerdings versucht,
den vollen Sprachumfang bereits durch die grafische Modellierung der
Befehle abzudecken.

Nachfolgend werden alle durch die Abschnitte \ref{sub:Datenmanagement-Patterns}
und \ref{sub:Umsetzung-der-Datenmanagement} identifizierten Aktivtäten
aufgezeigt und beschrieben. Dabei werden in den Listings der DM-Aktivitäten
die in \cite{key-4} beschriebenen Notationen und Definitionen verwendet.

\begin{center}

\begin{lstlisting}[caption={Listing der simpl-attributes},label={lst:simpl-attributes},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
dsType="xsd:string"
dsKind="xsd:string"
dsLanguage="xsd:string"
dsAdress="xsd:string"
dsStatement="xsd:string"

\end{lstlisting}

\par\end{center}


\subsubsection*{Query Aktivität}

Diese Aktivität setzt die Query Patterns um und ermöglicht es, aus
jeder beliebigen Datenquelle Daten zu lesen und diese auf derselben
Datenquelle zu speichern. Dafür wird ein spezifisches Attribut \emph{queryTarget}
benötigt. In diesem Attribut kann der Prozessmodellierer das Ziel
(Tabellenname, Dateiname, etc.) hinterlegen, wo die abgefragten Daten
auf der Datenquelle gespeichert werden sollen, um diese an einer anderen
Stelle im Prozess verwenden zu können. Die Query Aktivität ist für
alle Datenquellen gleich strukturiert, und nur die entsprechenden
Query-Befehle unterscheiden sich je nach Datenquelle. Diese Aktivität
kann auch für das sensornetzinterne Einfügen von Sensordaten in Buffer-Tabellen
genutzt werden (wie auch in Abschnitt \ref{sub:Sensornetze} beschrieben).
Listing \ref{lst:Query Aktivit=0000E4t} zeigt das BPEL-Schema einer
Query Aktivität.

\begin{center}

\begin{lstlisting}[caption={Schema einer Query Aktivität},label={lst:Query Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:queryActivity standard-attributes 
			simpl-attributes 
            queryTarget="xsd:string">
		
		standard-elements

	</simpl:queryActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{Insert Aktivität}

Diese Aktivität setzt die Data Insert Patterns um. Sie ermöglicht
es, Daten in eine Datenquelle einzufügen. Listing \ref{lst:Insert Aktivit=0000E4t}
zeigt das BPEL-Schema einer Insert Aktivität.

\begin{center}

\begin{lstlisting}[caption={Schema einer Insert Aktivität},label={lst:Insert Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:insertActivity standard-attributes 
			simpl-attributes>
		
		standard-elements

	</simpl:insertActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{Update Aktivität}

Diese Aktivität setzt die Data Update/Replace/Rename Patterns um.
Sie ermöglicht es, auf einer Datenquelle hinterlegte Daten zu aktualisieren.
Diese Aktivität kann nicht auf Sensornetze angewendet werden. Listing
\ref{lst:Insert Aktivit=0000E4t} zeigt das BPEL-Schema einer Update
Aktivität. 

\begin{center}

\begin{lstlisting}[caption={Schema einer Update Aktivität},label={lst:Update Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:updateActivity standard-attributes 
			simpl-attributes>
		
		standard-elements

	</simpl:updateActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{Delete Aktivität}

Diese Aktivität setzt die Data Delete Patterns um. Sie ermöglicht
es, Daten in Datenquellen zu löschen. Diese Aktivität kann nicht auf
Sensornetze angewendet werden. Listing \ref{lst:Delete Aktivit=0000E4t}
zeigt das BPEL-Schema einer Delete Aktivität.

\begin{center}

\begin{lstlisting}[caption={Schema einer Delete Aktivität},label={lst:Delete Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:deleteActivity standard-attributes 
			simpl-attributes>
		
		standard-elements

	</simpl:deleteActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{Create Aktivität}

Diese Aktivität setzt die Data Setup Create Patterns um. Sie ermöglicht
es, Zuordnungseinheiten (Dateien, Ordner, Tabellen, Schemata, usw.)
auf beliebigen Datenquellen zu erstellen. Dabei werden die folgenden
Befehle zur Erstellung von Zuordnungseinheiten auf den entsprechenden
Datenquellen unterstützt:
\begin{itemize}
\item Dateisysteme:

\begin{itemize}
\item MKDIR folder
\item MKFILE file
\end{itemize}
\item Datenbanken:

\begin{itemize}
\item CREATE TABLE
\item CREATE SCHEMA
\item mögliche Erweiterungen:

\begin{itemize}
\item CREATE VIEW
\item CREATE DOMAIN
\item CREATE INDEX 
\item CREATE TRIGGER
\end{itemize}
\end{itemize}
\item mögliche Erweiterungen für Sensornetze:

\begin{itemize}
\item CREATE BUFFER
\end{itemize}
\end{itemize}
Diese Aktivität wird für XQuery-Datenbanken nicht realisiert. Ebenso
werden keine weiteren Befehle umgesetzt. Listing \ref{lst:Create Aktivit=0000E4t}
zeigt das BPEL-Schema einer Create Aktivität. 

\begin{center}

\begin{lstlisting}[caption={Schema einer Create Aktivität},label={lst:Create Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:createActivity standard-attributes 
			simpl-attributes>
		
		standard-elements

	</simpl:createActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{Drop Aktivität}

Diese Aktivität setzt die Data Setup Drop Patterns um. Sie ermöglicht
es, Zuordnungseinheiten auf beliebigen Datenquellen zu verwerfen.
Dazu werden die folgenden Befehle unterstützt:
\begin{itemize}
\item Dateisysteme:

\begin{itemize}
\item RMDIR folder
\item RM file
\end{itemize}
\item Datenbanken:

\begin{itemize}
\item DROP TABLE
\item DROP SCHEMA
\item mögliche Erweiterungen:

\begin{itemize}
\item DROP VIEW
\item DROP DOMAIN
\item DROP INDEX 
\item DROP TRIGGER
\end{itemize}
\end{itemize}
\item mögliche Erweiterungen für Sensornetze:

\begin{itemize}
\item DROP ALL
\end{itemize}
\end{itemize}
Diese Aktivität wird für XQuery-Datenbanken nicht realisiert. Ebenso
werden keine weiteren Befehle umgesetzt. Listing \ref{lst:Drop Aktivit=0000E4t}
zeigt das BPEL-Schema einer Drop Aktivität. 

\begin{center}

\begin{lstlisting}[caption={Schema einer Drop Aktivität},label={lst:Drop Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:dropActivity standard-attributes 
			simpl-attributes>
		
		standard-elements

	</simpl:dropActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{Call Aktivität}

Diese Aktivität setzt das Stored Procedure Pattern um. Sie ermöglicht
es, auf der Datenquelle hinterlegte Prozeduren auszuführen. Diese
Aktivität wird nur für relationale Datenbanken umgesetzt. Listing
\ref{lst:Call Aktivit=0000E4t} zeigt das BPEL-Schema einer Call Aktivität. 

\begin{center}

\begin{lstlisting}[caption={Schema einer Call Aktivität},label={lst:Call Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:callActivity standard-attributes 
			simpl-attributes>
		
		standard-elements

	</simpl:callActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{RetrieveData Aktivität}

Diese Aktivität setzt die Data Retrieval to Process Cache Patterns
um. Sie ermöglicht es, Daten von Datenquellen in den BPEL-Prozess
zu laden. Dafür wird das zusätzliche Attribut \emph{dataVariable}
verwendet, in das eine Referenz auf eine BPEL-Variable abgelegt werden
kann. Diese Aktivität wird nur für relationale Datenbanken und CSV-Dateien
umgesetzt. Listing \ref{lst:RetrieveData Aktivit=0000E4t} zeigt das
BPEL-Schema einer RetrieveData Aktivität. 

\begin{center}

\begin{lstlisting}[caption={Schema einer RetrieveData
Aktivität},label={lst:RetrieveData Aktivit=0000E4t},basicstyle={\small\ttfamily},captionpos=b,frame=single,tabsize=4,xleftmargin=3cm,xrightmargin=3cm]
<bpel:extensionActivity>
	<simpl:retrieveDataActivity 
			standard-attributes 
			simpl-attributes
            dataVariable="bpel:BPELVariableName">
		
		standard-elements

	</simpl:retrieveDataActivity> 
</bpel:extensionActivity>

\end{lstlisting}

\par\end{center}


\subsubsection*{Mögliche Erweiterungen:}
\begin{itemize}
\item \textbf{WriteBack Aktivität:} Diese Aktivität setzt die Process Cache
WriteBack Patterns um. Sie ermöglicht es, Daten aus dem BPEL-Prozess
auf eine externe Datenquelle zu kopieren. Diese Aktivität existiert
nicht für Sensornetze.
\item \textbf{Alter Aktivität:} Diese Aktivität setzt die Data Setup Alter
Patterns um. Sie ermöglicht es, bereits bestehende Zuordnungseinheiten
(Tabellen, Schemata, usw.) nachträglich gezielt zu verändern und an
veränderte Anforderungen anzupassen. Es ist z.B. möglich, in eine
Tabelle neue Spalten einzufügen, bestehende Spalten neu zu benennen
oder zu verwerfen.
\item \textbf{Transfer Aktivität:} Diese Aktivität setzt die External Data
Transport Patterns um. Sie ermöglicht das externe Kopieren oder Verschieben
von externen Daten in derselben Datenstruktur, wie z.B. das Kopieren
von relationalen Daten in eine relationale Datenbank (Similar Data
Transport Patterns) und das externe Kopieren oder Verschieben von
externen Daten aus einer Datenstruktur in eine andere, wie z.B. das
Kopieren von relationalen Daten in eine XML-Datenbank (Diverse Data
Transport Patterns).
\end{itemize}
In Tabelle \ref{tab:ResultierendeAktivit=0000E4ten} werden nocheinmal
alle resultierenden DM-Aktivitäten und ihre Verwendbarkeit im Bezug
auf die verschiedenen Datenquellen aufgezeigt. Dabei steht ein {}``x''
für die vollständige Anwendbarkeit einer Aktivität auf eine Datenquelle
und ein {}``m'' dafür, dass eine Anwendung einer Aktivität auf diese
Datenquelle theoretisch möglich ist, aber nicht umgesetzt wird. Die
Markierung {}``-'' bedeutet, dass eine Aktivität aufgrund der in
Abschnitt \ref{sub:Datenmanagement-Patterns} und \ref{sub:Umsetzung-der-Datenmanagement}
beschriebenen Umstände überhaupt nicht mit dieser Datenquelle verwendet
werden kann.

%
\begin{table}[H]
\caption{\label{tab:ResultierendeAktivit=0000E4ten}Übersicht der resultierenden
Aktivitäten und ihrer Anwendbarkeit auf verschiedene Datenquellen}


\begin{centering}
\begin{tabular}{|>{\centering}p{3cm}|>{\centering}p{1.5cm}|>{\centering}p{1.5cm}|>{\centering}p{2.5cm}|>{\centering}p{3.5cm}|}
\hline 
Aktivität & RDB & XML-DB & Dateisysteme & Sensornetze (TinyDB)\tabularnewline
\hline
\hline 
Query Aktivität & x & m & x & m\tabularnewline
\hline 
Insert Aktivität & x & m & x & -\tabularnewline
\hline 
Update Aktivität & x & m & m & -\tabularnewline
\hline 
Delete Aktivität & x & m & x & -\tabularnewline
\hline 
Create Aktivität & x & m & x & m\tabularnewline
\hline 
Drop Aktivität & x & m & x & m\tabularnewline
\hline 
Call Aktivität & x & m & - & -\tabularnewline
\hline 
RetrieveData Aktivität & x & m & x & m\tabularnewline
\hline
\hline 
WriteBack Aktivität & m & m & m & -\tabularnewline
\hline 
Alter Aktivität & m & m & m & -\tabularnewline
\hline 
Transfer Aktivität & m & m & m & -\tabularnewline
\hline
\end{tabular}
\par\end{centering}


\end{table}



\subsection{\label{sub:Authentifizierung-und-Autorisierung}Authentifizierung
und Autorisierung}

Dieser Abschnitt behandelt die Authentifizierung und Autorisierung
beim Zugriff auf Datenquellen und die dabei eingesetzten Technologien
und Konzepte. Bei beiden Verfahren handelt es sich um Verfahren auf
Seite der Datenquellen, d.h. es findet keine Autorisierung und Authentifizierung
der Benutzer innerhalb eines Prozesses statt. Das Rahmenwerk bietet
dem Benutzer lediglich die Möglichkeit, benötigte Authentifizierungs-
und Autorisierungsinformationen anzugeben und ggf. zwischenzuspeichern.
Ziel des Rahmenwerks ist es, eine Vielzahl an Authentifizierungs-
und Autorisierungsverfahren zu unterstützen und für weitere Verfahren
erweiterbar zu sein.


\subsubsection{Authentifizierung}

Bei der Authentifizierung wird vor dem eigentlichen Zugriff zunächst
ein Vertrauensverhältnis zwischen Klient und Datenquelle hergestellt.
Je nach Verfahren wird dabei das Vertrauen einseitig oder auch beidseitig
hergestellt. Für das Rahmenwerk soll dabei das Konzept des Single
Sign On (SSO) angewendet werden, das nach einer erfolgreich durchgeführten
Authentifizierung verhindert, dass bei weiteren Zugriffen auf dieselbe
Datenquelle eine erneute Authentifizierung durchgeführt werden muss.
Unabhängig von der Realisierung soll das für den Benutzer auch bedeuten,
dass die Authentifizierungsinformationen nicht in jeder DM-Aktivität
zu einer Datenquelle redundant angegeben werden müssen. Vorerst wird
nur ein Verfahren mit Benutzername und Passwort realisiert. Benutzername
und Passwort können im Deployment-Deskriptor (siehe Kapitel \ref{sub:ODE-Deployment-Deskriptor})
oder über das UDDI Web Interface (siehe Kapitel \ref{sub:UDDI-Web-Interface})
für eine Datenquelle festgelegt werden.


\subsubsection{Autorisierung}

Eine Autorisierung findet meist nach einer erfolgreichen Authentifizierung
statt und überprüft, ob der Zugriff bzw. die Operation, die ausgeführt
werden soll, berechtigt ist. Dazu werden Zugriffsrechte überprüft,
die als Regeln formuliert auf Seite der Datenquellen verwaltet werden.
Es wird lediglich die Autorisierung über Benutzername und Passwort
unterstützt.


\subsection{\label{sub:Auditing}Auditing}

In diesem Abschnitt wird eine Beschreibung des geplanten Auditing
von SIMPL gegeben. Dazu wird zunächst auf das bestehende Auditing
und Monitoring von ODE eingegangen.


\subsubsection{Momentane Situation bei ODE}

Das Auditing und Monitoring von ODE wird durch sogenannte Events und
Event Listener sowie die Management API realisiert.


\subsubsection*{Management API}

Die Management API der ODE Engine macht es möglich, zahlreiche Informationen
abzurufen. So ist es beispielsweise möglich, zu überprüfen, welche
Prozessmodelle gerade eingesetzt werden und welche Prozessinstanzen
ausgeführt werden oder beendet sind. Dies ist besonders für das Monitoring
wichtig, da es hierdurch möglich ist, spezifische Informationen zu
einem bestimmten Prozess oder einer bestimmten Instanz abzurufen.
Dies kann zum Beispiel das Erstellungsdatum des Prozesses oder der
Instanz sein, eine Liste der Events, die für diesen Prozess oder diese
Instanz generiert wurden, und vieles mehr.


\subsubsection*{Events}

Events sind Ereignisse, die von der ODE Engine erzeugt werden, um
Rückmeldung über bestimmte Aktionen, die innerhalb der Engine auftreten,
zu geben. Bei diesen Ereignissen handelt es sich zum Beispiel um das
Aktivieren eines Prozesses oder das Erzeugen einer neuen Prozessinstanz.
Die Events sind in folgende fünf Gruppen eingeteilt: Instance Lifecycle
Events, Activity Lifecycle Events, Scope Handling, Data Handling,
Correlation Events. Diese Events machen es möglich zu verfolgen, was
innerhalb der ODE Engine passiert, und produzieren detailierte Informationen
über die Prozessausführung. Sie können mit Hilfe der Management API
oder durch die Nutzung von sogenannten Event Listenern abgefragt werden. 

Die Events werden momentan in der internen ODE Derby Datenbank gespeichert.
Im Rahmen des SIMPL Auditing werden diese in einer externen Datenbank
gespeichern.


\subsubsection*{Event Listener}

Event Listener sind bestimmte Konstrukte, die es ermöglichen, bei
dem Auftreten bestimmter Events eine direkte Rückmeldung zu geben,
oder auf verschiedene Events zu reagieren und event-spezifische Aktionen
durchzuführen. Diese Event Listener werden momentan zum Beispiel dazu
benutzt, um die verschiedenen event-spezifischen Informationen an
das entsprechende Event DAO weiterzuleiten, wo diese persistent gespeichert
werden.


\subsubsection{Auditing von SIMPL}

Im BPEL Designer ist der Zugriff auf das Auditing und die Auditingeinstellungen
unter dem entsprechenden Menüpunkt in der Admin-Konsole möglich. Hier
kommt man zum entsprechenden Interface, in dem sich verschiedene Einstellungen
für das Auditing tätigen lassen (siehe Abbildung \ref{fig:Auditing-Einstellungen}).
Es ist möglich, das Auditing zu aktivieren oder zu deaktivieren. Weiterhin
ist es möglich, die Datenbank für das Speichern der Auditing-Daten
festzulegen. Das Auditing ist standardmäßig deaktiviert, kann allerdings
über die Adminkonsole aktiviert und auch erneut deaktiviert werden.

Für das Auditing von SIMPL werden die von ODE erzeugten Daten direkt
an den SIMPL Core übergeben und weiterverarbeitet, anstatt diese wie
bisher in der virtuellen Datenbank von ODE abzulegen. Die so erzeugten
Daten über die Prozesse, Instanzen und Events werden anschließend
in einer zuvor in der Adminkonsole festgelegten Auditing-Datenbank
abgelegt.


\subsection{\label{sub:Datenquellen-Policies}Datenquellen Policies}

In diesem Abschnitt werden die verschiedenen Policies beschrieben,
mit denen die nichtfunktionalen Anforderungen der Datenquellen modelliert
werden können. 


\subsubsection{Policy-Beschreibungen}

Die Beschreibungen der Policies gliedert sich in die Bereiche:
\begin{itemize}
\item allgemeine Policies, die für alle Datenquellen gelten,
\item Datenbank Policies, die speziell für Datenbanken gelten und
\item Dateisystem Policies, die für Dateisystem gelten.
\end{itemize}
In den Policy-Dateien wird nicht unterschieden, welche Policies zu
welchen Datenquellen gehören. Die Trennung erfolgt nur zur besseren
Lesbarkeit.

%
\begin{table}[H]
\caption{Allgemeine Policies}


\begin{tabular}{|>{\centering}p{0.25\textwidth}|>{\centering}p{0.6\textwidth}|>{\centering}p{0.15\textwidth}|}
\hline 
Eigenschaft & Beschriebung & Einheit\tabularnewline
\hline
\hline 
responseTime & Die maximale Zeit, die ein Server zum Antworten brauchen darf. & ms\tabularnewline
\hline 
availability & Die Verfügbarkeit eines Servers beschrieben als maximale Downtime
des Servers. & hours/year\tabularnewline
\hline 
throughput & Maximal erreichbarer Datendurchsatz, unabhängig von der Netzanbindung. & megabyte/ sekunde\tabularnewline
\hline 
transaction & Werden Transaktionen von der Datenquelle unterstützt? & boolean\tabularnewline
\hline
\end{tabular}
\end{table}


%
\begin{table}[H]
\caption{Datenbank Policies}


\begin{tabular}{|>{\centering}p{0.25\textwidth}|>{\centering}p{0.6\textwidth}|>{\centering}p{0.15\textwidth}|}
\hline 
Eigenschaft & Beschreibung & Einheit\tabularnewline
\hline
\hline 
maxQueryLength & Die maximale Länge eines Befehls der Anfragesprache & Anzahl der Zeichen\tabularnewline
\hline 
maxConcurrentTransaction & Die maximale Anzahl an Verbindungen, die gleichzeitig (nebenläufig)
auf Daten der Datenbank zugreifen & Anzahl\tabularnewline
\hline 
maxColumnSize & Maximale Spaltenzahl innerhalb einer Tabelle & Anzahl\tabularnewline
\hline 
dbVersion & Die Version der Datenbank & Versionsnummer\tabularnewline
\hline
\end{tabular}
\end{table}


%
\begin{table}[H]
\caption{Dateisystem Policies}


\begin{tabular}{|>{\centering}p{0.25\textwidth}|>{\centering}p{0.6\textwidth}|>{\centering}p{0.15\textwidth}|}
\hline 
Eigenschaft & Beschreibung & Einheit\tabularnewline
\hline
\hline 
maxFilenameLength & Die maximale Länge eines Dateinamens & Anzahl der Zeichen\tabularnewline
\hline 
maxPathLength & Die maximale Länge eines Dateipfades & Anzahl der Zeichen\tabularnewline
\hline 
maxFileSize & Die maximale Größe einer Datei & Megabyte\tabularnewline
\hline
\end{tabular}
\end{table}



\subsubsection{Policy Defenition}

Folgende SIMPL Policy-Assertions stehen zur Verfügung und werden nachfolgend
SIMPLPolicy-Assertions genannt.


\begin{lstlisting}[caption={SIMPL Policy-Assertions},captionpos=b,frame=single,xleftmargin=2cm,xrightmargin=2cm]
<simpl:responseTime value = "xsd:integer"/>
<simpl:availability value = "xsd:integer"/>
<simpl:throughput value = "xsd:integer"/>
<simpl:transaction value = "xsd:boolean"/>
<simpl:maxQueryLength value = "xsd:integer"/>
<simpl:maxConcurrentConnection value = "xsd:integer"/>
<simpl:maxColumnSize value = "xsd:integer"/>
<simpl:dbVersion value = "xsd:String"/>
<simpl:maxFilenameLength value = "xsd:integer"/>
<simpl:maxPathLength value = "xsd:integer"/>
<simpl:maxFileSize value = "xsd:integer"/>

\end{lstlisting}



\subsubsection*{Definition:}

Folgend ist die Struktur einer SIMPL Policy-Datei aufgezeigt


\begin{lstlisting}[caption={Listing einer SIMPL Policy-Datei},captionpos=b,frame=single,showstringspaces=false,tabsize=2,xleftmargin=2cm,xrightmargin=2cm]
<wsp:Policy
	xmlns:simplp="http://www.example.org/simpl/policy"
	xmlns:wsp="http://www.w3.org/ns/ws-policy">
	
	SIMPLPolicy-Assertions
</wsp:Policy>

\end{lstlisting}


\noindent Bezüglich der Policy-Datei gelten einige Einschränkungen.
So werden zum Beispiel nur die Kompaktformen von Policies unterstützt.
Die Policy-Operatoren wsp:exactlyOnce und wsp:all, sowie die Möglichkeit
Assertions als optional zu kennzeichnen (wsp:optional) werden nicht
unterstützt. Darüber hinaus ist es nicht möglich Referenzen innerhalb
des Dokumentes zu verwenden.

\pagebreak{}


\section{\label{sec:Ausblick}Ausblick und Erweiterungsmöglichkeiten}

In diesem Teil des Dokumentes werden mögliche Erweiterungen des SIMPL
Rahmenwerkes beschrieben und erläutert.


\subsection{SIMPL Event System}

In diesem Teil wird das SIMPL Event Modell als mögliche Erweiterung
des Auditing von SIMPL besprochen. Das SIMPL Event-Modell nutzt als
Grundlage das Modell in Abbildung \ref{fig:BPEL-Event-Modell} welches
ein Event Modell für die Ausführung von allgemeinen Aktivitäten ist.
Die in diesem Element vorkommenden Events sind nicht mit den Events
in ODE identisch, da es sich dabeium ein WS-BPEL 2.0 Event-Modell
handelt. Deswegen sind einige Anpassungen und Änderungen notwendig.

Die verschiedenen Schritte der Aktivitätsausführung, die in Abbildung
\ref{fig:BPEL-Event-Modell} aufgeführt sind (Inactive, Ready, Executing
etc.), können bis auf eine Ausnahme für das SIMPL Event-Modell, genutzt
werden. Der Grund dafür ist, dass der Ablauf der Ausführung einer
Aktivität in ODE dem in diesem Modell gleicht, d. h. es werden die
selben Zustände durchlaufen. Die SIMPL Events werden nur während der
direkten Ausführung der Aktivität genutzt (d.h. im Zustand \textquotedbl{}Executing\textquotedbl{}
in Abbildung \ref{fig:BPEL-Event-Modell}). Es genügt daher, das SIMPL
Event Modell darauf zu beschränken, was im Zustand \textquotedbl{}Executing\textquotedbl{}
passiert, da es in allen anderen Zuständen keine neuen Events gibt.

In ODE selbst gibt es für Aktivitäten nur die fünf Events: Activity
enabled, Activity execution started, Activity execution ended, Activity
failure und Activity recovery. Da es in ODE keine Entsprechung der
Events Complete Activity oder Activity\_Completed (Übergang vom Zustand
{}``Waiting'' zu {}``Complete'') gibt, sondern nur das Event Activity
execution ended, geht ODE vom Zustand Execution direkt zum Zustand
Complete über.

Das SIMPL-Event-Modell wurde daher so aufgebaut, dass die Zustände
{}``Ready'' und {}``Complete'', sowie {}``Faulted'' übernommen
wurden. Der Zustand {}``Executing'' wird nicht expliziet dargestellt,
stattdessen werden die einzelnen Vorgänge, die zwischen {}``Ready''
und {}``Complete'' auftreten, näher veranschaulicht. Der Zustand
{}``Ready'' stellt daher den Anfangszustand des SIMPL-Event-Modells
da, und der Zustand \textquotedbl{}Complete\textquotedbl{} den Endzustand.

Zur Vereinfachung wurden im SIMPL-Event-Modell nur die SIMPL-Events
aufgeführt und keine der bestehenden ODE-Events. Das daraus resultierende
Event Modell ist in Abbildung \ref{fig:Event-Modell-des-Auditings}
zu sehen. Dabei ist zu beachten, dass die Zustände, die aus dem Modell
in Abbildung \ref{fig:BPEL-Event-Modell} übernommen wurden, in Rot
dargestellt sind.

%
\begin{figure}
\begin{centering}
\includegraphics[scale=0.65]{\string"img/diagrams/ODE Event Modell Steinmetz\string".JPG}
\par\end{centering}

\caption{\label{fig:BPEL-Event-Modell}BPEL Event Modell für die Ausführung
allgemeiner Aktivitäten in WS-BPEL 2.0\cite{key-23}}

\end{figure}


%
\begin{figure}
\begin{centering}
\includegraphics[width=1\textwidth]{\string"img/diagrams/BPEL Event Modell DM-Aktivität Ablauf 3\string".jpg}
\par\end{centering}

\caption{\label{fig:Event-Modell-des-Auditings}Event-Modell für die Ausführung
von DM-Aktivitäten}

\end{figure}
Wie im SIMPL-Event-Modell zu sehen ist gibt es zwei neue Event Klassen.
Dies sind die Event Klassen Connection\_Events und DM\_Events. Jede
dieser beiden Event Klassen verfügt über eine Anzahl von einzelnen
Events, die nachfolgend genauer erläutert werden. Eine Mögliche Erweiterung
ist das Aktivieren und Deaktivieren dieser Event Klassen im Deployment
Deskriptor, wie es auch bei den anderen Event Klassen der Fall ist.


\paragraph{Connection\_Events}

Diese Events werden erzeugt, um verschiedene Ereignisse bei der Verbindung
zu einer Datenquelle zu erfassen. Sie enthalten Informationen darüber
zu welcher Datenbank eine Verbindung aufgebaut wurde (Typ der Datenbank
und ihre Adresse) und wann die Verbindung aufgebaut, bzw. beendet
wurde. Diese Events sind notwendig um festzuhalten wann auf eine bestimmte
Datenbank zugegriffen wurde und dies eventuell in einem Monitoringtool
darzustellen (z.B. Anzahl der Verbindungen zu einer bestimmte Datenbank
in den letzten 24 Stunden). 
\begin{itemize}
\item ConnectionStarted


Dieses Event wird erzeugt, wenn erfolgreich eine Verbindung aufgebaut
wurde.

\item ConnectionEnd


Dieses Event wird erzeugt, wenn die Verbindung zu einer Datenquelle
beendet wurde.

\item ConnectionLost


Dieses Event wird erzeugt, wenn es zu einen unerwarteten Abbruch der
Verbindung kommt. Beispielsweise wenn es zu einem Timeout der Verbindung
kommt.

\end{itemize}

\paragraph{DM\_Events}

Die DM\_Events sind für die Ereignisse einer DM-Aktivität zuständig.
Hier wird nicht unterschieden, um welche Art von DM-Aktivität es sich
handelt. Für alle DM-Aktivitäten werden dieselben Events erzeugt.
Diese Events enthalten alle relevanten Informationen zu den Aktivitäten
(z.B. Name der Aktivität, die Art der Datenbank auf der die DM-Operation
durchgeführt wird, das zu übergebende Statement etc.). Diese speziellen
Events werden zusätzlich zu den normalen Activity\_Events erzeugt.
Der Grund dafür diese Events zusätzlich zu erzeugen liegt darin, das
wie bereits erwähnt die Möglichkeit bestehen soll, im Rahmen des Auditing
nur die SIMPL-Events zu erzeugen.
\begin{itemize}
\item DMStarted 


Dieses Event wird erzeugt, wenn die Ausführung einer DM-Aktivität
gestartet wurde.

\item DMEnd


Dieses Event wird erzeugt, wenn die Ausführung einer DM-Aktivität
erfolgreich beendet wurde.

\item DMFailure


Dieses Event wird erzeugt, wenn bei der Ausführung einer DM-Aktivität
ein Fehler auftrat.

\end{itemize}

\section{\label{sec:Technologien und Werkzeuge}Technologien und Werkzeuge}

In diesem Kapitel folgt ein Überblick über die im Projekt verwendeten
Technologien und Werkzeuge.


\subsection{Technologien}

In der Entwicklung von SIMPL werden die folgenden Technologien zum
Einsatz kommen:


\subsubsection*{Apache Axis2 \cite{key-5}}

Axis2 ist eine Simple Object Access Protocol (SOAP-) Engine zur Konstruktion
von darauf basierenden Web Services und Client-Anwendungen.


\subsubsection*{Apache ODE \cite{key-6}}

Apache ODE ist eine BPEL-Workflow-Engine. Es wird sowohl WS-BPEL 2.0
als auch BPEL4WS 1.1 unterstützt, um Prozesse in einer SOA auszuführen.
Zudem ist ein Deployment von Prozessen zur Laufzeit (Hot Deployment)
möglich sowie die Analyse und Validierung von Prozessen.


\subsubsection*{Apache Tomcat \cite{key-7}}

Apache Tomcat ist ein Web Container, der auch einen kompletten Web
Server beinhaltet.


\subsubsection*{Apache Tuscany DAS \cite{key-8}}

Data Access Services ermöglichen den einheitlichen Zugriff auf Datenquellen,
indem eine zentrale Schnittstelle für das Lesen und Schreiben von
heterogenen Daten bereitgestellt wird. Die Daten werden dabei in Service
Data Objects gekapselt und so von ihrer Quelle unabhängig gemacht.


\subsubsection*{Apache Tuscany SDO \cite{key-9}}

Service Data Objects stellen eine einheitliche API zur Verfügung,
mit der die Handhabung verschiedener heterogener Daten und Datenquellen
vereinfacht wird.


\subsubsection*{Eclipse BPEL Designer \cite{key-10}}

Der Eclipse BPEL Designer ist ein Eclipse Plugin für die Modellierung
von BPEL-Prozessen. Er verfügt über eine leicht verständliche GUI
und über eine Syntaxprüfung für BPEL-Prozesse. Zudem bietet der Eclipse
BPEL Designer in Kombination mit Apache ODE eine Schritt für Schritt
Ausführung von Prozessen.


\subsubsection*{IBM-DB2 \cite{key-11}}

Die IBM-DB2 ist ein Hybriddatenserver, mit dem sowohl die Verwaltung
von XML-Daten als auch von relationalen Daten möglich ist.


\subsubsection*{Java 6 \cite{key-12}}

Java ist eine objektorientierte Programmiersprache von Sun Microsystems,
mit der sich plattformunabhängige Programme entwickeln lassen.


\subsubsection*{JAX-WS \cite{key-13}}

JAX-WS ist eine Java API zur Erstellung von Web Services, die für
das Deployment Java Annotationen verwendet.


\subsubsection*{TinyDB \cite{key-14}}

TinyDB ist ein Datenbanksystem für Sensornetze und bietet eine SQL-ähnliche
Schnittstelle.


\subsubsection*{Web Services}

Web Services sind eigenständige Software-Einheiten, die sich selbst
beschreiben und die ihre Dienste über ein Netzwerk, wie beispielsweise
das Internet, bereitstellen. Damit werden verteilte Anwendungen möglich,
die flexibel auf sich ändernde Anforderungen angepasst werden können.
Die Schnittstellen von Web Services werden mit WSDL (siehe \cite{key-21})
beschrieben und können damit unabhängig von Betriebssystem, Plattform
und Programmiersprache verwendet werden.


\subsubsection*{jUDDI\cite{key-26}}

jUDDI ist eine UDDI Registry und wird dazu benutzt, Datenquellen und
Datenquellinformationen zu speichern. Darüber hinaus ist es möglich,
nichtfunktionale Anforderungen als WS-Policy zu definieren 


\subsection{Werkzeuge}

Es werden folgende Werkzeuge eingesetzt, um den Entwicklungsvorgang
und die Dokumentation zu unterstützen:




\subsubsection*{Apache Maven \cite{key-15}}

Maven ist ein Projekt-Management-Tool zur standardisierten Erstellung
und Verwaltung von Java-Programmen. Mit Maven ist es möglich, viele
Schritte, die die Entwickler normalerweise von Hand erledigen müssen,
zu automatisieren.


\subsubsection*{Eclipse \cite{key-16}}

Eclipse ist ein Integrated Development Environment (IDE) für Java
und auch andere Programmiersprachen. Für SIMPL wird Eclipse in der
Version 3.5 (Galileo) verwendet.


\subsubsection*{Hudson \cite{key-17}}

Hudson ist ein webbasiertes System zur kontinuierlichen Integration
von Softwareprojekten.


\subsubsection*{\protect\LyX{} \cite{key-18}}

\LyX{} ist ein Textverarbeitungsprogramm, mit dem es möglich ist,
auf einfache Art und Weise \LaTeX{}-Dokumente zu erstellen.


\subsubsection*{PDF-XChange Viewer \cite{key-19}}

Mit dem PDF-XChange Viewer lassen sich PDF-Dateien nicht nur öffnen,
lesen und drucken, sondern zusätzlich Kommentare, Notizen und Markierungen
vornehmen.


\subsubsection*{Subversion \cite{key-20}}

Subversion ist eine Software zur Versionskontrolle und eine Weiterentwicklung
von CVS. Es wird genutzt, um mehreren Nutzern den gleichzeitigen Zugriff
auf und ein gleichzeitiges Bearbeiten von verschiedenen Dateien und
Dokumenten zu ermöglichen.

\pagebreak{}

\addcontentsline{toc}{section}{Literaturverzeichnis}
\begin{thebibliography}{26}
\bibitem{key-1} SIMPL Angebot, Version 1.2, 25.September 2009

\bibitem{key-2} Vrhovnik, M.; Schwarz, H.; Radeschütz, S.; Mitschang,
B.: \emph{An Overview of SQL Support in Workflow Products}. In: Proc.
of the 24th International Conference on Data Engineering (ICDE 2008),
Cancún, México, 7. - 12. April 2008

\bibitem{key-3} Wieland, M.; Görlach, K.; Schumm, D.; Leymann, F.:
\emph{Towards Reference Passing in Web Service and Workflow-based
Applications}. In: Proc. of the 13th IEEE Enterprise Distributed Object
Conference (EDOC 2009), Auckland, New Zealand, 31. August - 04. September
2009.

\bibitem{key-4} Jordan, D.; Evdemon, J.: \emph{Web Services Business
Process Execution Language Version 2.0}, OASIS Standard. Organization
for the Advancement of Structured Information Standards (OASIS), 11.April
2007. http://docs.oasis-open.org/ wsbpel/2.0/OS/wsbpel-v2.0-OS.pdf,
zuletzt zugegriffen am 04.11.2009

\bibitem{key-5} Axis2, http://ws.apache.org/axis2/, zuletzt zugegriffen
am 17.10.2009

\bibitem{key-6} Apache ODE, http://ode.apache.org/, zuletzt zugegriffen
am 17.10.2009

\bibitem{key-7} Apache Tomcat, http://tomcat.apache.org/, zuletzt
zugegriffen am 17.10.2009

\bibitem{key-8} Apache Tuscany DAS, http://tuscany.apache.org/das-overview.html,
zuletzt zugegriffen am 17.10.2009

\bibitem{key-9} Apache Tuscany SDO, http://tuscany.apache.org/sdo-overview.html,
zuletzt zugegriffen am 17.10.2009

\bibitem{key-10} Eclipse BPEL Designer, http://www.eclipse.org/bpel/,
zuletzt zugegriffen am 17.10.2009

\bibitem{key-11} IBM-DB2, http://www.ibm.com/db2/, zuletzt zugegriffen
am 17.10.2009

\bibitem{key-12} Java 6, http://java.sun.com/, zuletzt zugegriffen
am 17.10.2009

\bibitem{key-13} JAX-WS, https://jax-ws.dev.java.net/, zuletzt zugegriffen
am 17.10.2009

\bibitem{key-14} TinyDB, http://telegraph.cs.berkeley.edu/tinydb/,
zuletzt zugegriffen am 17.10.2009

\bibitem{key-15} Apache Maven, http://maven.apache.org/, zuletzt
zugegriffen am 18.10.2009

\bibitem{key-16} Eclipse, http://www.eclipse.org/, zuletzt zugegriffen
am 18.10.2009

\bibitem{key-17} Hudson, https://hudson.dev.java.net/, zuletzt zugegriffen
am 18.10.2009

\bibitem{key-18} \LyX{}, http://www.lyx.org/, zuletzt zugegriffen
am 18.10.2009

\bibitem{key-19} PDF-XChange Viewer, http://pdf-xchange-viewer.softonic.de/,
zuletzt zugegriffen am 18.10.2009

\bibitem{key-20} Subversion, http://subversion.tigris.org/, zuletzt
zugegriffen am 18.10.2009

\bibitem{key-21}WSDL, http://www.w3.org/standards/techs/wsdl, zuletzt
zugegriffen am 04.11.2009

\bibitem{key-22}XQuery Update Facility, http://www.w3.org/standards/techs/xquery,
zuletzt zugegriffen am 06.11.2009

\bibitem{key-23}Steinmetz, T.: \emph{Ein Event-Modell für WS-BPEL
2.0 und dessen Realisierung in Apache ODE}. Universität Stuttgart,
Fakultät Informatik, Elektrotechnik und Informationstechnik, Diplomarbeit
Nr. 2729, 02.August 2008.

\bibitem{key-24}XPath, http://www.w3.org/standards/techs/xpath, zuletzt
zugegriffen am 30.01.2010

\bibitem{key-25}Gudgin, M.; Hadley, M.; Rogers, T.: \emph{Web Service
Addressing 1.0 - Core}, W3C Recommendation. World Wide Web Consortium
(W3C), 09.Mai 2006. http://www.w3.org/TR/ws-addr-core/, zuletzt zugegriffen
am 06.02.2010

\bibitem[26]{key-26}jUDDI, http://ws.apache.org/juddi/, zuletzt zugegriffen
am 28.02.09

\end{thebibliography}
\pagebreak{}

\addcontentsline{toc}{section}{Abkürzungsverzeichnis}


\section*{Abkürzungsverzeichnis}

\begin{center}
\begin{tabular}{|>{\raggedright}p{2cm}|>{\raggedright}p{6cm}|}
\hline 
API  & Application Programming Interface\tabularnewline
\hline 
BPEL & Business Process Execution Language\tabularnewline
\hline 
CSV & Comma-Separated Values\tabularnewline
\hline 
DAS & Data Access Service\tabularnewline
\hline 
DDL & Data Definition Language\tabularnewline
\hline 
DM & Data Management\tabularnewline
\hline 
FLWOR & FOR, LET, WHERE, ORDER, RETURN\tabularnewline
\hline 
IDE & Integrated Development Environment\tabularnewline
\hline 
IUD & INSERT, UPDATE, DELETE\tabularnewline
\hline 
NTFS & New Technology File System\tabularnewline
\hline 
ODE & Orchestration Director Engine\tabularnewline
\hline 
RDB & Relational Database\tabularnewline
\hline 
RRS & Reference Resolution System\tabularnewline
\hline 
SDO & Service Data Object\tabularnewline
\hline 
SIMPL & SimTech: Information Management, Processes and Languages\tabularnewline
\hline 
SOAP & Simple Object Access Protocol\tabularnewline
\hline 
SQL & Structured Query Language\tabularnewline
\hline 
SSO & Single Sign On\tabularnewline
\hline 
UDDI & Universal Description, Discovery and Integration \tabularnewline
\hline 
URI & Unified Resource Identifier\tabularnewline
\hline 
URL & Unified Resource Locator\tabularnewline
\hline 
WS & Web Service\tabularnewline
\hline 
WSDL & Web Service Description Language\tabularnewline
\hline 
XML & Extensible Markup Language\tabularnewline
\hline 
XPath & XML Path Language\tabularnewline
\hline 
XQUERY & XML Query Language\tabularnewline
\hline
\end{tabular}
\par\end{center}

\pagebreak{}

\addcontentsline{toc}{section}{Abbildungsverzeichnis}

\listoffigures


\pagebreak{}

\addcontentsline{toc}{section}{Verzeichnis der Listings}
\renewcommand{\lstlistlistingname}{Verzeichnis der Listings}
\lstlistoflistings

\pagebreak{}

\addcontentsline{toc}{section}{Tabellenverzeichnis}

\listoftables

\end{document}
